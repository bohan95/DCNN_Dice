{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def datato3d(arrays):#list of np arrays, NULL*3*100\n",
    "    output=list()\n",
    "    for i in arrays:\n",
    "        i=np.transpose(i,(0,2,1))\n",
    "        output.append(i)\n",
    "    return output\n",
    "\n",
    "\n",
    "def udflip(X_nparray, y_nparray, shuffle=True):\n",
    "\n",
    "    if X_nparray.shape[2] == 4:\n",
    "        if np.std(X_nparray[:, 0, :]) > np.std(X_nparray[:, -1, :]):\n",
    "            print(\"Detected special info in first column, swapping...\")\n",
    "            X_nparray = np.concatenate((X_nparray[:, 1:, :], X_nparray[:, 0:1, :]), axis=1)\n",
    "    \n",
    "    X_flipped = np.flip(X_nparray, axis=2)  \n",
    "\n",
    "    X_aug = np.vstack((X_nparray, X_flipped))\n",
    "    y_aug = np.hstack((y_nparray, y_nparray))  \n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_idx = np.random.permutation(X_aug.shape[0])\n",
    "        return X_aug[shuffle_idx], y_aug[shuffle_idx]\n",
    "    else:\n",
    "        return X_aug, y_aug\n",
    "\n",
    "with open('../data_61_26_ROIV2.pkl','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "\n",
    "dataList=datato3d([data['X_train'],data['X_test']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3496641, 100, 4), (1497440, 100, 4), (100, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'].shape, data['X_test'].shape,data['X_train'][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-50.86827  ,  -5.1718316, -11.912324 ,   0.       ],\n",
       "       [-50.886658 ,  -5.4194384, -11.963684 ,   0.       ],\n",
       "       [-50.911953 ,  -5.687157 , -12.018323 ,   0.       ],\n",
       "       [-50.926834 ,  -5.954355 , -12.07456  ,   0.       ],\n",
       "       [-50.913975 ,  -6.200402 , -12.130718 ,  20.       ],\n",
       "       [-50.85936  ,  -6.430222 , -12.192032 ,  20.       ],\n",
       "       [-50.769756 ,  -6.6747646, -12.26447  ,  20.       ],\n",
       "       [-50.662407 ,  -6.9200387, -12.3379   ,  20.       ],\n",
       "       [-50.554653 ,  -7.151108 , -12.401925 ,  20.       ],\n",
       "       [-50.4517   ,  -7.367921 , -12.4543   ,  20.       ],\n",
       "       [-50.331234 ,  -7.6009817, -12.509045 ,  20.       ],\n",
       "       [-50.201836 ,  -7.8392177, -12.557598 ,  20.       ],\n",
       "       [-50.074444 ,  -8.068485 , -12.589779 ,  20.       ],\n",
       "       [-49.95623  ,  -8.280725 , -12.597824 ,  20.       ],\n",
       "       [-49.827026 ,  -8.510864 , -12.589802 ,  20.       ],\n",
       "       [-49.689793 ,  -8.750706 , -12.565458 ,  20.       ],\n",
       "       [-49.55394  ,  -8.9807625, -12.522129 ,  20.       ],\n",
       "       [-49.428547 ,  -9.181544 , -12.457297 ,  20.       ],\n",
       "       [-49.29078  ,  -9.373226 , -12.362032 ,  20.       ],\n",
       "       [-49.1397   ,  -9.570057 , -12.238168 ,  20.       ],\n",
       "       [-48.997334 ,  -9.762211 , -12.096154 ,  20.       ],\n",
       "       [-48.885723 ,  -9.939861 , -11.946443 ,   0.       ],\n",
       "       [-48.816116 , -10.100949 , -11.783774 ,  20.       ],\n",
       "       [-48.767735 , -10.266159 , -11.580893 ,  20.       ],\n",
       "       [-48.735657 , -10.434408 , -11.36016  ,  20.       ],\n",
       "       [-48.716362 , -10.602713 , -11.146779 ,  20.       ],\n",
       "       [-48.70658  , -10.768736 , -10.964575 ,  20.       ],\n",
       "       [-48.709225 , -10.952564 , -10.787966 ,  20.       ],\n",
       "       [-48.72382  , -11.155451 , -10.605889 ,  20.       ],\n",
       "       [-48.74699  , -11.364614 , -10.428824 ,  20.       ],\n",
       "       [-48.775417 , -11.567281 , -10.267262 ,  20.       ],\n",
       "       [-48.809483 , -11.76266  , -10.125889 ,  20.       ],\n",
       "       [-48.85801  , -11.982917 ,  -9.986717 ,   0.       ],\n",
       "       [-48.914295 , -12.2149315,  -9.847743 ,   0.       ],\n",
       "       [-48.970177 , -12.440679 ,  -9.7093   ,   0.       ],\n",
       "       [-49.01751  , -12.64222  ,  -9.571656 ,   0.       ],\n",
       "       [-49.061634 , -12.835846 ,  -9.416056 ,   0.       ],\n",
       "       [-49.10787  , -13.0363   ,  -9.240161 ,   0.       ],\n",
       "       [-49.151714 , -13.237117 ,  -9.05889  ,   0.       ],\n",
       "       [-49.188705 , -13.431843 ,  -8.887161 ,   0.       ],\n",
       "       [-49.213554 , -13.618975 ,  -8.732718 ,   0.       ],\n",
       "       [-49.223083 , -13.822844 ,  -8.565083 ,   0.       ],\n",
       "       [-49.228058 , -14.038689 ,  -8.392146 ,  21.       ],\n",
       "       [-49.24076  , -14.255686 ,  -8.229966 ,  21.       ],\n",
       "       [-49.27348  , -14.46302  ,  -8.094593 ,  21.       ],\n",
       "       [-49.335632 , -14.674185 ,  -7.987565 ,   0.       ],\n",
       "       [-49.42278  , -14.909995 ,  -7.890837 ,   0.       ],\n",
       "       [-49.52378  , -15.152636 ,  -7.800441 ,   0.       ],\n",
       "       [-49.627407 , -15.384038 ,  -7.712535 ,   0.       ],\n",
       "       [-49.725113 , -15.590471 ,  -7.623116 ,   0.       ],\n",
       "       [-49.837795 , -15.806739 ,  -7.528829 ,   0.       ],\n",
       "       [-49.963135 , -16.031654 ,  -7.428169 ,  21.       ],\n",
       "       [-50.08912  , -16.248756 ,  -7.319421 ,  21.       ],\n",
       "       [-50.2037   , -16.441587 ,  -7.2008677,  21.       ],\n",
       "       [-50.30425  , -16.612165 ,  -7.0585895,  21.       ],\n",
       "       [-50.404205 , -16.78503  ,  -6.8785257,  21.       ],\n",
       "       [-50.5062   , -16.951378 ,  -6.680846 ,  21.       ],\n",
       "       [-50.612686 , -17.101582 ,  -6.486412 ,  21.       ],\n",
       "       [-50.727444 , -17.227957 ,  -6.312702 ,  21.       ],\n",
       "       [-50.864716 , -17.34879  ,  -6.1269946,  21.       ],\n",
       "       [-51.020916 , -17.464067 ,  -5.9296894,  21.       ],\n",
       "       [-51.18821  , -17.565393 ,  -5.7384996,  21.       ],\n",
       "       [-51.358795 , -17.644371 ,  -5.5711446,  21.       ],\n",
       "       [-51.54813  , -17.701433 ,  -5.426265 ,  21.       ],\n",
       "       [-51.774044 , -17.74564  ,  -5.2838264,  21.       ],\n",
       "       [-52.013245 , -17.775797 ,  -5.145474 ,  21.       ],\n",
       "       [-52.24209  , -17.79063  ,  -5.013077 ,  21.       ],\n",
       "       [-52.4487   , -17.78935  ,  -4.8835874,  21.       ],\n",
       "       [-52.672024 , -17.773352 ,  -4.739139 ,  21.       ],\n",
       "       [-52.903187 , -17.741438 ,  -4.5888767,  21.       ],\n",
       "       [-53.1252   , -17.69195  ,  -4.445495 ,  21.       ],\n",
       "       [-53.322712 , -17.62286  ,  -4.320688 ,  21.       ],\n",
       "       [-53.527004 , -17.524061 ,  -4.196682 ,  21.       ],\n",
       "       [-53.740143 , -17.397474 ,  -4.069832 ,  21.       ],\n",
       "       [-53.94072  , -17.25094  ,  -3.950089 ,   0.       ],\n",
       "       [-54.107346 , -17.092297 ,  -3.8474076,   0.       ],\n",
       "       [-54.24146  , -16.90885  ,  -3.7622333,   0.       ],\n",
       "       [-54.367554 , -16.682287 ,  -3.6816769,   0.       ],\n",
       "       [-54.477703 , -16.435705 ,  -3.6056905,   0.       ],\n",
       "       [-54.563416 , -16.192774 ,  -3.5344903,   0.       ],\n",
       "       [-54.61615  , -15.967454 ,  -3.4665868,   0.       ],\n",
       "       [-54.63784  , -15.717778 ,  -3.3924131,   0.       ],\n",
       "       [-54.64154  , -15.451428 ,  -3.3166416,   0.       ],\n",
       "       [-54.640373 , -15.187297 ,  -3.2466376,   0.       ],\n",
       "       [-54.647457 , -14.943955 ,  -3.189658 ,   0.       ],\n",
       "       [-54.663616 , -14.694769 ,  -3.1353052,   0.       ],\n",
       "       [-54.68254  , -14.426131 ,  -3.0807216,   0.       ],\n",
       "       [-54.703453 , -14.155595 ,  -3.0369964,   0.       ],\n",
       "       [-54.725605 , -13.90072  ,  -3.015222 ,   0.       ],\n",
       "       [-54.749928 , -13.66024  ,  -3.0261369,   0.       ],\n",
       "       [-54.77952  , -13.399671 ,  -3.0685139,   0.       ],\n",
       "       [-54.81238  , -13.1325655,  -3.12998  ,   0.       ],\n",
       "       [-54.846252 , -12.8751545,  -3.1978424,   0.       ],\n",
       "       [-54.879627 , -12.638925 ,  -3.2622478,   0.       ],\n",
       "       [-54.91942  , -12.378534 ,  -3.346464 ,   0.       ],\n",
       "       [-54.963654 , -12.104484 ,  -3.4426537,   0.       ],\n",
       "       [-55.006817 , -11.849942 ,  -3.5303628,   0.       ],\n",
       "       [-55.043434 , -11.648093 ,  -3.5891414,   0.       ],\n",
       "       [-55.10965  , -11.363186 ,  -3.6119215,   0.       ],\n",
       "       [-55.170914 , -11.140897 ,  -3.5951705,   0.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=dataList[0]\n",
    "X_test=dataList[1]\n",
    "# X_train, y_train = X_train[:, :, ::5], data['y_train'][:]\n",
    "# X_test, y_test = X_test[:, :, ::5], data['y_test'][:]\n",
    "X_train, y_train = X_train[:, :, ::1], data['y_train'][:]\n",
    "X_test, y_test = X_test[:, :, ::1], data['y_test'][:]\n",
    "\n",
    "y_test_list=data['y_test'].tolist()\n",
    "\n",
    "NCLASS=max(y_test_list)+1\n",
    "\n",
    "X_train,y_train=udflip(X_train,y_train,shuffle=True)\n",
    "X_test,y_test=udflip(X_test,y_test,shuffle=False)\n",
    "\n",
    "X_train=torch.from_numpy(X_train)#data['X_train'])\n",
    "y_train=torch.from_numpy(y_train.astype(np.int32))#data['y_train'])\n",
    "\n",
    "X_test=torch.from_numpy(X_test)\n",
    "y_test=torch.from_numpy(y_test.astype(np.int32))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n",
      "X_train_shape torch.Size([6993282, 4, 100])\n",
      "X_test_shape torch.Size([2994880, 4, 100])\n",
      "classes:  15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "del data,dataList\n",
    "gc.collect()\n",
    "print('data loaded!')\n",
    "print('X_train_shape',X_train.size())\n",
    "print('X_test_shape',X_test.size())\n",
    "print('classes: ', NCLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6993282, 4, 100]),\n",
       " torch.Size([10, 4, 100]),\n",
       " torch.Size([6993282]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train[10:20,:,:].shape, y_train.shape, y_train[10:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-22.7798, -23.2095, -23.6488, -24.1066, -24.5564, -25.0120, -25.4260,\n",
       "          -25.8552, -26.2227, -26.5948, -26.9435, -27.3249, -27.6934, -27.9871,\n",
       "          -28.2688, -28.5298, -28.8139, -29.0853, -29.3537, -29.6324, -29.8968,\n",
       "          -30.1894, -30.4526, -30.7249, -30.9713, -31.1477, -31.3044, -31.4400,\n",
       "          -31.5794, -31.6990, -31.7768, -31.8354, -31.8841, -31.9207, -31.9668,\n",
       "          -32.0530, -32.1843, -32.3450, -32.5947, -32.8801, -33.1978, -33.5565,\n",
       "          -33.9500, -34.3913, -34.8791, -35.3947, -35.9442, -36.4851, -37.0730,\n",
       "          -37.6075, -38.1614, -38.6716, -39.2143, -39.7491, -40.3289, -40.8770,\n",
       "          -41.4341, -41.9638, -42.4828, -43.0007, -43.5003, -44.0078, -44.5013,\n",
       "          -45.0275, -45.5446, -46.1130, -46.6539, -47.2165, -47.7126, -48.1638,\n",
       "          -48.5804, -49.0115, -49.4411, -49.9411, -50.4186, -50.9084, -51.3395,\n",
       "          -51.7195, -52.0617, -52.3882, -52.7167, -53.1041, -53.5042, -53.9351,\n",
       "          -54.3428, -54.6618, -54.9393, -55.1435, -55.3424, -55.6024, -55.9283,\n",
       "          -56.3174, -56.8050, -57.2711, -57.7823, -58.2044, -58.6156, -58.9834,\n",
       "          -59.3723, -59.6797],\n",
       "         [-21.9086, -21.6517, -21.3452, -21.0398, -20.7789, -20.5264, -20.2919,\n",
       "          -20.0504, -19.8498, -19.6515, -19.4900, -19.3538, -19.2421, -19.1717,\n",
       "          -19.1227, -19.0760, -19.0183, -18.9853, -19.0019, -19.0519, -19.1326,\n",
       "          -19.2575, -19.3638, -19.4562, -19.5405, -19.6180, -19.6935, -19.7287,\n",
       "          -19.7151, -19.7037, -19.7416, -19.8069, -19.8488, -19.8718, -19.8706,\n",
       "          -19.8169, -19.7075, -19.5860, -19.4225, -19.2495, -19.0657, -18.8965,\n",
       "          -18.8534, -18.8766, -18.9088, -18.9313, -18.8790, -18.8595, -18.9131,\n",
       "          -19.0291, -19.2164, -19.3665, -19.4999, -19.5374, -19.5100, -19.4964,\n",
       "          -19.4608, -19.3468, -19.2093, -19.0623, -18.9572, -18.9371, -18.9209,\n",
       "          -18.8583, -18.8467, -18.9542, -19.0742, -19.2007, -19.2691, -19.2377,\n",
       "          -19.2206, -19.2567, -19.3136, -19.3959, -19.5036, -19.6494, -19.8495,\n",
       "          -20.1615, -20.4685, -20.7517, -21.0183, -21.2836, -21.5442, -21.8115,\n",
       "          -22.0878, -22.3777, -22.6900, -23.0292, -23.3908, -23.6993, -24.0063,\n",
       "          -24.2861, -24.5730, -24.8151, -25.0560, -25.2981, -25.5772, -25.8905,\n",
       "          -26.2958, -26.6069],\n",
       "         [  5.0932,   5.2472,   5.4773,   5.7241,   5.9620,   6.2212,   6.5033,\n",
       "            6.8353,   7.1830,   7.6046,   8.0073,   8.4228,   8.8577,   9.3151,\n",
       "            9.8378,  10.3170,  10.8337,  11.3305,  11.8289,  12.3461,  12.8152,\n",
       "           13.3148,  13.7864,  14.2911,  14.8089,  15.3245,  15.8977,  16.4262,\n",
       "           16.9958,  17.5627,  18.1044,  18.6941,  19.2409,  19.8230,  20.4090,\n",
       "           20.9463,  21.5261,  22.0337,  22.5387,  22.9994,  23.4361,  23.8569,\n",
       "           24.2535,  24.6269,  24.9155,  25.1466,  25.3356,  25.4457,  25.4655,\n",
       "           25.4165,  25.2987,  25.1399,  24.9338,  24.7955,  24.7150,  24.7939,\n",
       "           24.9588,  25.1287,  25.3175,  25.5255,  25.7559,  26.0440,  26.3140,\n",
       "           26.5731,  26.7669,  26.8862,  26.8999,  26.7687,  26.5392,  26.1641,\n",
       "           25.7853,  25.3865,  25.0382,  24.7459,  24.4777,  24.1917,  23.9057,\n",
       "           23.5908,  23.2630,  22.8722,  22.4996,  22.1649,  21.8579,  21.5864,\n",
       "           21.2985,  20.9309,  20.5262,  20.1284,  19.7118,  19.3226,  18.9325,\n",
       "           18.6785,  18.4971,  18.3298,  18.1507,  17.9058,  17.5740,  17.2782,\n",
       "           16.9657,  16.7339],\n",
       "         [691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000,\n",
       "          691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000,\n",
       "          691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000,\n",
       "          691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000, 691.0000,\n",
       "          691.0000, 691.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           96.0000, 145.0000, 145.0000, 145.0000, 145.0000, 145.0000, 145.0000,\n",
       "           96.0000,  96.0000,  96.0000,  96.0000,  96.0000,  96.0000,  96.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,  96.0000,  96.0000,  96.0000,\n",
       "           96.0000,  96.0000]]),\n",
       " tensor(0, dtype=torch.int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[14], y_train[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiber 1: [487.0, 692.0] cluster: 11\n",
      "Fiber 2: [47.0] cluster: 4\n",
      "Fiber 3: [422.0, 648.0] cluster: 12\n",
      "Fiber 4: [151.0, 191.0, 691.0] cluster: 1\n",
      "Fiber 5: [649.0] cluster: 13\n",
      "Fiber 6: [] cluster: 4\n",
      "Fiber 7: [27.0] cluster: 4\n",
      "Fiber 8: [228.0] cluster: 6\n",
      "Fiber 9: [159.0, 196.0] cluster: 6\n",
      "Fiber 10: [36.0, 37.0, 48.0, 49.0] cluster: 4\n",
      "Fiber 11: [156.0, 691.0] cluster: 2\n",
      "Fiber 12: [146.0, 152.0] cluster: 14\n",
      "Fiber 13: [221.0, 228.0] cluster: 6\n",
      "Fiber 14: [] cluster: 6\n",
      "Fiber 15: [96.0, 145.0, 691.0] cluster: 0\n",
      "Fiber 16: [111.0] cluster: 14\n",
      "Fiber 17: [151.0, 152.0, 153.0, 691.0] cluster: 1\n",
      "Fiber 18: [30.0, 36.0, 37.0] cluster: 4\n",
      "Fiber 19: [] cluster: 3\n",
      "Fiber 20: [647.0] cluster: 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_fiber_roi(fiber_data):\n",
    "    \"\"\"\n",
    "    Compute the unique ROI classification for each fiber, removing ROI values of 0.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor of shape (b, 4, 100), where the last dimension represents ROI classification.\n",
    "\n",
    "    Returns:\n",
    "        roi_list: List[Tensor], each element contains a fiber's unique ROI classifications (deduplicated, excluding 0).\n",
    "    \"\"\"\n",
    "    # Extract ROI classification data (b, 100)\n",
    "    roi_data = fiber_data[:, 3, :]\n",
    "\n",
    "    # Remove 0 and get unique ROI classifications\n",
    "    roi_list = [torch.unique(roi[roi != 0]) for roi in roi_data]\n",
    "\n",
    "    return roi_list\n",
    "\n",
    "# Example data\n",
    "b, num_points = 5, 100  # 5 fibers, each with 100 points\n",
    "fiber_data = X_train[:20, :, :]  # Extract ROI classifications\n",
    "labels = y_train[:20]\n",
    "\n",
    "# Compute ROI classifications for each fiber\n",
    "fiber_rois = compute_fiber_roi(fiber_data)\n",
    "\n",
    "# Print results\n",
    "for i, rois in enumerate(fiber_rois):\n",
    "    print(f\"Fiber {i + 1}: {rois.tolist()} cluster: {labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cluster-Level ROI Classification =====\n",
      "Cluster 0: [21.0, 22.0, 23.0, 24.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 100.0, 101.0, 116.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 214.0, 215.0, 217.0, 218.0, 219.0, 220.0, 221.0, 335.0, 338.0, 339.0, 342.0, 343.0, 691.0]\n",
      "Cluster 1: [23.0, 24.0, 96.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 145.0, 146.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 161.0, 182.0, 183.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 216.0, 219.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 332.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 344.0, 691.0]\n",
      "Cluster 2: [23.0, 24.0, 92.0, 93.0, 94.0, 96.0, 115.0, 116.0, 120.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 145.0, 146.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 161.0, 190.0, 194.0, 214.0, 215.0, 217.0, 218.0, 219.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 691.0]\n",
      "Cluster 3: [1.0, 6.0, 10.0, 13.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 73.0, 75.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 239.0, 240.0, 241.0, 244.0, 248.0, 249.0, 250.0, 251.0, 255.0, 256.0, 260.0, 264.0, 265.0, 269.0, 273.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 299.0, 300.0, 302.0, 303.0, 304.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 366.0, 367.0, 368.0, 369.0, 372.0, 374.0, 375.0, 376.0, 396.0, 399.0, 400.0, 404.0, 405.0, 418.0, 430.0, 431.0, 433.0, 436.0, 441.0, 447.0, 450.0, 453.0, 454.0, 455.0, 456.0, 459.0, 460.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 485.0, 491.0, 492.0, 493.0, 495.0, 496.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 506.0, 507.0, 510.0, 511.0, 514.0, 515.0, 516.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 543.0, 544.0, 545.0, 547.0, 548.0, 549.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 559.0, 561.0, 562.0, 563.0, 564.0, 565.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 585.0, 589.0, 592.0, 593.0, 596.0, 598.0, 600.0, 632.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 674.0, 675.0, 677.0, 680.0, 681.0, 687.0, 688.0, 691.0, 692.0]\n",
      "Cluster 4: [1.0, 2.0, 6.0, 8.0, 10.0, 11.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 99.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 133.0, 141.0, 142.0, 143.0, 146.0, 147.0, 148.0, 149.0, 150.0, 155.0, 156.0, 157.0, 158.0, 159.0, 161.0, 177.0, 178.0, 181.0, 182.0, 183.0, 185.0, 186.0, 187.0, 189.0, 190.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 203.0, 204.0, 205.0, 207.0, 208.0, 210.0, 211.0, 213.0, 214.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 230.0, 269.0, 272.0, 273.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 315.0, 316.0, 317.0, 318.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 337.0, 338.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 366.0, 367.0, 368.0, 372.0, 373.0, 374.0, 376.0, 390.0, 395.0, 396.0, 397.0, 399.0, 400.0, 402.0, 403.0, 404.0, 405.0, 406.0, 412.0, 415.0, 416.0, 433.0, 434.0, 436.0, 447.0, 450.0, 455.0, 456.0, 460.0, 461.0, 462.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 478.0, 479.0, 480.0, 485.0, 486.0, 503.0, 530.0, 535.0, 561.0, 564.0, 628.0, 660.0, 663.0, 664.0, 665.0, 666.0, 667.0, 669.0, 670.0, 676.0, 688.0, 691.0]\n",
      "Cluster 5: [1.0, 6.0, 10.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 62.0, 63.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 74.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 136.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 190.0, 191.0, 192.0, 194.0, 198.0, 199.0, 200.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 244.0, 248.0, 251.0, 269.0, 273.0, 282.0, 283.0, 284.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 298.0, 299.0, 300.0, 301.0, 303.0, 304.0, 309.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 365.0, 366.0, 368.0, 369.0, 374.0, 379.0, 386.0, 392.0, 397.0, 400.0, 415.0, 430.0, 431.0, 433.0, 434.0, 436.0, 447.0, 450.0, 453.0, 454.0, 455.0, 456.0, 459.0, 460.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 484.0, 485.0, 486.0, 495.0, 500.0, 501.0, 502.0, 506.0, 507.0, 511.0, 515.0, 519.0, 520.0, 522.0, 523.0, 526.0, 527.0, 531.0, 535.0, 548.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 561.0, 564.0, 565.0, 567.0, 572.0, 573.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 674.0, 677.0, 680.0, 689.0, 690.0, 691.0]\n",
      "Cluster 6: [19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 47.0, 48.0, 49.0, 50.0, 52.0, 55.0, 57.0, 58.0, 59.0, 60.0, 66.0, 70.0, 71.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 119.0, 120.0, 125.0, 126.0, 129.0, 130.0, 133.0, 134.0, 135.0, 136.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 165.0, 166.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 231.0, 248.0, 249.0, 250.0, 251.0, 255.0, 256.0, 269.0, 273.0, 282.0, 283.0, 284.0, 287.0, 288.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 324.0, 325.0, 329.0, 330.0, 332.0, 333.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 342.0, 343.0, 455.0, 456.0, 459.0, 460.0, 461.0, 465.0, 466.0, 471.0, 479.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 491.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 503.0, 506.0, 507.0, 511.0, 518.0, 519.0, 522.0, 523.0, 524.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 543.0, 544.0, 547.0, 548.0, 549.0, 551.0, 552.0, 555.0, 558.0, 559.0, 561.0, 564.0, 565.0, 567.0, 570.0, 572.0, 573.0, 596.0, 600.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 674.0, 677.0, 680.0, 681.0, 683.0, 691.0, 692.0]\n",
      "Cluster 7: [14.0, 16.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 88.0, 89.0, 90.0, 91.0, 121.0, 127.0, 128.0, 129.0, 130.0, 133.0, 225.0, 228.0, 273.0, 276.0, 277.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 338.0, 341.0, 342.0, 343.0, 344.0, 345.0, 691.0]\n",
      "Cluster 8: [1.0, 6.0, 10.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 91.0, 109.0, 127.0, 224.0, 273.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 331.0, 333.0, 334.0, 336.0, 337.0, 342.0, 343.0, 344.0, 345.0, 691.0]\n",
      "Cluster 9: [366.0, 367.0, 368.0, 369.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 445.0, 446.0, 461.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 556.0, 559.0, 560.0, 562.0, 563.0, 564.0, 565.0, 566.0, 677.0, 680.0, 681.0, 683.0, 684.0, 687.0, 688.0, 689.0, 692.0]\n",
      "Cluster 10: [358.0, 367.0, 368.0, 369.0, 441.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 462.0, 464.0, 466.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 490.0, 491.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 506.0, 523.0, 524.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 561.0, 564.0, 661.0, 662.0, 663.0, 664.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0]\n",
      "Cluster 11: [367.0, 368.0, 438.0, 439.0, 441.0, 459.0, 460.0, 461.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 490.0, 491.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 506.0, 531.0, 534.0, 535.0, 536.0, 537.0, 539.0, 562.0, 563.0, 564.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0]\n",
      "Cluster 12: [346.0, 347.0, 351.0, 355.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 400.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 433.0, 434.0, 435.0, 436.0, 450.0, 454.0, 466.0, 472.0, 473.0, 474.0, 475.0, 478.0, 569.0, 571.0, 575.0, 576.0, 614.0, 618.0, 621.0, 622.0, 623.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 678.0, 679.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0]\n",
      "Cluster 13: [346.0, 351.0, 355.0, 359.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 403.0, 404.0, 405.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 436.0, 441.0, 446.0, 453.0, 454.0, 491.0, 569.0, 571.0, 574.0, 575.0, 589.0, 596.0, 610.0, 614.0, 617.0, 618.0, 621.0, 622.0, 624.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 654.0, 655.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0]\n",
      "Cluster 14: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 582.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 601.0, 602.0, 603.0, 604.0, 605.0, 606.0, 607.0, 608.0, 609.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 621.0, 622.0, 623.0, 624.0, 625.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 640.0, 641.0, 642.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 650.0, 651.0, 652.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 691.0, 692.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_cluster_roi(X_train, y_train, num_of_class, threshold=0.00000000002):\n",
    "    \"\"\"\n",
    "    Compute ROI classification for each cluster based on the rule that 40% of fibers pass through an ROI (ignoring 0).\n",
    "    Also, print the ROI each fiber passes through along with its corresponding cluster.\n",
    "\n",
    "    Parameters:\n",
    "        X_train: Tensor, shape (b, 4, 100), where the 4th dimension represents ROI classification.\n",
    "        y_train: Tensor, shape (b,), containing each fiber's cluster label.\n",
    "        num_of_class: int, total number of clusters.\n",
    "        threshold: float, threshold setting (default is 0.4, i.e., 40%).\n",
    "\n",
    "    Returns:\n",
    "        cluster_rois: List[Tensor], each element contains the ROI classification of the cluster (deduplicated & filtered by threshold).\n",
    "    \"\"\"\n",
    "    # Extract fiber ROI classification information (b, 100)\n",
    "    roi_data = X_train[:, 3, :]\n",
    "\n",
    "    # Compute unique ROI classifications for each fiber (remove duplicates & ignore 0)\n",
    "    fiber_rois = [torch.unique(roi[roi != 0]) for roi in roi_data]\n",
    "    # Compute ROI for each cluster\n",
    "    cluster_rois = []\n",
    "    for cluster_id in range(num_of_class):\n",
    "        # Get fibers belonging to the current cluster\n",
    "        cluster_fibers = [fiber_rois[i] for i in range(len(y_train)) if y_train[i] == cluster_id]\n",
    "\n",
    "        if not cluster_fibers:  # If no fibers belong to this cluster, skip\n",
    "            cluster_rois.append(torch.tensor([]))\n",
    "            continue\n",
    "\n",
    "        # Aggregate all ROI classifications from fibers\n",
    "        all_rois = torch.cat(cluster_fibers)  # Concatenate all fiber ROIs\n",
    "        unique_rois, counts = torch.unique(all_rois, return_counts=True)  # Count occurrences of each ROI\n",
    "\n",
    "        # Compute the occurrence ratio\n",
    "        fiber_count = len(cluster_fibers)  # Total number of fibers in this cluster\n",
    "        roi_ratio = counts.float() / fiber_count  # Compute the proportion of fibers passing through each ROI\n",
    "\n",
    "        # Select ROIs that meet the 40% threshold\n",
    "        selected_rois = unique_rois[roi_ratio >= threshold]\n",
    "        cluster_rois.append(selected_rois)\n",
    "\n",
    "    return cluster_rois\n",
    "\n",
    "# Example data\n",
    "num_of_class = NCLASS  # Total number of clusters\n",
    "num_samples = 1000000\n",
    "x_train_sub = X_train[:num_samples, :, :]  # Select the first 100 fibers\n",
    "y_train_sub = y_train[:num_samples]  # Select the first 100 fiber cluster labels\n",
    "\n",
    "# Compute cluster-level ROI classification\n",
    "cluster_roi_classes = compute_cluster_roi(x_train_sub, y_train_sub, num_of_class)\n",
    "\n",
    "# Print cluster-level ROI classification results\n",
    "print(\"\\n===== Cluster-Level ROI Classification =====\")\n",
    "for cluster_id, rois in enumerate(cluster_roi_classes):\n",
    "    print(f\"Cluster {cluster_id}: {rois.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cluster-Level ROI Classification =====\n",
      "Cluster 0: [21.0, 22.0, 23.0, 24.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 100.0, 101.0, 116.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 214.0, 215.0, 217.0, 218.0, 219.0, 220.0, 221.0, 335.0, 338.0, 339.0, 342.0, 343.0, 691.0], size 42\n",
      "Cluster 1: [23.0, 24.0, 96.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 145.0, 146.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 161.0, 182.0, 183.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 216.0, 219.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 332.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 344.0, 691.0], size 61\n",
      "Cluster 2: [23.0, 24.0, 92.0, 93.0, 94.0, 96.0, 115.0, 116.0, 120.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 145.0, 146.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 161.0, 190.0, 194.0, 214.0, 215.0, 217.0, 218.0, 219.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 691.0], size 38\n",
      "Cluster 3: [1.0, 6.0, 10.0, 13.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 73.0, 75.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 239.0, 240.0, 241.0, 244.0, 248.0, 249.0, 250.0, 251.0, 255.0, 256.0, 260.0, 264.0, 265.0, 269.0, 273.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 299.0, 300.0, 302.0, 303.0, 304.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 366.0, 367.0, 368.0, 369.0, 372.0, 374.0, 375.0, 376.0, 396.0, 399.0, 400.0, 404.0, 405.0, 418.0, 430.0, 431.0, 433.0, 436.0, 441.0, 447.0, 450.0, 453.0, 454.0, 455.0, 456.0, 459.0, 460.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 485.0, 491.0, 492.0, 493.0, 495.0, 496.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 506.0, 507.0, 510.0, 511.0, 514.0, 515.0, 516.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 543.0, 544.0, 545.0, 547.0, 548.0, 549.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 559.0, 561.0, 562.0, 563.0, 564.0, 565.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 585.0, 589.0, 592.0, 593.0, 596.0, 598.0, 600.0, 632.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 674.0, 675.0, 677.0, 680.0, 681.0, 687.0, 688.0, 691.0, 692.0], size 400\n",
      "Cluster 4: [1.0, 2.0, 6.0, 8.0, 10.0, 11.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 99.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 133.0, 141.0, 142.0, 143.0, 146.0, 147.0, 148.0, 149.0, 150.0, 155.0, 156.0, 157.0, 158.0, 159.0, 161.0, 177.0, 178.0, 181.0, 182.0, 183.0, 185.0, 186.0, 187.0, 189.0, 190.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 203.0, 204.0, 205.0, 207.0, 208.0, 210.0, 211.0, 213.0, 214.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 230.0, 269.0, 272.0, 273.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 315.0, 316.0, 317.0, 318.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 337.0, 338.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 366.0, 367.0, 368.0, 372.0, 373.0, 374.0, 376.0, 390.0, 395.0, 396.0, 397.0, 399.0, 400.0, 402.0, 403.0, 404.0, 405.0, 406.0, 412.0, 415.0, 416.0, 433.0, 434.0, 436.0, 447.0, 450.0, 455.0, 456.0, 460.0, 461.0, 462.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 478.0, 479.0, 480.0, 485.0, 486.0, 503.0, 530.0, 535.0, 561.0, 564.0, 628.0, 660.0, 663.0, 664.0, 665.0, 666.0, 667.0, 669.0, 670.0, 676.0, 688.0, 691.0], size 285\n",
      "Cluster 5: [1.0, 6.0, 10.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 62.0, 63.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 74.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 136.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 190.0, 191.0, 192.0, 194.0, 198.0, 199.0, 200.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 244.0, 248.0, 251.0, 269.0, 273.0, 282.0, 283.0, 284.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 298.0, 299.0, 300.0, 301.0, 303.0, 304.0, 309.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 365.0, 366.0, 368.0, 369.0, 374.0, 379.0, 386.0, 392.0, 397.0, 400.0, 415.0, 430.0, 431.0, 433.0, 434.0, 436.0, 447.0, 450.0, 453.0, 454.0, 455.0, 456.0, 459.0, 460.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 484.0, 485.0, 486.0, 495.0, 500.0, 501.0, 502.0, 506.0, 507.0, 511.0, 515.0, 519.0, 520.0, 522.0, 523.0, 526.0, 527.0, 531.0, 535.0, 548.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 561.0, 564.0, 565.0, 567.0, 572.0, 573.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 674.0, 677.0, 680.0, 689.0, 690.0, 691.0], size 334\n",
      "Cluster 6: [19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 41.0, 42.0, 43.0, 44.0, 45.0, 47.0, 48.0, 49.0, 50.0, 52.0, 55.0, 57.0, 58.0, 59.0, 60.0, 66.0, 70.0, 71.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 119.0, 120.0, 125.0, 126.0, 129.0, 130.0, 133.0, 134.0, 135.0, 136.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 165.0, 166.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 231.0, 248.0, 249.0, 250.0, 251.0, 255.0, 256.0, 269.0, 273.0, 282.0, 283.0, 284.0, 287.0, 288.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 324.0, 325.0, 329.0, 330.0, 332.0, 333.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 342.0, 343.0, 455.0, 456.0, 459.0, 460.0, 461.0, 465.0, 466.0, 471.0, 479.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 491.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 503.0, 506.0, 507.0, 511.0, 518.0, 519.0, 522.0, 523.0, 524.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 543.0, 544.0, 547.0, 548.0, 549.0, 551.0, 552.0, 555.0, 558.0, 559.0, 561.0, 564.0, 565.0, 567.0, 570.0, 572.0, 573.0, 596.0, 600.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 674.0, 677.0, 680.0, 681.0, 683.0, 691.0, 692.0], size 285\n",
      "Cluster 7: [14.0, 16.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 88.0, 89.0, 90.0, 91.0, 121.0, 127.0, 128.0, 129.0, 130.0, 133.0, 225.0, 228.0, 273.0, 276.0, 277.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 338.0, 341.0, 342.0, 343.0, 344.0, 345.0, 691.0], size 118\n",
      "Cluster 8: [1.0, 6.0, 10.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 91.0, 109.0, 127.0, 224.0, 273.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 331.0, 333.0, 334.0, 336.0, 337.0, 342.0, 343.0, 344.0, 345.0, 691.0], size 100\n",
      "Cluster 9: [366.0, 367.0, 368.0, 369.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 445.0, 446.0, 461.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 556.0, 559.0, 560.0, 562.0, 563.0, 564.0, 565.0, 566.0, 677.0, 680.0, 681.0, 683.0, 684.0, 687.0, 688.0, 689.0, 692.0], size 46\n",
      "Cluster 10: [358.0, 367.0, 368.0, 369.0, 441.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 462.0, 464.0, 466.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 490.0, 491.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 506.0, 523.0, 524.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 561.0, 564.0, 661.0, 662.0, 663.0, 664.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0], size 64\n",
      "Cluster 11: [367.0, 368.0, 438.0, 439.0, 441.0, 459.0, 460.0, 461.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 490.0, 491.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 506.0, 531.0, 534.0, 535.0, 536.0, 537.0, 539.0, 562.0, 563.0, 564.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0], size 46\n",
      "Cluster 12: [346.0, 347.0, 351.0, 355.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 400.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 433.0, 434.0, 435.0, 436.0, 450.0, 454.0, 466.0, 472.0, 473.0, 474.0, 475.0, 478.0, 569.0, 571.0, 575.0, 576.0, 614.0, 618.0, 621.0, 622.0, 623.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 678.0, 679.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0], size 135\n",
      "Cluster 13: [346.0, 351.0, 355.0, 359.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 403.0, 404.0, 405.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 436.0, 441.0, 446.0, 453.0, 454.0, 491.0, 569.0, 571.0, 574.0, 575.0, 589.0, 596.0, 610.0, 614.0, 617.0, 618.0, 621.0, 622.0, 624.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 654.0, 655.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0], size 121\n",
      "Cluster 14: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 582.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 601.0, 602.0, 603.0, 604.0, 605.0, 606.0, 607.0, 608.0, 609.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 621.0, 622.0, 623.0, 624.0, 625.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 640.0, 641.0, 642.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 650.0, 651.0, 652.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 691.0, 692.0], size 692\n"
     ]
    }
   ],
   "source": [
    "# Print cluster-level ROI classification results\n",
    "print(\"\\n===== Cluster-Level ROI Classification =====\")\n",
    "for cluster_id, rois in enumerate(cluster_roi_classes):\n",
    "    print(f\"Cluster {cluster_id}: {rois.tolist()}, size {len(rois.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def compute_cluster_roi(X_train, y_train, num_of_class, threshold=0.4):\n",
    "#     \"\"\"\n",
    "#     Compute ROI class information at the cluster level and ignore fibers without classification.\n",
    "#     Also, count the number of valid fibers within each cluster.\n",
    "\n",
    "#     Parameters:\n",
    "#         X_train: Tensor, shape (b, 4, 100), where the 4th column represents ROI.\n",
    "#         y_train: Tensor, shape (b,), containing each fiber's cluster label.\n",
    "#         num_of_class: int, number of clusters.\n",
    "#         threshold: float, default threshold is 40%.\n",
    "\n",
    "#     Returns:\n",
    "#         cluster_rois: List[Tensor], cluster ROI information.\n",
    "#         cluster_fiber_counts: List[int], where each element represents the number of valid fibers within the cluster.\n",
    "#     \"\"\"\n",
    "#     # Extract fiber ROI classification information (b, 100)\n",
    "#     roi_data = X_train[:, 3, :]\n",
    "\n",
    "#     # Compute unique ROI classifications for each fiber (remove duplicates & ignore 0)\n",
    "#     fiber_rois = [torch.unique(roi[roi != 0]) for roi in roi_data]\n",
    "\n",
    "#     # Filter out fibers without any classification (i.e., fibers where fiber_rois is empty)\n",
    "#     valid_indices = [i for i in range(len(fiber_rois)) if fiber_rois[i].numel() > 0]\n",
    "#     valid_fiber_rois = [fiber_rois[i] for i in valid_indices]\n",
    "#     valid_y_train = y_train[valid_indices]  # Filtered y_train\n",
    "\n",
    "#     # Print ROI and cluster information for each valid fiber\n",
    "#     # print(\"\\n===== Fiber ROI & Cluster Information (Ignoring Unclassified Fibers) =====\")\n",
    "#     # for i, idx in enumerate(valid_indices):\n",
    "#     #     print(f\"Fiber {idx + 1} (Cluster {valid_y_train[i].item()}): {valid_fiber_rois[i].tolist()}\")\n",
    "\n",
    "#     # Compute ROI and fiber count for each cluster\n",
    "#     cluster_rois = []\n",
    "#     cluster_fiber_counts = []  # Store the number of valid fibers in each cluster\n",
    "\n",
    "#     for cluster_id in range(num_of_class):\n",
    "#         # Get fibers belonging to the current cluster\n",
    "#         cluster_fibers = [valid_fiber_rois[i] for i in range(len(valid_y_train)) if valid_y_train[i] == cluster_id]\n",
    "\n",
    "#         cluster_fiber_counts.append(len(cluster_fibers))  # Record the number of valid fibers in the cluster\n",
    "\n",
    "#         if not cluster_fibers:  # If no fibers belong to this cluster, skip\n",
    "#             cluster_rois.append(torch.tensor([]))\n",
    "#             continue\n",
    "\n",
    "#         # Aggregate all ROI classifications from fibers\n",
    "#         all_rois = torch.cat(cluster_fibers)  # Concatenate all fiber ROIs\n",
    "#         unique_rois, counts = torch.unique(all_rois, return_counts=True)  # Count occurrences of each ROI\n",
    "\n",
    "#         # Compute the occurrence ratio\n",
    "#         fiber_count = len(cluster_fibers)  # Total number of fibers in this cluster\n",
    "#         roi_ratio = counts.float() / fiber_count  # Compute the proportion of fibers passing through each ROI\n",
    "\n",
    "#         # Select ROIs that meet the 40% threshold\n",
    "#         selected_rois = unique_rois[roi_ratio >= threshold]\n",
    "#         cluster_rois.append(selected_rois)\n",
    "\n",
    "#     return cluster_rois, cluster_fiber_counts\n",
    "\n",
    "# # Example data\n",
    "# num_of_class = NCLASS  # Total number of clusters\n",
    "# num_samples = 10000\n",
    "# x_train_sub = X_train[:num_samples, :, :]  # Select the first 1000 fibers\n",
    "# y_train_sub = y_train[:num_samples]  # Select the first 1000 fiber cluster labels\n",
    "\n",
    "# # Compute cluster-level ROI classification and fiber count\n",
    "# cluster_roi_classes, cluster_fiber_counts = compute_cluster_roi(x_train_sub, y_train_sub, num_of_class, threshold=0.1)\n",
    "\n",
    "# # Print cluster-level ROI classification results and fiber counts\n",
    "# print(\"\\n===== Cluster-Level ROI Classification and Fiber Count =====\")\n",
    "# for cluster_id, (rois, fiber_count) in enumerate(zip(cluster_roi_classes, cluster_fiber_counts)):\n",
    "#     print(f\"Cluster {cluster_id} (Valid Fiber Count: {fiber_count}): {rois.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11,  4, 12,  1, 13,  4,  4,  6,  6,  4], dtype=torch.int32)\n",
      "Fiber-Level Dice Loss: tensor([0.9167, 0.9930, 0.9708, 0.9062, 0.9836, 1.0000, 0.9930, 0.9930, 0.9861,\n",
      "        0.9723])\n",
      "tensor([367., 368., 438., 439., 441., 459., 460., 461., 480., 481., 483., 484.,\n",
      "        485., 486., 487., 488., 490., 491., 496., 497., 498., 499., 500., 501.,\n",
      "        502., 503., 506., 531., 534., 535., 536., 537., 539., 562., 563., 564.,\n",
      "        677., 680., 681., 683., 684., 685., 687., 688., 689., 692.])\n",
      "tensor([487., 692.])\n",
      "tensor(11, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_fiber_roi(fiber_data):\n",
    "    \"\"\"\n",
    "    Compute the unique ROI category numbers for each fiber, removing points where ROI = 0.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor of shape (b, 4, 100), where the last dimension represents ROI category labels.\n",
    "\n",
    "    Returns:\n",
    "        roi_list: List[Tensor], each element is a tensor containing the unique ROI category numbers for a fiber \n",
    "                  (duplicates removed, and 0 values excluded).\n",
    "    \"\"\"\n",
    "    roi_data = fiber_data[:, 3, :]  # Extract ROI dimension (b, 100)\n",
    "    roi_list = [torch.unique(roi[roi != 0]) for roi in roi_data]  # Compute unique ROIs\n",
    "    return roi_list\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "def dice_loss_fiber(fiber_data, fiber_pred, cluster_roi_true, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the fiber-level ROI Dice Loss based only on the predicted cluster.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor, shape (b, 4, 100), containing fiber ROI information.\n",
    "        fiber_pred: Tensor, shape (b,), model-predicted fiber cluster labels.\n",
    "        cluster_roi_true: List[Tensor], ground-truth ROI categories for each cluster (each cluster has one tensor).\n",
    "        smooth: float, a small value to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        dice_losses_per_batch: Tensor, shape (b,), containing Dice Loss for each batch element.\n",
    "    \"\"\"\n",
    "    fiber_rois = compute_fiber_roi(fiber_data)  # Compute ROI categories for each fiber\n",
    "    batch_size = fiber_data.shape[0]  # Get batch size\n",
    "    fiber_losses_per_batch = []\n",
    "\n",
    "    for batch_idx in range(batch_size):  # Iterate over each batch\n",
    "        ROI_fiber = fiber_rois[batch_idx]  # Fiber-level ROI\n",
    "        pred_cluster = fiber_pred[batch_idx].item()  # Model-predicted cluster\n",
    "        \n",
    "        # Get predicted cluster-level ROI\n",
    "        ROI_cluster_pred = cluster_roi_true[pred_cluster] if pred_cluster < len(cluster_roi_true) else torch.tensor([])\n",
    "\n",
    "        if ROI_fiber.numel() == 0 and ROI_cluster_pred.numel() == 0:\n",
    "            fiber_losses_per_batch.append(torch.tensor(0.0))  # If both are empty, loss = 0\n",
    "        elif ROI_fiber.numel() == 0 or ROI_cluster_pred.numel() == 0:\n",
    "            fiber_losses_per_batch.append(torch.tensor(1.0))  # If only one is empty, loss = 1\n",
    "        else:\n",
    "            # Compute Dice Loss based on fiber ROI and predicted cluster ROI\n",
    "            intersection = (ROI_fiber.unsqueeze(1) == ROI_cluster_pred.unsqueeze(0)).sum().float()\n",
    "            dice_score = (2. * intersection + smooth) / (ROI_fiber.numel() + ROI_cluster_pred.numel() + smooth)\n",
    "            fiber_losses_per_batch.append(1 - dice_score)  # 1 - Dice coefficient = Dice Loss\n",
    "\n",
    "    return torch.tensor(fiber_losses_per_batch)  # Shape: (b,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example data\n",
    "b = 2  # Number of fibers\n",
    "num_of_classes = 14  # Number of clusters\n",
    "num_points = 100  # Each fiber has 100 points\n",
    "\n",
    "# Generate fiber data (b, 4, 100) (last dimension represents ROI category)\n",
    "fiber_data = X_train[:10, :, :]  # ROI values range from 0 to 693\n",
    "# Generate predicted cluster labels for fibers\n",
    "fiber_pred = y_train[:10]\n",
    "print(fiber_pred)\n",
    "fiber_pred[0] = 11\n",
    "# Generate ground-truth ROI categories for each cluster (each cluster has one tensor)\n",
    "cluster_roi_true = cluster_roi_classes\n",
    "\n",
    "# Compute Dice Loss\n",
    "loss = dice_loss_fiber(fiber_data, fiber_pred, cluster_roi_true)\n",
    "fiber_rois_profile = compute_fiber_roi(fiber_data)\n",
    "print(f\"Fiber-Level Dice Loss: {loss}\")\n",
    "print(cluster_roi_true[11])\n",
    "print(fiber_rois_profile[0])\n",
    "print(fiber_pred[0])\n",
    "# 9: 0.9167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiber-Level Dice Loss: tensor([0.9000, 0.9942, 0.9861, 1.0000, 0.8667, 0.9971, 0.8769, 0.9792, 1.0000,\n",
      "        0.9853])\n",
      "tensor([ 23.,  24.,  96., 110., 111., 112., 113., 114., 115., 116., 117., 118.,\n",
      "        119., 120., 121., 122., 134., 135., 136., 137., 138., 139., 140., 145.,\n",
      "        146., 150., 151., 152., 153., 154., 155., 161., 182., 183., 185., 186.,\n",
      "        187., 188., 189., 190., 191., 192., 193., 194., 216., 219., 315., 316.,\n",
      "        317., 318., 319., 320., 332., 335., 336., 338., 339., 342., 343., 344.,\n",
      "        691.])\n",
      "tensor([ 2, 14,  6,  6,  0, 14,  1,  4,  3, 12], dtype=torch.int32)\n",
      "tensor([146., 152.])\n",
      "tensor(14, dtype=torch.int32)\n",
      "tensor(14, dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bohan\\AppData\\Local\\Temp\\ipykernel_24068\\427431408.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fiber_pred = torch.tensor(fiber_pred_gt)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_fiber_roi(fiber_data):\n",
    "    \"\"\"\n",
    "    Compute the unique ROI category numbers for each fiber, removing points where ROI = 0.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor of shape (b, 4, 100), where the last dimension represents ROI category labels.\n",
    "\n",
    "    Returns:\n",
    "        roi_list: List[Tensor], each element is a tensor containing the unique ROI category numbers for a fiber \n",
    "                  (duplicates removed, and 0 values excluded).\n",
    "    \"\"\"\n",
    "    roi_data = fiber_data[:, 3, :]  # Extract ROI dimension (b, 100)\n",
    "    roi_list = [torch.unique(roi[roi != 0]) for roi in roi_data]  # Compute unique ROIs\n",
    "    return roi_list\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "def dice_loss_fiber(fiber_data, fiber_pred, fiber_gt, cluster_roi_true, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the fiber-level ROI Dice Loss, considering fiber prediction correctness.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor, shape (b, 4, 100), containing fiber ROI information.\n",
    "        fiber_pred: Tensor, shape (b,), model-predicted fiber cluster labels.\n",
    "        fiber_gt: Tensor, shape (b,), ground-truth fiber cluster labels.\n",
    "        cluster_roi_true: List[Tensor], ground-truth ROI categories for each cluster (each cluster has one tensor).\n",
    "        smooth: float, a small value to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        dice_losses_per_batch: Tensor, shape (b,), containing Dice Loss for each batch element.\n",
    "    \"\"\"\n",
    "    fiber_rois = compute_fiber_roi(fiber_data)  # Compute ROI categories for each fiber\n",
    "    batch_size = fiber_data.shape[0]  # Get batch size\n",
    "    fiber_losses_per_batch = []\n",
    "\n",
    "    for batch_idx in range(batch_size):  # Iterate over each batch\n",
    "        ROI_fiber = fiber_rois[batch_idx]  # Fiber-level ROI\n",
    "        pred_cluster = fiber_pred[batch_idx].item()  # Predicted fiber cluster\n",
    "        gt_cluster = fiber_gt[batch_idx].item()  # Ground-truth fiber cluster\n",
    "        \n",
    "        ROI_cluster_pred = cluster_roi_true[pred_cluster] if pred_cluster < len(cluster_roi_true) else torch.tensor([])\n",
    "        ROI_cluster_gt = cluster_roi_true[gt_cluster] if gt_cluster < len(cluster_roi_true) else torch.tensor([])\n",
    "\n",
    "        if ROI_fiber.numel() == 0 and ROI_cluster_pred.numel() == 0:\n",
    "            fiber_losses_per_batch.append(torch.tensor(0.0))  # If both are empty, loss = 0\n",
    "        elif ROI_fiber.numel() == 0 or ROI_cluster_pred.numel() == 0:\n",
    "            fiber_losses_per_batch.append(torch.tensor(1.0))  # If only one is empty, loss = 1\n",
    "        else:\n",
    "            # 计算 ROI_fiber 与 cluster 预测的 ROI 之间的 Dice Loss\n",
    "            intersection = (ROI_fiber.unsqueeze(1) == ROI_cluster_pred.unsqueeze(0)).sum().float()\n",
    "            dice_score = (2. * intersection + smooth) / (ROI_fiber.numel() + ROI_cluster_pred.numel() + smooth)\n",
    "            dice_loss = 1 - dice_score  # 1 - Dice coefficient = Dice Loss\n",
    "\n",
    "            # 如果 fiber 分类错误，增加 loss 惩罚\n",
    "            if pred_cluster != gt_cluster:\n",
    "                dice_loss += 0.5  # 额外增加损失，惩罚错误分类\n",
    "            \n",
    "            fiber_losses_per_batch.append(dice_loss)\n",
    "\n",
    "    return torch.tensor(fiber_losses_per_batch)  # Shape: (b,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example data\n",
    "b = 2  # Number of fibers\n",
    "num_of_classes = 14  # Number of clusters\n",
    "num_points = 100  # Each fiber has 100 points\n",
    "\n",
    "# Generate fiber data (b, 4, 100) (last dimension represents ROI category)\n",
    "fiber_data = X_train[10:20, :, :]  # ROI values range from 0 to 693\n",
    "# Generate predicted cluster labels for fibers\n",
    "fiber_pred_gt = y_train[10:20]\n",
    "fiber_pred = torch.tensor(fiber_pred_gt)\n",
    "test_index = 1\n",
    "fiber_pred[test_index] = 14\n",
    "# Generate ground-truth ROI categories for each cluster (each cluster has one tensor)\n",
    "cluster_roi_true = cluster_roi_classes\n",
    "\n",
    "# Compute Dice Loss\n",
    "loss = dice_loss_fiber(fiber_data, fiber_pred, fiber_pred_gt, cluster_roi_true)\n",
    "fiber_rois_profile = compute_fiber_roi(fiber_data)\n",
    "print(f\"Fiber-Level Dice Loss: {loss}\")\n",
    "print(cluster_roi_true[test_index])\n",
    "print(fiber_pred_gt)\n",
    "print(fiber_rois_profile[test_index])\n",
    "print(fiber_pred[test_index])\n",
    "print(fiber_pred_gt[test_index])\n",
    "# 9: 0.9167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "\n",
    "kwargs = {}\n",
    "trn_set=utils.TensorDataset(X_train,y_train)\n",
    "trn_loader=utils.DataLoader(trn_set,batch_size=2,shuffle=True,**kwargs)\n",
    "\n",
    "# tst_set=utils.TensorDataset(X_test,y_test)\n",
    "# tst_loader=utils.DataLoader(tst_set,batch_size=2,shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tract_anatomical_profile(fiber_roi):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(fiber_roi, return_counts=True)\n",
    "    roi_profile = dict(zip(unique, counts / len(fiber_roi)))  # 计算占比\n",
    "    return roi_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 100])\n",
      "torch.Size([2, 4, 100])\n",
      "torch.Size([2, 1, 100])\n",
      "tensor([[[158., 158., 158.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0., 157., 157., 157., 157.,   0.,   0.,   0.,   0.,   0., 157.,\n",
      "          157.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.]],\n",
      "\n",
      "        [[505., 505., 505., 505., 505., 505., 505., 505., 505., 505., 505.,\n",
      "          505., 505., 505., 505., 505., 504., 504., 504., 504., 504., 504.,\n",
      "          504.,   0., 504., 504., 504.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0., 692., 692., 692., 692., 692., 692.,\n",
      "          692., 692., 692., 692., 692., 692., 692., 692., 692., 692., 692.,\n",
      "          692., 692., 692., 692., 692., 692., 692., 692., 692., 692., 692.,\n",
      "          692.]]])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx,(data,target) in enumerate(trn_loader):\n",
    "    # data = data[0]\n",
    "    # target = target[0]\n",
    "    print(data.shape)\n",
    "    print(data.shape)\n",
    "    print(data[:, 3:4, :].shape)\n",
    "    print(data[:, 3:4, :])\n",
    "    roi_profile = compute_tract_anatomical_profile(data[:, 3:4, :])\n",
    "    # print(roi_profile)\n",
    "    # print(target.shape)\n",
    "    # print(data)\n",
    "    # print(target)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d_bridge_condition_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
