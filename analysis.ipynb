{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def datato3d(arrays):#list of np arrays, NULL*3*100\n",
    "    output=list()\n",
    "    for i in arrays:\n",
    "        i=np.transpose(i,(0,2,1))\n",
    "        output.append(i)\n",
    "    return output\n",
    "\n",
    "\n",
    "def udflip(X_nparray, y_nparray, shuffle=True):\n",
    "\n",
    "    if X_nparray.shape[2] == 4:\n",
    "        if np.std(X_nparray[:, 0, :]) > np.std(X_nparray[:, -1, :]):\n",
    "            print(\"Detected special info in first column, swapping...\")\n",
    "            X_nparray = np.concatenate((X_nparray[:, 1:, :], X_nparray[:, 0:1, :]), axis=1)\n",
    "    \n",
    "    X_flipped = np.flip(X_nparray, axis=2)  \n",
    "\n",
    "    X_aug = np.vstack((X_nparray, X_flipped))\n",
    "    y_aug = np.hstack((y_nparray, y_nparray))  \n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_idx = np.random.permutation(X_aug.shape[0])\n",
    "        return X_aug[shuffle_idx], y_aug[shuffle_idx]\n",
    "    else:\n",
    "        return X_aug, y_aug\n",
    "\n",
    "with open('../data_61_26_ROIV2.pkl','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "\n",
    "\n",
    "dataList=datato3d([data['X_train'],data['X_test']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3496641, 100, 4), (1497440, 100, 4), (100, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'].shape, data['X_test'].shape,data['X_train'][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-50.86827  ,  -5.1718316, -11.912324 ,   0.       ],\n",
       "       [-50.886658 ,  -5.4194384, -11.963684 ,   0.       ],\n",
       "       [-50.911953 ,  -5.687157 , -12.018323 ,   0.       ],\n",
       "       [-50.926834 ,  -5.954355 , -12.07456  ,   0.       ],\n",
       "       [-50.913975 ,  -6.200402 , -12.130718 ,  20.       ],\n",
       "       [-50.85936  ,  -6.430222 , -12.192032 ,  20.       ],\n",
       "       [-50.769756 ,  -6.6747646, -12.26447  ,  20.       ],\n",
       "       [-50.662407 ,  -6.9200387, -12.3379   ,  20.       ],\n",
       "       [-50.554653 ,  -7.151108 , -12.401925 ,  20.       ],\n",
       "       [-50.4517   ,  -7.367921 , -12.4543   ,  20.       ],\n",
       "       [-50.331234 ,  -7.6009817, -12.509045 ,  20.       ],\n",
       "       [-50.201836 ,  -7.8392177, -12.557598 ,  20.       ],\n",
       "       [-50.074444 ,  -8.068485 , -12.589779 ,  20.       ],\n",
       "       [-49.95623  ,  -8.280725 , -12.597824 ,  20.       ],\n",
       "       [-49.827026 ,  -8.510864 , -12.589802 ,  20.       ],\n",
       "       [-49.689793 ,  -8.750706 , -12.565458 ,  20.       ],\n",
       "       [-49.55394  ,  -8.9807625, -12.522129 ,  20.       ],\n",
       "       [-49.428547 ,  -9.181544 , -12.457297 ,  20.       ],\n",
       "       [-49.29078  ,  -9.373226 , -12.362032 ,  20.       ],\n",
       "       [-49.1397   ,  -9.570057 , -12.238168 ,  20.       ],\n",
       "       [-48.997334 ,  -9.762211 , -12.096154 ,  20.       ],\n",
       "       [-48.885723 ,  -9.939861 , -11.946443 ,   0.       ],\n",
       "       [-48.816116 , -10.100949 , -11.783774 ,  20.       ],\n",
       "       [-48.767735 , -10.266159 , -11.580893 ,  20.       ],\n",
       "       [-48.735657 , -10.434408 , -11.36016  ,  20.       ],\n",
       "       [-48.716362 , -10.602713 , -11.146779 ,  20.       ],\n",
       "       [-48.70658  , -10.768736 , -10.964575 ,  20.       ],\n",
       "       [-48.709225 , -10.952564 , -10.787966 ,  20.       ],\n",
       "       [-48.72382  , -11.155451 , -10.605889 ,  20.       ],\n",
       "       [-48.74699  , -11.364614 , -10.428824 ,  20.       ],\n",
       "       [-48.775417 , -11.567281 , -10.267262 ,  20.       ],\n",
       "       [-48.809483 , -11.76266  , -10.125889 ,  20.       ],\n",
       "       [-48.85801  , -11.982917 ,  -9.986717 ,   0.       ],\n",
       "       [-48.914295 , -12.2149315,  -9.847743 ,   0.       ],\n",
       "       [-48.970177 , -12.440679 ,  -9.7093   ,   0.       ],\n",
       "       [-49.01751  , -12.64222  ,  -9.571656 ,   0.       ],\n",
       "       [-49.061634 , -12.835846 ,  -9.416056 ,   0.       ],\n",
       "       [-49.10787  , -13.0363   ,  -9.240161 ,   0.       ],\n",
       "       [-49.151714 , -13.237117 ,  -9.05889  ,   0.       ],\n",
       "       [-49.188705 , -13.431843 ,  -8.887161 ,   0.       ],\n",
       "       [-49.213554 , -13.618975 ,  -8.732718 ,   0.       ],\n",
       "       [-49.223083 , -13.822844 ,  -8.565083 ,   0.       ],\n",
       "       [-49.228058 , -14.038689 ,  -8.392146 ,  21.       ],\n",
       "       [-49.24076  , -14.255686 ,  -8.229966 ,  21.       ],\n",
       "       [-49.27348  , -14.46302  ,  -8.094593 ,  21.       ],\n",
       "       [-49.335632 , -14.674185 ,  -7.987565 ,   0.       ],\n",
       "       [-49.42278  , -14.909995 ,  -7.890837 ,   0.       ],\n",
       "       [-49.52378  , -15.152636 ,  -7.800441 ,   0.       ],\n",
       "       [-49.627407 , -15.384038 ,  -7.712535 ,   0.       ],\n",
       "       [-49.725113 , -15.590471 ,  -7.623116 ,   0.       ],\n",
       "       [-49.837795 , -15.806739 ,  -7.528829 ,   0.       ],\n",
       "       [-49.963135 , -16.031654 ,  -7.428169 ,  21.       ],\n",
       "       [-50.08912  , -16.248756 ,  -7.319421 ,  21.       ],\n",
       "       [-50.2037   , -16.441587 ,  -7.2008677,  21.       ],\n",
       "       [-50.30425  , -16.612165 ,  -7.0585895,  21.       ],\n",
       "       [-50.404205 , -16.78503  ,  -6.8785257,  21.       ],\n",
       "       [-50.5062   , -16.951378 ,  -6.680846 ,  21.       ],\n",
       "       [-50.612686 , -17.101582 ,  -6.486412 ,  21.       ],\n",
       "       [-50.727444 , -17.227957 ,  -6.312702 ,  21.       ],\n",
       "       [-50.864716 , -17.34879  ,  -6.1269946,  21.       ],\n",
       "       [-51.020916 , -17.464067 ,  -5.9296894,  21.       ],\n",
       "       [-51.18821  , -17.565393 ,  -5.7384996,  21.       ],\n",
       "       [-51.358795 , -17.644371 ,  -5.5711446,  21.       ],\n",
       "       [-51.54813  , -17.701433 ,  -5.426265 ,  21.       ],\n",
       "       [-51.774044 , -17.74564  ,  -5.2838264,  21.       ],\n",
       "       [-52.013245 , -17.775797 ,  -5.145474 ,  21.       ],\n",
       "       [-52.24209  , -17.79063  ,  -5.013077 ,  21.       ],\n",
       "       [-52.4487   , -17.78935  ,  -4.8835874,  21.       ],\n",
       "       [-52.672024 , -17.773352 ,  -4.739139 ,  21.       ],\n",
       "       [-52.903187 , -17.741438 ,  -4.5888767,  21.       ],\n",
       "       [-53.1252   , -17.69195  ,  -4.445495 ,  21.       ],\n",
       "       [-53.322712 , -17.62286  ,  -4.320688 ,  21.       ],\n",
       "       [-53.527004 , -17.524061 ,  -4.196682 ,  21.       ],\n",
       "       [-53.740143 , -17.397474 ,  -4.069832 ,  21.       ],\n",
       "       [-53.94072  , -17.25094  ,  -3.950089 ,   0.       ],\n",
       "       [-54.107346 , -17.092297 ,  -3.8474076,   0.       ],\n",
       "       [-54.24146  , -16.90885  ,  -3.7622333,   0.       ],\n",
       "       [-54.367554 , -16.682287 ,  -3.6816769,   0.       ],\n",
       "       [-54.477703 , -16.435705 ,  -3.6056905,   0.       ],\n",
       "       [-54.563416 , -16.192774 ,  -3.5344903,   0.       ],\n",
       "       [-54.61615  , -15.967454 ,  -3.4665868,   0.       ],\n",
       "       [-54.63784  , -15.717778 ,  -3.3924131,   0.       ],\n",
       "       [-54.64154  , -15.451428 ,  -3.3166416,   0.       ],\n",
       "       [-54.640373 , -15.187297 ,  -3.2466376,   0.       ],\n",
       "       [-54.647457 , -14.943955 ,  -3.189658 ,   0.       ],\n",
       "       [-54.663616 , -14.694769 ,  -3.1353052,   0.       ],\n",
       "       [-54.68254  , -14.426131 ,  -3.0807216,   0.       ],\n",
       "       [-54.703453 , -14.155595 ,  -3.0369964,   0.       ],\n",
       "       [-54.725605 , -13.90072  ,  -3.015222 ,   0.       ],\n",
       "       [-54.749928 , -13.66024  ,  -3.0261369,   0.       ],\n",
       "       [-54.77952  , -13.399671 ,  -3.0685139,   0.       ],\n",
       "       [-54.81238  , -13.1325655,  -3.12998  ,   0.       ],\n",
       "       [-54.846252 , -12.8751545,  -3.1978424,   0.       ],\n",
       "       [-54.879627 , -12.638925 ,  -3.2622478,   0.       ],\n",
       "       [-54.91942  , -12.378534 ,  -3.346464 ,   0.       ],\n",
       "       [-54.963654 , -12.104484 ,  -3.4426537,   0.       ],\n",
       "       [-55.006817 , -11.849942 ,  -3.5303628,   0.       ],\n",
       "       [-55.043434 , -11.648093 ,  -3.5891414,   0.       ],\n",
       "       [-55.10965  , -11.363186 ,  -3.6119215,   0.       ],\n",
       "       [-55.170914 , -11.140897 ,  -3.5951705,   0.       ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=dataList[0]\n",
    "X_test=dataList[1]\n",
    "# X_train, y_train = X_train[:, :, ::5], data['y_train'][:]\n",
    "# X_test, y_test = X_test[:, :, ::5], data['y_test'][:]\n",
    "X_train, y_train = X_train[:, :, ::1], data['y_train'][:]\n",
    "X_test, y_test = X_test[:, :, ::1], data['y_test'][:]\n",
    "\n",
    "y_test_list=data['y_test'].tolist()\n",
    "\n",
    "NCLASS=max(y_test_list)+1\n",
    "\n",
    "X_train,y_train=udflip(X_train,y_train,shuffle=True)\n",
    "X_test,y_test=udflip(X_test,y_test,shuffle=False)\n",
    "\n",
    "X_train=torch.from_numpy(X_train)#data['X_train'])\n",
    "y_train=torch.from_numpy(y_train.astype(np.int32))#data['y_train'])\n",
    "\n",
    "X_test=torch.from_numpy(X_test)\n",
    "y_test=torch.from_numpy(y_test.astype(np.int32))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n",
      "X_train_shape torch.Size([6993282, 4, 100])\n",
      "X_test_shape torch.Size([2994880, 4, 100])\n",
      "classes:  15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "del data,dataList\n",
    "gc.collect()\n",
    "print('data loaded!')\n",
    "print('X_train_shape',X_train.size())\n",
    "print('X_test_shape',X_test.size())\n",
    "print('classes: ', NCLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6993282, 4, 100]),\n",
       " torch.Size([10, 4, 100]),\n",
       " torch.Size([6993282]),\n",
       " torch.Size([10]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train[10:20,:,:].shape, y_train.shape, y_train[10:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.6134e+00,  5.5451e+00,  5.4695e+00,  5.3871e+00,  5.2896e+00,\n",
       "           5.1976e+00,  5.0953e+00,  4.9927e+00,  4.8789e+00,  4.7589e+00,\n",
       "           4.7117e+00,  4.7528e+00,  4.7736e+00,  4.6980e+00,  4.5677e+00,\n",
       "           4.4205e+00,  4.2166e+00,  4.0195e+00,  3.8679e+00,  3.7294e+00,\n",
       "           3.6422e+00,  3.6066e+00,  3.5814e+00,  3.5264e+00,  3.4558e+00,\n",
       "           3.4306e+00,  3.4855e+00,  3.5548e+00,  3.5647e+00,  3.5325e+00,\n",
       "           3.5045e+00,  3.4975e+00,  3.4921e+00,  3.4727e+00,  3.4384e+00,\n",
       "           3.4032e+00,  3.3698e+00,  3.3308e+00,  3.2819e+00,  3.2168e+00,\n",
       "           3.1397e+00,  3.0320e+00,  2.9084e+00,  2.8055e+00,  2.7003e+00,\n",
       "           2.6153e+00,  2.5625e+00,  2.5166e+00,  2.4469e+00,  2.3434e+00,\n",
       "           2.2620e+00,  2.2190e+00,  2.1967e+00,  2.2008e+00,  2.2340e+00,\n",
       "           2.2581e+00,  2.2547e+00,  2.2416e+00,  2.2327e+00,  2.2255e+00,\n",
       "           2.2114e+00,  2.1735e+00,  2.1309e+00,  2.1273e+00,  2.1619e+00,\n",
       "           2.1907e+00,  2.1935e+00,  2.1848e+00,  2.1663e+00,  2.1307e+00,\n",
       "           2.1081e+00,  2.1119e+00,  2.1351e+00,  2.1878e+00,  2.2814e+00,\n",
       "           2.3752e+00,  2.4621e+00,  2.5485e+00,  2.5997e+00,  2.6163e+00,\n",
       "           2.6438e+00,  2.7083e+00,  2.8016e+00,  2.9287e+00,  3.1179e+00,\n",
       "           3.2975e+00,  3.4399e+00,  3.5745e+00,  3.6920e+00,  3.8071e+00,\n",
       "           3.9342e+00,  4.1031e+00,  4.2955e+00,  4.4656e+00,  4.6469e+00,\n",
       "           4.8195e+00,  5.0080e+00,  5.1975e+00,  5.3907e+00,  5.5892e+00],\n",
       "         [ 8.8620e+00,  8.4270e+00,  7.9743e+00,  7.5632e+00,  7.1139e+00,\n",
       "           6.7004e+00,  6.2520e+00,  5.8137e+00,  5.3928e+00,  4.9433e+00,\n",
       "           4.5241e+00,  4.0612e+00,  3.6139e+00,  3.1983e+00,  2.7620e+00,\n",
       "           2.3682e+00,  1.9539e+00,  1.5455e+00,  1.1369e+00,  6.8961e-01,\n",
       "           2.7773e-01, -1.6486e-01, -6.0168e-01, -1.0014e+00, -1.4278e+00,\n",
       "          -1.8255e+00, -2.2491e+00, -2.6837e+00, -3.0965e+00, -3.5559e+00,\n",
       "          -3.9881e+00, -4.4301e+00, -4.8873e+00, -5.3115e+00, -5.7764e+00,\n",
       "          -6.2142e+00, -6.6547e+00, -7.1111e+00, -7.5322e+00, -7.9923e+00,\n",
       "          -8.4249e+00, -8.8574e+00, -9.3048e+00, -9.7168e+00, -1.0165e+01,\n",
       "          -1.0593e+01, -1.1035e+01, -1.1497e+01, -1.1916e+01, -1.2367e+01,\n",
       "          -1.2794e+01, -1.3234e+01, -1.3693e+01, -1.4117e+01, -1.4580e+01,\n",
       "          -1.5018e+01, -1.5461e+01, -1.5922e+01, -1.6337e+01, -1.6781e+01,\n",
       "          -1.7203e+01, -1.7632e+01, -1.8085e+01, -1.8505e+01, -1.8970e+01,\n",
       "          -1.9403e+01, -1.9815e+01, -2.0233e+01, -2.0599e+01, -2.0972e+01,\n",
       "          -2.1339e+01, -2.1744e+01, -2.2185e+01, -2.2582e+01, -2.3012e+01,\n",
       "          -2.3408e+01, -2.3771e+01, -2.4132e+01, -2.4436e+01, -2.4728e+01,\n",
       "          -2.5006e+01, -2.5289e+01, -2.5596e+01, -2.5899e+01, -2.6251e+01,\n",
       "          -2.6607e+01, -2.6991e+01, -2.7416e+01, -2.7808e+01, -2.8244e+01,\n",
       "          -2.8640e+01, -2.8990e+01, -2.9335e+01, -2.9648e+01, -2.9982e+01,\n",
       "          -3.0286e+01, -3.0599e+01, -3.0896e+01, -3.1142e+01, -3.1346e+01],\n",
       "         [ 2.8947e+01,  2.8948e+01,  2.8968e+01,  2.9054e+01,  2.9179e+01,\n",
       "           2.9260e+01,  2.9303e+01,  2.9337e+01,  2.9390e+01,  2.9447e+01,\n",
       "           2.9462e+01,  2.9436e+01,  2.9382e+01,  2.9279e+01,  2.9147e+01,\n",
       "           2.9087e+01,  2.9110e+01,  2.9141e+01,  2.9135e+01,  2.9111e+01,\n",
       "           2.9049e+01,  2.8933e+01,  2.8793e+01,  2.8639e+01,  2.8451e+01,\n",
       "           2.8287e+01,  2.8130e+01,  2.7985e+01,  2.7883e+01,  2.7802e+01,\n",
       "           2.7731e+01,  2.7650e+01,  2.7573e+01,  2.7533e+01,  2.7521e+01,\n",
       "           2.7497e+01,  2.7429e+01,  2.7349e+01,  2.7292e+01,  2.7243e+01,\n",
       "           2.7217e+01,  2.7223e+01,  2.7252e+01,  2.7302e+01,  2.7387e+01,\n",
       "           2.7442e+01,  2.7435e+01,  2.7398e+01,  2.7353e+01,  2.7285e+01,\n",
       "           2.7220e+01,  2.7156e+01,  2.7092e+01,  2.7038e+01,  2.6986e+01,\n",
       "           2.6935e+01,  2.6886e+01,  2.6827e+01,  2.6731e+01,  2.6584e+01,\n",
       "           2.6449e+01,  2.6343e+01,  2.6246e+01,  2.6173e+01,  2.6120e+01,\n",
       "           2.6038e+01,  2.5878e+01,  2.5669e+01,  2.5449e+01,  2.5168e+01,\n",
       "           2.4922e+01,  2.4748e+01,  2.4594e+01,  2.4446e+01,  2.4287e+01,\n",
       "           2.4107e+01,  2.3870e+01,  2.3583e+01,  2.3290e+01,  2.2930e+01,\n",
       "           2.2582e+01,  2.2249e+01,  2.1908e+01,  2.1640e+01,  2.1394e+01,\n",
       "           2.1188e+01,  2.1028e+01,  2.0889e+01,  2.0766e+01,  2.0647e+01,\n",
       "           2.0503e+01,  2.0291e+01,  2.0038e+01,  1.9799e+01,  1.9527e+01,\n",
       "           1.9263e+01,  1.8971e+01,  1.8674e+01,  1.8365e+01,  1.8041e+01],\n",
       "         [ 6.5900e+02,  6.5900e+02,  6.5900e+02,  6.5900e+02,  6.5900e+02,\n",
       "           6.5900e+02,  6.5900e+02,  6.5900e+02,  6.5900e+02,  6.5900e+02,\n",
       "           6.5900e+02,  6.5900e+02,  6.5900e+02,  6.5900e+02,  6.5900e+02,\n",
       "           6.5900e+02,  0.0000e+00,  0.0000e+00,  6.6000e+02,  6.6000e+02,\n",
       "           6.6000e+02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]),\n",
       " tensor(14, dtype=torch.int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[14], y_train[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiber 1: [691.0] cluster: 0\n",
      "Fiber 2: [113.0, 114.0, 117.0, 134.0] cluster: 14\n",
      "Fiber 3: [390.0, 395.0, 629.0] cluster: 13\n",
      "Fiber 4: [31.0, 37.0, 38.0] cluster: 5\n",
      "Fiber 5: [248.0, 255.0] cluster: 14\n",
      "Fiber 6: [287.0, 325.0] cluster: 4\n",
      "Fiber 7: [31.0] cluster: 3\n",
      "Fiber 8: [186.0, 191.0, 691.0] cluster: 1\n",
      "Fiber 9: [566.0] cluster: 14\n",
      "Fiber 10: [255.0] cluster: 14\n",
      "Fiber 11: [481.0, 496.0, 683.0, 692.0] cluster: 10\n",
      "Fiber 12: [497.0, 692.0] cluster: 10\n",
      "Fiber 13: [500.0, 692.0] cluster: 11\n",
      "Fiber 14: [139.0, 140.0, 141.0, 142.0] cluster: 14\n",
      "Fiber 15: [659.0, 660.0] cluster: 14\n",
      "Fiber 16: [691.0] cluster: 3\n",
      "Fiber 17: [45.0, 49.0, 50.0, 283.0, 284.0] cluster: 4\n",
      "Fiber 18: [376.0, 382.0] cluster: 14\n",
      "Fiber 19: [207.0] cluster: 6\n",
      "Fiber 20: [394.0, 627.0] cluster: 12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_fiber_roi(fiber_data):\n",
    "    \"\"\"\n",
    "    Compute the unique ROI classification for each fiber, removing ROI values of 0.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor of shape (b, 4, 100), where the last dimension represents ROI classification.\n",
    "\n",
    "    Returns:\n",
    "        roi_list: List[Tensor], each element contains a fiber's unique ROI classifications (deduplicated, excluding 0).\n",
    "    \"\"\"\n",
    "    # Extract ROI classification data (b, 100)\n",
    "    roi_data = fiber_data[:, 3, :]\n",
    "\n",
    "    # Remove 0 and get unique ROI classifications\n",
    "    roi_list = [torch.unique(roi[roi != 0]) for roi in roi_data]\n",
    "\n",
    "    return roi_list\n",
    "\n",
    "# Example data\n",
    "b, num_points = 5, 100  # 5 fibers, each with 100 points\n",
    "fiber_data = X_train[:20, :, :]  # Extract ROI classifications\n",
    "labels = y_train[:20]\n",
    "\n",
    "# Compute ROI classifications for each fiber\n",
    "fiber_rois = compute_fiber_roi(fiber_data)\n",
    "\n",
    "# Print results\n",
    "for i, rois in enumerate(fiber_rois):\n",
    "    print(f\"Fiber {i + 1}: {rois.tolist()} cluster: {labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cluster-Level ROI Classification =====\n",
      "Cluster 0: [20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 100.0, 101.0, 116.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 214.0, 215.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 324.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 691.0]\n",
      "Cluster 1: [23.0, 24.0, 96.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 145.0, 146.0, 151.0, 152.0, 153.0, 154.0, 155.0, 161.0, 178.0, 182.0, 183.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 219.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 344.0, 691.0]\n",
      "Cluster 2: [23.0, 92.0, 93.0, 94.0, 96.0, 114.0, 115.0, 116.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 146.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 161.0, 189.0, 190.0, 194.0, 214.0, 215.0, 217.0, 218.0, 219.0, 335.0, 338.0, 339.0, 342.0, 343.0, 344.0, 691.0]\n",
      "Cluster 3: [1.0, 6.0, 10.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 75.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 98.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 239.0, 240.0, 241.0, 244.0, 248.0, 249.0, 250.0, 251.0, 254.0, 255.0, 256.0, 260.0, 264.0, 265.0, 269.0, 273.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 299.0, 300.0, 302.0, 303.0, 304.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 364.0, 365.0, 367.0, 368.0, 369.0, 371.0, 372.0, 374.0, 375.0, 379.0, 396.0, 399.0, 400.0, 403.0, 404.0, 413.0, 418.0, 430.0, 433.0, 436.0, 441.0, 447.0, 450.0, 455.0, 456.0, 460.0, 461.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 491.0, 492.0, 493.0, 495.0, 496.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 506.0, 507.0, 511.0, 512.0, 513.0, 514.0, 515.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 543.0, 544.0, 545.0, 547.0, 548.0, 549.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 559.0, 561.0, 562.0, 563.0, 564.0, 565.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 585.0, 589.0, 592.0, 593.0, 596.0, 599.0, 600.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 670.0, 671.0, 674.0, 677.0, 680.0, 681.0, 683.0, 687.0, 688.0, 691.0, 692.0]\n",
      "Cluster 4: [1.0, 2.0, 6.0, 8.0, 10.0, 11.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 133.0, 141.0, 142.0, 143.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 155.0, 156.0, 157.0, 158.0, 159.0, 161.0, 173.0, 176.0, 177.0, 178.0, 179.0, 181.0, 182.0, 183.0, 185.0, 186.0, 189.0, 190.0, 196.0, 197.0, 199.0, 200.0, 201.0, 204.0, 206.0, 207.0, 208.0, 210.0, 211.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 240.0, 249.0, 264.0, 269.0, 273.0, 279.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 309.0, 314.0, 315.0, 316.0, 317.0, 318.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 337.0, 338.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 365.0, 367.0, 368.0, 369.0, 370.0, 374.0, 375.0, 376.0, 379.0, 386.0, 387.0, 390.0, 394.0, 396.0, 397.0, 399.0, 400.0, 402.0, 403.0, 404.0, 405.0, 406.0, 415.0, 416.0, 433.0, 436.0, 447.0, 450.0, 455.0, 456.0, 460.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 485.0, 503.0, 559.0, 561.0, 564.0, 629.0, 660.0, 663.0, 664.0, 665.0, 666.0, 667.0, 669.0, 670.0, 688.0, 691.0]\n",
      "Cluster 5: [1.0, 6.0, 10.0, 11.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 76.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 190.0, 191.0, 192.0, 194.0, 196.0, 198.0, 199.0, 200.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 240.0, 244.0, 248.0, 255.0, 273.0, 276.0, 277.0, 282.0, 283.0, 284.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 294.0, 298.0, 299.0, 300.0, 301.0, 303.0, 304.0, 309.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 337.0, 338.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 374.0, 379.0, 386.0, 392.0, 397.0, 400.0, 430.0, 433.0, 434.0, 436.0, 441.0, 447.0, 450.0, 454.0, 455.0, 456.0, 459.0, 460.0, 462.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 484.0, 485.0, 486.0, 495.0, 498.0, 500.0, 501.0, 502.0, 506.0, 507.0, 511.0, 515.0, 519.0, 520.0, 522.0, 523.0, 526.0, 527.0, 530.0, 531.0, 535.0, 536.0, 548.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 561.0, 564.0, 565.0, 567.0, 572.0, 573.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 677.0, 680.0, 688.0, 689.0, 691.0]\n",
      "Cluster 6: [19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 42.0, 43.0, 44.0, 45.0, 49.0, 50.0, 55.0, 58.0, 59.0, 66.0, 68.0, 70.0, 71.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 119.0, 120.0, 121.0, 125.0, 126.0, 129.0, 130.0, 133.0, 134.0, 135.0, 136.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 165.0, 166.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 248.0, 249.0, 251.0, 254.0, 255.0, 256.0, 269.0, 273.0, 282.0, 283.0, 284.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 325.0, 329.0, 330.0, 332.0, 333.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 342.0, 343.0, 447.0, 455.0, 456.0, 459.0, 460.0, 461.0, 465.0, 471.0, 475.0, 479.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 491.0, 493.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 503.0, 506.0, 507.0, 511.0, 518.0, 519.0, 520.0, 522.0, 523.0, 524.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 543.0, 544.0, 545.0, 547.0, 548.0, 549.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 559.0, 561.0, 564.0, 565.0, 566.0, 567.0, 570.0, 572.0, 573.0, 596.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 677.0, 680.0, 681.0, 683.0, 691.0, 692.0]\n",
      "Cluster 7: [1.0, 14.0, 16.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 88.0, 89.0, 91.0, 121.0, 127.0, 128.0, 129.0, 130.0, 131.0, 133.0, 195.0, 223.0, 225.0, 228.0, 273.0, 274.0, 275.0, 276.0, 279.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 691.0]\n",
      "Cluster 8: [1.0, 6.0, 10.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 88.0, 91.0, 109.0, 273.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 324.0, 325.0, 326.0, 327.0, 328.0, 330.0, 331.0, 334.0, 336.0, 337.0, 342.0, 343.0, 344.0, 345.0, 691.0]\n",
      "Cluster 9: [366.0, 367.0, 368.0, 369.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 445.0, 446.0, 461.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 559.0, 560.0, 562.0, 563.0, 564.0, 565.0, 566.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0]\n",
      "Cluster 10: [358.0, 366.0, 367.0, 368.0, 369.0, 441.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 462.0, 463.0, 464.0, 466.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 490.0, 491.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 506.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 561.0, 564.0, 661.0, 662.0, 663.0, 664.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0]\n",
      "Cluster 11: [367.0, 368.0, 438.0, 439.0, 441.0, 459.0, 460.0, 461.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 490.0, 491.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 506.0, 531.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 559.0, 562.0, 563.0, 564.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0]\n",
      "Cluster 12: [346.0, 351.0, 355.0, 356.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 399.0, 400.0, 402.0, 403.0, 404.0, 405.0, 407.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 433.0, 434.0, 435.0, 436.0, 450.0, 453.0, 454.0, 466.0, 472.0, 473.0, 474.0, 475.0, 478.0, 569.0, 571.0, 614.0, 618.0, 619.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 681.0, 682.0, 683.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0]\n",
      "Cluster 13: [346.0, 347.0, 351.0, 355.0, 359.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 403.0, 404.0, 405.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 436.0, 441.0, 454.0, 490.0, 491.0, 544.0, 568.0, 569.0, 571.0, 574.0, 575.0, 589.0, 614.0, 617.0, 618.0, 621.0, 622.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 654.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0]\n",
      "Cluster 14: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 582.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 601.0, 602.0, 603.0, 604.0, 605.0, 606.0, 607.0, 608.0, 609.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 621.0, 622.0, 623.0, 624.0, 625.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 640.0, 641.0, 642.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 650.0, 651.0, 652.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 691.0, 692.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_cluster_roi(X_train, y_train, num_of_class, threshold=0.00000000002):\n",
    "    \"\"\"\n",
    "    Compute ROI classification for each cluster based on the rule that 40% of fibers pass through an ROI (ignoring 0).\n",
    "    Also, print the ROI each fiber passes through along with its corresponding cluster.\n",
    "\n",
    "    Parameters:\n",
    "        X_train: Tensor, shape (b, 4, 100), where the 4th dimension represents ROI classification.\n",
    "        y_train: Tensor, shape (b,), containing each fiber's cluster label.\n",
    "        num_of_class: int, total number of clusters.\n",
    "        threshold: float, threshold setting (default is 0.4, i.e., 40%).\n",
    "\n",
    "    Returns:\n",
    "        cluster_rois: List[Tensor], each element contains the ROI classification of the cluster (deduplicated & filtered by threshold).\n",
    "    \"\"\"\n",
    "    # Extract fiber ROI classification information (b, 100)\n",
    "    roi_data = X_train[:, 3, :]\n",
    "\n",
    "    # Compute unique ROI classifications for each fiber (remove duplicates & ignore 0)\n",
    "    fiber_rois = [torch.unique(roi[roi != 0]) for roi in roi_data]\n",
    "    # Compute ROI for each cluster\n",
    "    cluster_rois = []\n",
    "    for cluster_id in range(num_of_class):\n",
    "        # Get fibers belonging to the current cluster\n",
    "        cluster_fibers = [fiber_rois[i] for i in range(len(y_train)) if y_train[i] == cluster_id]\n",
    "\n",
    "        if not cluster_fibers:  # If no fibers belong to this cluster, skip\n",
    "            cluster_rois.append(torch.tensor([]))\n",
    "            continue\n",
    "\n",
    "        # Aggregate all ROI classifications from fibers\n",
    "        all_rois = torch.cat(cluster_fibers)  # Concatenate all fiber ROIs\n",
    "        unique_rois, counts = torch.unique(all_rois, return_counts=True)  # Count occurrences of each ROI\n",
    "\n",
    "        # Compute the occurrence ratio\n",
    "        fiber_count = len(cluster_fibers)  # Total number of fibers in this cluster\n",
    "        roi_ratio = counts.float() / fiber_count  # Compute the proportion of fibers passing through each ROI\n",
    "\n",
    "        # Select ROIs that meet the 40% threshold\n",
    "        selected_rois = unique_rois[roi_ratio >= threshold]\n",
    "        cluster_rois.append(selected_rois)\n",
    "\n",
    "    return cluster_rois\n",
    "\n",
    "# Example data\n",
    "num_of_class = NCLASS  # Total number of clusters\n",
    "num_samples = 1000000\n",
    "x_train_sub = X_train[:num_samples, :, :]  # Select the first 100 fibers\n",
    "y_train_sub = y_train[:num_samples]  # Select the first 100 fiber cluster labels\n",
    "\n",
    "# Compute cluster-level ROI classification\n",
    "cluster_roi_classes = compute_cluster_roi(x_train_sub, y_train_sub, num_of_class)\n",
    "\n",
    "# Print cluster-level ROI classification results\n",
    "print(\"\\n===== Cluster-Level ROI Classification =====\")\n",
    "for cluster_id, rois in enumerate(cluster_roi_classes):\n",
    "    print(f\"Cluster {cluster_id}: {rois.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cluster-Level ROI Classification =====\n",
      "Cluster 0: [20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 100.0, 101.0, 116.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 214.0, 215.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 324.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 691.0], size 47\n",
      "Cluster 1: [23.0, 24.0, 96.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 145.0, 146.0, 151.0, 152.0, 153.0, 154.0, 155.0, 161.0, 178.0, 182.0, 183.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 219.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 335.0, 336.0, 338.0, 339.0, 342.0, 343.0, 344.0, 691.0], size 60\n",
      "Cluster 2: [23.0, 92.0, 93.0, 94.0, 96.0, 114.0, 115.0, 116.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 146.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 161.0, 189.0, 190.0, 194.0, 214.0, 215.0, 217.0, 218.0, 219.0, 335.0, 338.0, 339.0, 342.0, 343.0, 344.0, 691.0], size 38\n",
      "Cluster 3: [1.0, 6.0, 10.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 75.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 98.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 239.0, 240.0, 241.0, 244.0, 248.0, 249.0, 250.0, 251.0, 254.0, 255.0, 256.0, 260.0, 264.0, 265.0, 269.0, 273.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 299.0, 300.0, 302.0, 303.0, 304.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 364.0, 365.0, 367.0, 368.0, 369.0, 371.0, 372.0, 374.0, 375.0, 379.0, 396.0, 399.0, 400.0, 403.0, 404.0, 413.0, 418.0, 430.0, 433.0, 436.0, 441.0, 447.0, 450.0, 455.0, 456.0, 460.0, 461.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 491.0, 492.0, 493.0, 495.0, 496.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 506.0, 507.0, 511.0, 512.0, 513.0, 514.0, 515.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 543.0, 544.0, 545.0, 547.0, 548.0, 549.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 559.0, 561.0, 562.0, 563.0, 564.0, 565.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 585.0, 589.0, 592.0, 593.0, 596.0, 599.0, 600.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 670.0, 671.0, 674.0, 677.0, 680.0, 681.0, 683.0, 687.0, 688.0, 691.0, 692.0], size 402\n",
      "Cluster 4: [1.0, 2.0, 6.0, 8.0, 10.0, 11.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 133.0, 141.0, 142.0, 143.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 155.0, 156.0, 157.0, 158.0, 159.0, 161.0, 173.0, 176.0, 177.0, 178.0, 179.0, 181.0, 182.0, 183.0, 185.0, 186.0, 189.0, 190.0, 196.0, 197.0, 199.0, 200.0, 201.0, 204.0, 206.0, 207.0, 208.0, 210.0, 211.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 240.0, 249.0, 264.0, 269.0, 273.0, 279.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 309.0, 314.0, 315.0, 316.0, 317.0, 318.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 337.0, 338.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 365.0, 367.0, 368.0, 369.0, 370.0, 374.0, 375.0, 376.0, 379.0, 386.0, 387.0, 390.0, 394.0, 396.0, 397.0, 399.0, 400.0, 402.0, 403.0, 404.0, 405.0, 406.0, 415.0, 416.0, 433.0, 436.0, 447.0, 450.0, 455.0, 456.0, 460.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 485.0, 503.0, 559.0, 561.0, 564.0, 629.0, 660.0, 663.0, 664.0, 665.0, 666.0, 667.0, 669.0, 670.0, 688.0, 691.0], size 284\n",
      "Cluster 5: [1.0, 6.0, 10.0, 11.0, 14.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 76.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 125.0, 126.0, 128.0, 129.0, 130.0, 131.0, 133.0, 134.0, 135.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 190.0, 191.0, 192.0, 194.0, 196.0, 198.0, 199.0, 200.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 240.0, 244.0, 248.0, 255.0, 273.0, 276.0, 277.0, 282.0, 283.0, 284.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 294.0, 298.0, 299.0, 300.0, 301.0, 303.0, 304.0, 309.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 337.0, 338.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 374.0, 379.0, 386.0, 392.0, 397.0, 400.0, 430.0, 433.0, 434.0, 436.0, 441.0, 447.0, 450.0, 454.0, 455.0, 456.0, 459.0, 460.0, 462.0, 464.0, 465.0, 466.0, 467.0, 470.0, 471.0, 473.0, 474.0, 475.0, 478.0, 479.0, 480.0, 484.0, 485.0, 486.0, 495.0, 498.0, 500.0, 501.0, 502.0, 506.0, 507.0, 511.0, 515.0, 519.0, 520.0, 522.0, 523.0, 526.0, 527.0, 530.0, 531.0, 535.0, 536.0, 548.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 561.0, 564.0, 565.0, 567.0, 572.0, 573.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 677.0, 680.0, 688.0, 689.0, 691.0], size 333\n",
      "Cluster 6: [19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 35.0, 36.0, 37.0, 38.0, 39.0, 42.0, 43.0, 44.0, 45.0, 49.0, 50.0, 55.0, 58.0, 59.0, 66.0, 68.0, 70.0, 71.0, 85.0, 86.0, 87.0, 88.0, 89.0, 91.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 114.0, 115.0, 116.0, 119.0, 120.0, 121.0, 125.0, 126.0, 129.0, 130.0, 133.0, 134.0, 135.0, 136.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 165.0, 166.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 248.0, 249.0, 251.0, 254.0, 255.0, 256.0, 269.0, 273.0, 282.0, 283.0, 284.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 325.0, 329.0, 330.0, 332.0, 333.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 342.0, 343.0, 447.0, 455.0, 456.0, 459.0, 460.0, 461.0, 465.0, 471.0, 475.0, 479.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 491.0, 493.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 503.0, 506.0, 507.0, 511.0, 518.0, 519.0, 520.0, 522.0, 523.0, 524.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 543.0, 544.0, 545.0, 547.0, 548.0, 549.0, 551.0, 552.0, 553.0, 555.0, 556.0, 558.0, 559.0, 561.0, 564.0, 565.0, 566.0, 567.0, 570.0, 572.0, 573.0, 596.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 677.0, 680.0, 681.0, 683.0, 691.0, 692.0], size 284\n",
      "Cluster 7: [1.0, 14.0, 16.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 88.0, 89.0, 91.0, 121.0, 127.0, 128.0, 129.0, 130.0, 131.0, 133.0, 195.0, 223.0, 225.0, 228.0, 273.0, 274.0, 275.0, 276.0, 279.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 339.0, 341.0, 342.0, 343.0, 344.0, 345.0, 691.0], size 123\n",
      "Cluster 8: [1.0, 6.0, 10.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 55.0, 58.0, 59.0, 60.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 88.0, 91.0, 109.0, 273.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 296.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 324.0, 325.0, 326.0, 327.0, 328.0, 330.0, 331.0, 334.0, 336.0, 337.0, 342.0, 343.0, 344.0, 345.0, 691.0], size 100\n",
      "Cluster 9: [366.0, 367.0, 368.0, 369.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 445.0, 446.0, 461.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 559.0, 560.0, 562.0, 563.0, 564.0, 565.0, 566.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0], size 45\n",
      "Cluster 10: [358.0, 366.0, 367.0, 368.0, 369.0, 441.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 462.0, 463.0, 464.0, 466.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 490.0, 491.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 506.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 561.0, 564.0, 661.0, 662.0, 663.0, 664.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0], size 64\n",
      "Cluster 11: [367.0, 368.0, 438.0, 439.0, 441.0, 459.0, 460.0, 461.0, 480.0, 481.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 490.0, 491.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 506.0, 531.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 559.0, 562.0, 563.0, 564.0, 677.0, 680.0, 681.0, 683.0, 684.0, 685.0, 687.0, 688.0, 689.0, 692.0], size 48\n",
      "Cluster 12: [346.0, 351.0, 355.0, 356.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 399.0, 400.0, 402.0, 403.0, 404.0, 405.0, 407.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 433.0, 434.0, 435.0, 436.0, 450.0, 453.0, 454.0, 466.0, 472.0, 473.0, 474.0, 475.0, 478.0, 569.0, 571.0, 614.0, 618.0, 619.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 681.0, 682.0, 683.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0], size 133\n",
      "Cluster 13: [346.0, 347.0, 351.0, 355.0, 359.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 403.0, 404.0, 405.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 436.0, 441.0, 454.0, 490.0, 491.0, 544.0, 568.0, 569.0, 571.0, 574.0, 575.0, 589.0, 614.0, 617.0, 618.0, 621.0, 622.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 654.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 692.0], size 120\n",
      "Cluster 14: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 536.0, 537.0, 538.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 568.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 582.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 601.0, 602.0, 603.0, 604.0, 605.0, 606.0, 607.0, 608.0, 609.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 621.0, 622.0, 623.0, 624.0, 625.0, 626.0, 627.0, 628.0, 629.0, 630.0, 631.0, 632.0, 633.0, 634.0, 635.0, 636.0, 637.0, 638.0, 639.0, 640.0, 641.0, 642.0, 643.0, 644.0, 645.0, 646.0, 647.0, 648.0, 649.0, 650.0, 651.0, 652.0, 653.0, 654.0, 655.0, 656.0, 657.0, 658.0, 659.0, 660.0, 661.0, 662.0, 663.0, 664.0, 665.0, 666.0, 667.0, 668.0, 669.0, 670.0, 671.0, 672.0, 673.0, 674.0, 675.0, 676.0, 677.0, 678.0, 679.0, 680.0, 681.0, 682.0, 683.0, 684.0, 685.0, 686.0, 687.0, 688.0, 689.0, 690.0, 691.0, 692.0], size 692\n"
     ]
    }
   ],
   "source": [
    "# Print cluster-level ROI classification results\n",
    "print(\"\\n===== Cluster-Level ROI Classification =====\")\n",
    "for cluster_id, rois in enumerate(cluster_roi_classes):\n",
    "    print(f\"Cluster {cluster_id}: {rois.tolist()}, size {len(rois.tolist())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def compute_cluster_roi(X_train, y_train, num_of_class, threshold=0.4):\n",
    "#     \"\"\"\n",
    "#     Compute ROI class information at the cluster level and ignore fibers without classification.\n",
    "#     Also, count the number of valid fibers within each cluster.\n",
    "\n",
    "#     Parameters:\n",
    "#         X_train: Tensor, shape (b, 4, 100), where the 4th column represents ROI.\n",
    "#         y_train: Tensor, shape (b,), containing each fiber's cluster label.\n",
    "#         num_of_class: int, number of clusters.\n",
    "#         threshold: float, default threshold is 40%.\n",
    "\n",
    "#     Returns:\n",
    "#         cluster_rois: List[Tensor], cluster ROI information.\n",
    "#         cluster_fiber_counts: List[int], where each element represents the number of valid fibers within the cluster.\n",
    "#     \"\"\"\n",
    "#     # Extract fiber ROI classification information (b, 100)\n",
    "#     roi_data = X_train[:, 3, :]\n",
    "\n",
    "#     # Compute unique ROI classifications for each fiber (remove duplicates & ignore 0)\n",
    "#     fiber_rois = [torch.unique(roi[roi != 0]) for roi in roi_data]\n",
    "\n",
    "#     # Filter out fibers without any classification (i.e., fibers where fiber_rois is empty)\n",
    "#     valid_indices = [i for i in range(len(fiber_rois)) if fiber_rois[i].numel() > 0]\n",
    "#     valid_fiber_rois = [fiber_rois[i] for i in valid_indices]\n",
    "#     valid_y_train = y_train[valid_indices]  # Filtered y_train\n",
    "\n",
    "#     # Print ROI and cluster information for each valid fiber\n",
    "#     # print(\"\\n===== Fiber ROI & Cluster Information (Ignoring Unclassified Fibers) =====\")\n",
    "#     # for i, idx in enumerate(valid_indices):\n",
    "#     #     print(f\"Fiber {idx + 1} (Cluster {valid_y_train[i].item()}): {valid_fiber_rois[i].tolist()}\")\n",
    "\n",
    "#     # Compute ROI and fiber count for each cluster\n",
    "#     cluster_rois = []\n",
    "#     cluster_fiber_counts = []  # Store the number of valid fibers in each cluster\n",
    "\n",
    "#     for cluster_id in range(num_of_class):\n",
    "#         # Get fibers belonging to the current cluster\n",
    "#         cluster_fibers = [valid_fiber_rois[i] for i in range(len(valid_y_train)) if valid_y_train[i] == cluster_id]\n",
    "\n",
    "#         cluster_fiber_counts.append(len(cluster_fibers))  # Record the number of valid fibers in the cluster\n",
    "\n",
    "#         if not cluster_fibers:  # If no fibers belong to this cluster, skip\n",
    "#             cluster_rois.append(torch.tensor([]))\n",
    "#             continue\n",
    "\n",
    "#         # Aggregate all ROI classifications from fibers\n",
    "#         all_rois = torch.cat(cluster_fibers)  # Concatenate all fiber ROIs\n",
    "#         unique_rois, counts = torch.unique(all_rois, return_counts=True)  # Count occurrences of each ROI\n",
    "\n",
    "#         # Compute the occurrence ratio\n",
    "#         fiber_count = len(cluster_fibers)  # Total number of fibers in this cluster\n",
    "#         roi_ratio = counts.float() / fiber_count  # Compute the proportion of fibers passing through each ROI\n",
    "\n",
    "#         # Select ROIs that meet the 40% threshold\n",
    "#         selected_rois = unique_rois[roi_ratio >= threshold]\n",
    "#         cluster_rois.append(selected_rois)\n",
    "\n",
    "#     return cluster_rois, cluster_fiber_counts\n",
    "\n",
    "# # Example data\n",
    "# num_of_class = NCLASS  # Total number of clusters\n",
    "# num_samples = 10000\n",
    "# x_train_sub = X_train[:num_samples, :, :]  # Select the first 1000 fibers\n",
    "# y_train_sub = y_train[:num_samples]  # Select the first 1000 fiber cluster labels\n",
    "\n",
    "# # Compute cluster-level ROI classification and fiber count\n",
    "# cluster_roi_classes, cluster_fiber_counts = compute_cluster_roi(x_train_sub, y_train_sub, num_of_class, threshold=0.1)\n",
    "\n",
    "# # Print cluster-level ROI classification results and fiber counts\n",
    "# print(\"\\n===== Cluster-Level ROI Classification and Fiber Count =====\")\n",
    "# for cluster_id, (rois, fiber_count) in enumerate(zip(cluster_roi_classes, cluster_fiber_counts)):\n",
    "#     print(f\"Cluster {cluster_id} (Valid Fiber Count: {fiber_count}): {rois.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 14, 13,  5, 14,  4,  3,  1, 14, 14], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (47) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m cluster_roi_true \u001b[38;5;241m=\u001b[39m cluster_roi_classes\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Compute Dice Loss\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mdice_loss_fiber\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiber_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_roi_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m fiber_rois_profile \u001b[38;5;241m=\u001b[39m compute_fiber_roi(fiber_data)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiber-Level Dice Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 56\u001b[0m, in \u001b[0;36mdice_loss_fiber\u001b[0;34m(fiber_data, cluster_roi_true, smooth)\u001b[0m\n\u001b[1;32m     53\u001b[0m     dice_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m)  \u001b[38;5;66;03m# 其中一个为空集，Dice Loss = 1\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# 计算 Dice Loss\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     intersection \u001b[38;5;241m=\u001b[39m (\u001b[43mROI_fiber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mROI_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     57\u001b[0m     dice_score \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m intersection \u001b[38;5;241m+\u001b[39m smooth) \u001b[38;5;241m/\u001b[39m (ROI_fiber\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m+\u001b[39m ROI_cluster\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m+\u001b[39m smooth)\n\u001b[1;32m     58\u001b[0m     dice_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dice_score  \u001b[38;5;66;03m# 1 - Dice Score = Dice Loss\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (47) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_fiber_roi(fiber_data):\n",
    "    \"\"\"\n",
    "    Compute the unique ROI category numbers for each fiber, removing points where ROI = 0.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor of shape (b, 4, 100), where the last dimension represents ROI category labels.\n",
    "\n",
    "    Returns:\n",
    "        roi_list: List[Tensor], each element is a tensor containing the unique ROI category numbers for a fiber \n",
    "                  (duplicates removed, and 0 values excluded).\n",
    "    \"\"\"\n",
    "    roi_data = fiber_data[:, 3, :]  # Extract ROI dimension (b, 100)\n",
    "    roi_list = [torch.unique(roi[roi != 0]) for roi in roi_data]  # Compute unique ROIs\n",
    "    return roi_list\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "def dice_loss_fiber(fiber_data, cluster_roi_true, smooth=1e-6):\n",
    "        \"\"\"\n",
    "        Compute Dice Loss for each fiber against all clusters.\n",
    "\n",
    "        Parameters:\n",
    "            fiber_data: List[Tensor], 每个 fiber 的 ROI category，长度等于 batch_size。\n",
    "            cluster_roi_true: List[Tensor], 每个 cluster 的 ROI category，长度等于 num_clusters。\n",
    "            smooth: float, 避免除零的小数值。\n",
    "\n",
    "        Returns:\n",
    "            dice_losses: Tensor, shape (batch_size, num_clusters)，\n",
    "                        每个 fiber 和每个 cluster 的 Dice Loss。\n",
    "        \"\"\"\n",
    "        batch_size = len(fiber_data)  # Fiber 数量\n",
    "        num_clusters = len(cluster_roi_true)  # Cluster 数量\n",
    "        dice_losses = torch.zeros((batch_size, num_clusters))  # 结果存储张量\n",
    "\n",
    "        for batch_idx in range(batch_size):  # 遍历 batch 里的每个 fiber\n",
    "            ROI_fiber = fiber_data[batch_idx]  # 当前 fiber 的 ROI\n",
    "            fiber_losses = []\n",
    "\n",
    "            for cluster_idx in range(num_clusters):  # 遍历所有 clusters\n",
    "                ROI_cluster = cluster_roi_true[cluster_idx]  # 当前 cluster 的 ROI\n",
    "\n",
    "                if ROI_fiber.numel() == 0 and ROI_cluster.numel() == 0:\n",
    "                    dice_loss = torch.tensor(0.0)  # 两者都是空集，Dice Loss = 0\n",
    "                elif ROI_fiber.numel() == 0 or ROI_cluster.numel() == 0:\n",
    "                    dice_loss = torch.tensor(1.0)  # 其中一个为空集，Dice Loss = 1\n",
    "                else:\n",
    "                    # 计算 Dice Loss\n",
    "                    intersection = (ROI_fiber.unsqueeze(1) == ROI_cluster.unsqueeze(0)).sum().float()\n",
    "                    dice_score = (2. * intersection + smooth) / (ROI_fiber.numel() + ROI_cluster.numel() + smooth)\n",
    "                    dice_loss = 1 - dice_score  # 1 - Dice Score = Dice Loss\n",
    "\n",
    "                fiber_losses.append(dice_loss)  # 存储当前 fiber 和 cluster 的 loss\n",
    "\n",
    "            dice_losses[batch_idx, :] = torch.stack(fiber_losses)  # 存入 batch 结果\n",
    "\n",
    "        return dice_losses  # Shape: (batch_size, num_clusters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example data\n",
    "b = 2  # Number of fibers\n",
    "num_of_classes = 14  # Number of clusters\n",
    "num_points = 100  # Each fiber has 100 points\n",
    "\n",
    "# Generate fiber data (b, 4, 100) (last dimension represents ROI category)\n",
    "fiber_data = X_train[:10, :, :]  # ROI values range from 0 to 693\n",
    "# Generate predicted cluster labels for fibers\n",
    "fiber_pred = y_train[:10]\n",
    "print(fiber_pred)\n",
    "fiber_pred[0] = 11\n",
    "# Generate ground-truth ROI categories for each cluster (each cluster has one tensor)\n",
    "cluster_roi_true = cluster_roi_classes\n",
    "\n",
    "# Compute Dice Loss\n",
    "loss = dice_loss_fiber(fiber_data, cluster_roi_true)\n",
    "fiber_rois_profile = compute_fiber_roi(fiber_data)\n",
    "print(f\"Fiber-Level Dice Loss: {loss}\")\n",
    "print(cluster_roi_true[11])\n",
    "print(fiber_rois_profile[0])\n",
    "print(fiber_pred[0])\n",
    "# 9: 0.9167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fiber-Level Dice Loss: tensor([0.9000, 0.9942, 0.9861, 1.0000, 0.8667, 0.9971, 0.8769, 0.9792, 1.0000,\n",
      "        0.9853])\n",
      "tensor([ 23.,  24.,  96., 110., 111., 112., 113., 114., 115., 116., 117., 118.,\n",
      "        119., 120., 121., 122., 134., 135., 136., 137., 138., 139., 140., 145.,\n",
      "        146., 150., 151., 152., 153., 154., 155., 161., 182., 183., 185., 186.,\n",
      "        187., 188., 189., 190., 191., 192., 193., 194., 216., 219., 315., 316.,\n",
      "        317., 318., 319., 320., 332., 335., 336., 338., 339., 342., 343., 344.,\n",
      "        691.])\n",
      "tensor([ 2, 14,  6,  6,  0, 14,  1,  4,  3, 12], dtype=torch.int32)\n",
      "tensor([146., 152.])\n",
      "tensor(14, dtype=torch.int32)\n",
      "tensor(14, dtype=torch.int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bohan\\AppData\\Local\\Temp\\ipykernel_24068\\427431408.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fiber_pred = torch.tensor(fiber_pred_gt)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_fiber_roi(fiber_data):\n",
    "    \"\"\"\n",
    "    Compute the unique ROI category numbers for each fiber, removing points where ROI = 0.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor of shape (b, 4, 100), where the last dimension represents ROI category labels.\n",
    "\n",
    "    Returns:\n",
    "        roi_list: List[Tensor], each element is a tensor containing the unique ROI category numbers for a fiber \n",
    "                  (duplicates removed, and 0 values excluded).\n",
    "    \"\"\"\n",
    "    roi_data = fiber_data[:, 3, :]  # Extract ROI dimension (b, 100)\n",
    "    roi_list = [torch.unique(roi[roi != 0]) for roi in roi_data]  # Compute unique ROIs\n",
    "    return roi_list\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "def dice_loss_fiber(fiber_data, fiber_pred, fiber_gt, cluster_roi_true, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the fiber-level ROI Dice Loss, considering fiber prediction correctness.\n",
    "\n",
    "    Parameters:\n",
    "        fiber_data: Tensor, shape (b, 4, 100), containing fiber ROI information.\n",
    "        fiber_pred: Tensor, shape (b,), model-predicted fiber cluster labels.\n",
    "        fiber_gt: Tensor, shape (b,), ground-truth fiber cluster labels.\n",
    "        cluster_roi_true: List[Tensor], ground-truth ROI categories for each cluster (each cluster has one tensor).\n",
    "        smooth: float, a small value to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        dice_losses_per_batch: Tensor, shape (b,), containing Dice Loss for each batch element.\n",
    "    \"\"\"\n",
    "    fiber_rois = compute_fiber_roi(fiber_data)  # Compute ROI categories for each fiber\n",
    "    batch_size = fiber_data.shape[0]  # Get batch size\n",
    "    fiber_losses_per_batch = []\n",
    "\n",
    "    for batch_idx in range(batch_size):  # Iterate over each batch\n",
    "        ROI_fiber = fiber_rois[batch_idx]  # Fiber-level ROI\n",
    "        pred_cluster = fiber_pred[batch_idx].item()  # Predicted fiber cluster\n",
    "        gt_cluster = fiber_gt[batch_idx].item()  # Ground-truth fiber cluster\n",
    "        \n",
    "        ROI_cluster_pred = cluster_roi_true[pred_cluster] if pred_cluster < len(cluster_roi_true) else torch.tensor([])\n",
    "        ROI_cluster_gt = cluster_roi_true[gt_cluster] if gt_cluster < len(cluster_roi_true) else torch.tensor([])\n",
    "\n",
    "        if ROI_fiber.numel() == 0 and ROI_cluster_pred.numel() == 0:\n",
    "            fiber_losses_per_batch.append(torch.tensor(0.0))  # If both are empty, loss = 0\n",
    "        elif ROI_fiber.numel() == 0 or ROI_cluster_pred.numel() == 0:\n",
    "            fiber_losses_per_batch.append(torch.tensor(1.0))  # If only one is empty, loss = 1\n",
    "        else:\n",
    "            # 计算 ROI_fiber 与 cluster 预测的 ROI 之间的 Dice Loss\n",
    "            intersection = (ROI_fiber.unsqueeze(1) == ROI_cluster_pred.unsqueeze(0)).sum().float()\n",
    "            dice_score = (2. * intersection + smooth) / (ROI_fiber.numel() + ROI_cluster_pred.numel() + smooth)\n",
    "            dice_loss = 1 - dice_score  # 1 - Dice coefficient = Dice Loss\n",
    "\n",
    "            # 如果 fiber 分类错误，增加 loss 惩罚\n",
    "            if pred_cluster != gt_cluster:\n",
    "                dice_loss += 0.5  # 额外增加损失，惩罚错误分类\n",
    "            \n",
    "            fiber_losses_per_batch.append(dice_loss)\n",
    "\n",
    "    return torch.tensor(fiber_losses_per_batch)  # Shape: (b,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example data\n",
    "b = 2  # Number of fibers\n",
    "num_of_classes = 14  # Number of clusters\n",
    "num_points = 100  # Each fiber has 100 points\n",
    "\n",
    "# Generate fiber data (b, 4, 100) (last dimension represents ROI category)\n",
    "fiber_data = X_train[10:20, :, :]  # ROI values range from 0 to 693\n",
    "# Generate predicted cluster labels for fibers\n",
    "fiber_pred_gt = y_train[10:20]\n",
    "fiber_pred = torch.tensor(fiber_pred_gt)\n",
    "test_index = 1\n",
    "fiber_pred[test_index] = 14\n",
    "# Generate ground-truth ROI categories for each cluster (each cluster has one tensor)\n",
    "cluster_roi_true = cluster_roi_classes\n",
    "\n",
    "# Compute Dice Loss\n",
    "loss = dice_loss_fiber(fiber_data, fiber_pred, fiber_pred_gt, cluster_roi_true)\n",
    "fiber_rois_profile = compute_fiber_roi(fiber_data)\n",
    "print(f\"Fiber-Level Dice Loss: {loss}\")\n",
    "print(cluster_roi_true[test_index])\n",
    "print(fiber_pred_gt)\n",
    "print(fiber_rois_profile[test_index])\n",
    "print(fiber_pred[test_index])\n",
    "print(fiber_pred_gt[test_index])\n",
    "# 9: 0.9167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "\n",
    "kwargs = {}\n",
    "trn_set=utils.TensorDataset(X_train,y_train)\n",
    "trn_loader=utils.DataLoader(trn_set,batch_size=2,shuffle=True,**kwargs)\n",
    "\n",
    "# tst_set=utils.TensorDataset(X_test,y_test)\n",
    "# tst_loader=utils.DataLoader(tst_set,batch_size=2,shuffle=False,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tract_anatomical_profile(fiber_roi):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(fiber_roi, return_counts=True)\n",
    "    roi_profile = dict(zip(unique, counts / len(fiber_roi)))  # 计算占比\n",
    "    return roi_profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 100])\n",
      "torch.Size([2, 4, 100])\n",
      "torch.Size([2, 1, 100])\n",
      "tensor([[[158., 158., 158.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0., 157., 157., 157., 157.,   0.,   0.,   0.,   0.,   0., 157.,\n",
      "          157.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.]],\n",
      "\n",
      "        [[505., 505., 505., 505., 505., 505., 505., 505., 505., 505., 505.,\n",
      "          505., 505., 505., 505., 505., 504., 504., 504., 504., 504., 504.,\n",
      "          504.,   0., 504., 504., 504.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0., 692., 692., 692., 692., 692., 692.,\n",
      "          692., 692., 692., 692., 692., 692., 692., 692., 692., 692., 692.,\n",
      "          692., 692., 692., 692., 692., 692., 692., 692., 692., 692., 692.,\n",
      "          692.]]])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx,(data,target) in enumerate(trn_loader):\n",
    "    # data = data[0]\n",
    "    # target = target[0]\n",
    "    print(data.shape)\n",
    "    print(data.shape)\n",
    "    print(data[:, 3:4, :].shape)\n",
    "    print(data[:, 3:4, :])\n",
    "    roi_profile = compute_tract_anatomical_profile(data[:, 3:4, :])\n",
    "    # print(roi_profile)\n",
    "    # print(target.shape)\n",
    "    # print(data)\n",
    "    # print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())  # Number of GPUs available\n",
    "print(torch.cuda.current_device())  # Current GPU ID\n",
    "print(torch.cuda.get_device_name(0))  # GPU name (if available)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deterministic-a-bridge-condition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
