{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# del os.environ['MKL_NUM_THREADS'] # error corrected by MH 10/12/2022 (add these three lines)\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import scipy.io as spio\n",
    "import h5py\n",
    "import RESNET152_ATT_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    读取 MATLAB v7.3 `.mat` 文件（Whole_tracks 作为 tracks）\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # 打开 HDF5 MAT 文件\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # 读取 Whole_tracks 变量\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # 结构体 Whole_tracks\n",
    "\n",
    "        # 确保它有 `count` 和 `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count（可能是字符编码格式，需要解析）\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"🔍 Whole_tracks['count'] 数据:\", count)\n",
    "        print(\"🔍 数据类型:\", type(count))\n",
    "\n",
    "        # 直接转换成整数\n",
    "        total_count = int(count.item())\n",
    "        print(f'total_count: {total_count}')\n",
    "        # 读取 Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # 组织输出\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "#%%\n",
    "def mySoftmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\"\"\"normalize\"\"\"#110\n",
    "def rescale(X_list,count):\n",
    "    output=list()\n",
    "    if count==1:\n",
    "        output.append(X_list/110)\n",
    "        return output\n",
    "    for i in range(len(X_list)):\n",
    "        output.append(X_list[i]/110)\n",
    "    return output\n",
    "\n",
    "def udflip(X_list,count=2):\n",
    "    output=list()\n",
    "    if count==1:\n",
    "        output.append(np.flipud(X_list))\n",
    "        return output\n",
    "    for i in range(len(X_list)):\n",
    "        output.append(np.flipud(X_list[i]))\n",
    "    return output\n",
    "def datato3d(arrays):#list of np arrays, NULL*3*100\n",
    "    output=list()\n",
    "    for i in arrays:\n",
    "        i=np.squeeze(i,axis=1)\n",
    "        i=np.transpose(i,(0,2,1))\n",
    "        output.append(i)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.utils.data as utils\n",
    "\n",
    "# 参数\n",
    "matpath = '../Testing_Set/J0037_tracks.mat'\n",
    "label_path = '../Testing_Set/J0037_class_label.mat'  # 你的标签文件\n",
    "modelpath = 'save_small/focal_loss_and_cluster_loss_c_10.0_concat.model'\n",
    "classnum = 15  # 类别数\n",
    "ROI_EMBEDDING_DIM = 32\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\" 读取 MATLAB v7.3 .mat 文件 \"\"\"\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "        \n",
    "        whole_tracks = data['Whole_tracks']\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count\n",
    "        count = int(whole_tracks['count'][()].item())\n",
    "        track = [np.transpose(data[whole_tracks['data'][i].item()][:]).astype(np.float32) for i in range(count)]\n",
    "    \n",
    "    return {'tracks': {'count': count, 'data': track}}\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\" 读取标签 .mat 文件 \"\"\"\n",
    "    with h5py.File(label_path, 'r') as data:\n",
    "        if 'class_label' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'class_label' 变量不存在！\")\n",
    "        \n",
    "        class_label = data['class_label'][()]\n",
    "        \n",
    "        if isinstance(class_label, np.ndarray):\n",
    "            if class_label.size == 1:  \n",
    "                class_label = class_label.item()\n",
    "            else:  \n",
    "                class_label = np.array(class_label)\n",
    "        else:\n",
    "            class_label = int(class_label)\n",
    "\n",
    "        print(f\"✅ 成功解析 class_label, 形状: {class_label.shape}\")\n",
    "        return class_label\n",
    "\n",
    "\n",
    "\"\"\" 测试模型 \"\"\"\n",
    "args_test_batch_size = 10000\n",
    "NCLASS = int(classnum)\n",
    "\n",
    "print(f\"📌 处理数据: {matpath}\")\n",
    "mat = loadmat(matpath)\n",
    "X_test = mat['tracks']['data']\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "X_test = np.transpose(X_test, (0, 2, 1))  # 维度转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取标签\n",
    "y_test = load_labels(label_path)\n",
    "y_test = torch.from_numpy(y_test.astype(np.int64))  # 确保是整数类型\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "X_test = torch.from_numpy(X_test)\n",
    "tst_set = utils.TensorDataset(X_test, y_test)\n",
    "tst_loader = utils.DataLoader(tst_set, batch_size=args_test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "\n",
    "\n",
    "# 加载模型\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "model = RESNET152_ATT_naive.resnet18(num_classes=classnum, input_ch=4)  # input_ch 可能要根据你的任务调整\n",
    "model.to(device)\n",
    "\n",
    "# 2️⃣ 加载权重\n",
    "state_dict = torch.load(modelpath, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 进行推理\n",
    "preds = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in tst_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output, embed, _, _, _, _, _, _, _, _, _ = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        labels.extend(target.cpu().numpy())\n",
    "# 计算评估指标\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "\n",
    "# 打印结果\n",
    "print(f'📊 Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "# print(f'🔢 混淆矩阵:\\n{conf_matrix}')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(sys.argv))\n",
    "# checkArgc(sys.argv)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "filename = \"../Testing_Set/J0037_tracks.mat\"\n",
    "\n",
    "# 读取 MAT v7.3 文件\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print(\"MAT 文件中的变量:\", list(f.keys()))  # 输出所有变量名称\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename, 'r') as f:\n",
    "    if 'tracks' in f:\n",
    "        print(\"tracks 内部结构:\", list(f['tracks'].keys()))\n",
    "    else:\n",
    "        print(\"❌ 错误: 'tracks' 不存在！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename, 'r') as f:\n",
    "    print(\"MAT 文件中的变量:\", list(f.keys()))  # 顶层变量\n",
    "\n",
    "    # 检查 Whole_tracks 里面的内容\n",
    "    if 'Whole_tracks' in f:\n",
    "        print(\"\\n🔍 Whole_tracks 结构:\")\n",
    "        try:\n",
    "            print(\"    子变量:\", list(f['Whole_tracks'].keys()))  # 打印 Whole_tracks 内部结构\n",
    "        except AttributeError:\n",
    "            print(\"    Whole_tracks 不是结构体，可能是数组或标量\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    读取 MATLAB v7.3 `.mat` 文件（Whole_tracks 作为 tracks）\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # 打开 HDF5 MAT 文件\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # 读取 Whole_tracks 变量\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # 结构体 Whole_tracks\n",
    "\n",
    "        # 确保它有 `count` 和 `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count（可能是字符编码格式，需要解析）\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"🔍 Whole_tracks['count'] 数据:\", count)\n",
    "        print(\"🔍 数据类型:\", type(count))\n",
    "\n",
    "        # 直接转换成整数\n",
    "        total_count = int(count.item())\n",
    "        # 读取 Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # 组织输出\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 运行测试\n",
    "filename = \"../Testing_Set/J0037_tracks.mat\"\n",
    "tracks_data = loadmat(filename)\n",
    "print(\"✅ 成功读取 Whole_tracks 数据！\")\n",
    "print(f\"轨迹数: {tracks_data['tracks']['count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tracks_data['tracks']['data']\n",
    "X_test=rescale(X_test,int(tracks_data['tracks']['count']))\n",
    "#X_test_ud=np.asarray(udflip(X_test,int(mat['tracks']['count']))).astype(np.float32)\n",
    "X_test=np.asarray(X_test).astype(np.float32)\n",
    "#X_test=np.vstack((X_test,X_test_ud))\n",
    "#X_test=X_test.reshape((X_test.shape[0],1,X_test.shape[1],X_test.shape[2]))\n",
    "#X_test=datato3d(X_test)[0]\n",
    "X_test=np.transpose(X_test,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    读取 MATLAB v7.3 `.mat` 文件（Whole_tracks 作为 tracks）\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # 打开 HDF5 MAT 文件\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # 读取 Whole_tracks 变量\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # 结构体 Whole_tracks\n",
    "\n",
    "        # 确保它有 `count` 和 `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count（可能是字符编码格式，需要解析）\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"🔍 Whole_tracks['count'] 数据:\", count)\n",
    "        print(\"🔍 数据类型:\", type(count))\n",
    "\n",
    "        # 直接转换成整数\n",
    "        total_count = int(count.item())\n",
    "        # 读取 Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # 组织输出\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 运行测试\n",
    "filename = \"../Testing_Set/J0037_class_label.mat\"\n",
    "tracks_data = loadmat(filename)\n",
    "print(\"✅ 成功读取 Whole_tracks 数据！\")\n",
    "print(f\"轨迹数: {tracks_data['tracks']['count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "filename = \"../Testing_Set/J0037_class_label.mat\"\n",
    "\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print(\"MAT 文件变量:\", list(f.keys()))  # 列出顶层变量\n",
    "    \n",
    "    for key in f.keys():\n",
    "        print(f\"\\n🔍 变量 '{key}' 结构:\")\n",
    "        try:\n",
    "            print(\"    子变量:\", list(f[key].keys()))  # 如果是 group，打印内部结构\n",
    "        except AttributeError:\n",
    "            print(\"    不是结构体，可能是数组或标量\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_label_mat(filename):\n",
    "    \"\"\"\n",
    "    读取 MATLAB v7.3 (.mat) 文件中的 `class_label`\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        if 'class_label' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'class_label' 变量不存在！\")\n",
    "\n",
    "        # 读取 class_label\n",
    "        class_label = data['class_label'][()]\n",
    "\n",
    "        # 解析数据\n",
    "        if isinstance(class_label, np.ndarray):\n",
    "            if class_label.size == 1:  # 只有一个值\n",
    "                class_label = class_label.item()\n",
    "            else:  # 多个值，转换为 NumPy 数组\n",
    "                class_label = np.array(class_label)\n",
    "        else:\n",
    "            class_label = int(class_label)  # 可能是单个数值\n",
    "\n",
    "        print(f\"✅ 成功解析 class_label: {class_label}\")\n",
    "        return class_label\n",
    "\n",
    "# 测试\n",
    "filename = \"../Testing_Set/J0037_class_label.mat\"\n",
    "labels = load_label_mat(filename)\n",
    "print(\"📌 解析出的 labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    通用测试函数（无损失函数计算）\n",
    "    - 适用于分类任务\n",
    "    - 计算预测结果、混淆矩阵、Precision、Recall、F1\n",
    "\n",
    "    参数：\n",
    "    - model: 训练好的 PyTorch 模型\n",
    "    - test_loader: PyTorch DataLoader (测试集)\n",
    "    - device: 'cuda' or 'cpu'\n",
    "\n",
    "    返回：\n",
    "    - conf_matrix: 混淆矩阵\n",
    "    - precision, recall, f1: 分类指标\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():  # 不计算梯度，加速推理\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # 获取模型输出\n",
    "            output = model(data)\n",
    "\n",
    "            # 分类任务：获取预测类别\n",
    "            if output.dim() > 1:  # 确保 output 是 logits 形式\n",
    "                pred = output.argmax(dim=1)  # 取最大概率的类别\n",
    "                preds.extend(pred.cpu().numpy())\n",
    "                labels.extend(target.cpu().numpy())\n",
    "\n",
    "    # 计算分类指标\n",
    "    if preds:\n",
    "        conf_matrix = confusion_matrix(labels, preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    else:\n",
    "        conf_matrix, precision, recall, f1 = None, None, None, None\n",
    "\n",
    "    # 输出结果\n",
    "    print(f'📊 Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "    print(f'🔢 混淆矩阵:\\n{conf_matrix}')\n",
    "\n",
    "    return conf_matrix, precision, recall, f1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deterministic-a-bridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
