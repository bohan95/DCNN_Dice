{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# del os.environ['MKL_NUM_THREADS'] # error corrected by MH 10/12/2022 (add these three lines)\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import scipy.io as spio\n",
    "import h5py\n",
    "import RESNET152_ATT_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    è¯»å– MATLAB v7.3 `.mat` æ–‡ä»¶ï¼ˆWhole_tracks ä½œä¸º tracksï¼‰\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # æ‰“å¼€ HDF5 MAT æ–‡ä»¶\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # è¯»å– Whole_tracks å˜é‡\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"âŒ é”™è¯¯: 'Whole_tracks' å˜é‡ä¸å­˜åœ¨ï¼\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # ç»“æ„ä½“ Whole_tracks\n",
    "\n",
    "        # ç¡®ä¿å®ƒæœ‰ `count` å’Œ `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"âŒ é”™è¯¯: 'Whole_tracks' ç»“æ„ä¸å®Œæ•´ï¼åŒ…å«: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # è¯»å– countï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ç¼–ç æ ¼å¼ï¼Œéœ€è¦è§£æï¼‰\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"ğŸ” Whole_tracks['count'] æ•°æ®:\", count)\n",
    "        print(\"ğŸ” æ•°æ®ç±»å‹:\", type(count))\n",
    "\n",
    "        # ç›´æ¥è½¬æ¢æˆæ•´æ•°\n",
    "        total_count = int(count.item())\n",
    "        print(f'total_count: {total_count}')\n",
    "        # è¯»å– Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # ç»„ç»‡è¾“å‡º\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "#%%\n",
    "def mySoftmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\"\"\"normalize\"\"\"#110\n",
    "def rescale(X_list,count):\n",
    "    output=list()\n",
    "    if count==1:\n",
    "        output.append(X_list/110)\n",
    "        return output\n",
    "    for i in range(len(X_list)):\n",
    "        output.append(X_list[i]/110)\n",
    "    return output\n",
    "\n",
    "def udflip(X_list,count=2):\n",
    "    output=list()\n",
    "    if count==1:\n",
    "        output.append(np.flipud(X_list))\n",
    "        return output\n",
    "    for i in range(len(X_list)):\n",
    "        output.append(np.flipud(X_list[i]))\n",
    "    return output\n",
    "def datato3d(arrays):#list of np arrays, NULL*3*100\n",
    "    output=list()\n",
    "    for i in arrays:\n",
    "        i=np.squeeze(i,axis=1)\n",
    "        i=np.transpose(i,(0,2,1))\n",
    "        output.append(i)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.utils.data as utils\n",
    "\n",
    "# å‚æ•°\n",
    "matpath = '../Testing_Set/J0037_tracks.mat'\n",
    "label_path = '../Testing_Set/J0037_class_label.mat'  # ä½ çš„æ ‡ç­¾æ–‡ä»¶\n",
    "modelpath = 'save_small/focal_loss_and_cluster_loss_c_10.0_concat.model'\n",
    "classnum = 15  # ç±»åˆ«æ•°\n",
    "ROI_EMBEDDING_DIM = 32\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\" è¯»å– MATLAB v7.3 .mat æ–‡ä»¶ \"\"\"\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"âŒ é”™è¯¯: 'Whole_tracks' å˜é‡ä¸å­˜åœ¨ï¼\")\n",
    "        \n",
    "        whole_tracks = data['Whole_tracks']\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"âŒ é”™è¯¯: 'Whole_tracks' ç»“æ„ä¸å®Œæ•´ï¼åŒ…å«: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # è¯»å– count\n",
    "        count = int(whole_tracks['count'][()].item())\n",
    "        track = [np.transpose(data[whole_tracks['data'][i].item()][:]).astype(np.float32) for i in range(count)]\n",
    "    \n",
    "    return {'tracks': {'count': count, 'data': track}}\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\" è¯»å–æ ‡ç­¾ .mat æ–‡ä»¶ \"\"\"\n",
    "    with h5py.File(label_path, 'r') as data:\n",
    "        if 'class_label' not in data:\n",
    "            raise KeyError(\"âŒ é”™è¯¯: 'class_label' å˜é‡ä¸å­˜åœ¨ï¼\")\n",
    "        \n",
    "        class_label = data['class_label'][()]\n",
    "        \n",
    "        if isinstance(class_label, np.ndarray):\n",
    "            if class_label.size == 1:  \n",
    "                class_label = class_label.item()\n",
    "            else:  \n",
    "                class_label = np.array(class_label)\n",
    "        else:\n",
    "            class_label = int(class_label)\n",
    "\n",
    "        print(f\"âœ… æˆåŠŸè§£æ class_label, å½¢çŠ¶: {class_label.shape}\")\n",
    "        return class_label\n",
    "\n",
    "\n",
    "\"\"\" æµ‹è¯•æ¨¡å‹ \"\"\"\n",
    "args_test_batch_size = 10000\n",
    "NCLASS = int(classnum)\n",
    "\n",
    "print(f\"ğŸ“Œ å¤„ç†æ•°æ®: {matpath}\")\n",
    "mat = loadmat(matpath)\n",
    "X_test = mat['tracks']['data']\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "X_test = np.transpose(X_test, (0, 2, 1))  # ç»´åº¦è½¬æ¢\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–æ ‡ç­¾\n",
    "y_test = load_labels(label_path)\n",
    "y_test = torch.from_numpy(y_test.astype(np.int64))  # ç¡®ä¿æ˜¯æ•´æ•°ç±»å‹\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "X_test = torch.from_numpy(X_test)\n",
    "tst_set = utils.TensorDataset(X_test, y_test)\n",
    "tst_loader = utils.DataLoader(tst_set, batch_size=args_test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®åŠ è½½\n",
    "\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "model = RESNET152_ATT_naive.resnet18(num_classes=classnum, input_ch=4)  # input_ch å¯èƒ½è¦æ ¹æ®ä½ çš„ä»»åŠ¡è°ƒæ•´\n",
    "model.to(device)\n",
    "\n",
    "# 2ï¸âƒ£ åŠ è½½æƒé‡\n",
    "state_dict = torch.load(modelpath, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# è¿›è¡Œæ¨ç†\n",
    "preds = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in tst_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output, embed, _, _, _, _, _, _, _, _, _ = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        preds.extend(pred.cpu().numpy())\n",
    "        labels.extend(target.cpu().numpy())\n",
    "# è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n",
    "conf_matrix = confusion_matrix(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "\n",
    "# æ‰“å°ç»“æœ\n",
    "print(f'ğŸ“Š Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "# print(f'ğŸ”¢ æ··æ·†çŸ©é˜µ:\\n{conf_matrix}')\n",
    "\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(sys.argv))\n",
    "# checkArgc(sys.argv)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "filename = \"../Testing_Set/J0037_tracks.mat\"\n",
    "\n",
    "# è¯»å– MAT v7.3 æ–‡ä»¶\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print(\"MAT æ–‡ä»¶ä¸­çš„å˜é‡:\", list(f.keys()))  # è¾“å‡ºæ‰€æœ‰å˜é‡åç§°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename, 'r') as f:\n",
    "    if 'tracks' in f:\n",
    "        print(\"tracks å†…éƒ¨ç»“æ„:\", list(f['tracks'].keys()))\n",
    "    else:\n",
    "        print(\"âŒ é”™è¯¯: 'tracks' ä¸å­˜åœ¨ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(filename, 'r') as f:\n",
    "    print(\"MAT æ–‡ä»¶ä¸­çš„å˜é‡:\", list(f.keys()))  # é¡¶å±‚å˜é‡\n",
    "\n",
    "    # æ£€æŸ¥ Whole_tracks é‡Œé¢çš„å†…å®¹\n",
    "    if 'Whole_tracks' in f:\n",
    "        print(\"\\nğŸ” Whole_tracks ç»“æ„:\")\n",
    "        try:\n",
    "            print(\"    å­å˜é‡:\", list(f['Whole_tracks'].keys()))  # æ‰“å° Whole_tracks å†…éƒ¨ç»“æ„\n",
    "        except AttributeError:\n",
    "            print(\"    Whole_tracks ä¸æ˜¯ç»“æ„ä½“ï¼Œå¯èƒ½æ˜¯æ•°ç»„æˆ–æ ‡é‡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    è¯»å– MATLAB v7.3 `.mat` æ–‡ä»¶ï¼ˆWhole_tracks ä½œä¸º tracksï¼‰\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # æ‰“å¼€ HDF5 MAT æ–‡ä»¶\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # è¯»å– Whole_tracks å˜é‡\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"âŒ é”™è¯¯: 'Whole_tracks' å˜é‡ä¸å­˜åœ¨ï¼\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # ç»“æ„ä½“ Whole_tracks\n",
    "\n",
    "        # ç¡®ä¿å®ƒæœ‰ `count` å’Œ `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"âŒ é”™è¯¯: 'Whole_tracks' ç»“æ„ä¸å®Œæ•´ï¼åŒ…å«: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # è¯»å– countï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ç¼–ç æ ¼å¼ï¼Œéœ€è¦è§£æï¼‰\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"ğŸ” Whole_tracks['count'] æ•°æ®:\", count)\n",
    "        print(\"ğŸ” æ•°æ®ç±»å‹:\", type(count))\n",
    "\n",
    "        # ç›´æ¥è½¬æ¢æˆæ•´æ•°\n",
    "        total_count = int(count.item())\n",
    "        # è¯»å– Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # ç»„ç»‡è¾“å‡º\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "filename = \"../Testing_Set/J0037_tracks.mat\"\n",
    "tracks_data = loadmat(filename)\n",
    "print(\"âœ… æˆåŠŸè¯»å– Whole_tracks æ•°æ®ï¼\")\n",
    "print(f\"è½¨è¿¹æ•°: {tracks_data['tracks']['count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=tracks_data['tracks']['data']\n",
    "X_test=rescale(X_test,int(tracks_data['tracks']['count']))\n",
    "#X_test_ud=np.asarray(udflip(X_test,int(mat['tracks']['count']))).astype(np.float32)\n",
    "X_test=np.asarray(X_test).astype(np.float32)\n",
    "#X_test=np.vstack((X_test,X_test_ud))\n",
    "#X_test=X_test.reshape((X_test.shape[0],1,X_test.shape[1],X_test.shape[2]))\n",
    "#X_test=datato3d(X_test)[0]\n",
    "X_test=np.transpose(X_test,(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    è¯»å– MATLAB v7.3 `.mat` æ–‡ä»¶ï¼ˆWhole_tracks ä½œä¸º tracksï¼‰\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # æ‰“å¼€ HDF5 MAT æ–‡ä»¶\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # è¯»å– Whole_tracks å˜é‡\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"âŒ é”™è¯¯: 'Whole_tracks' å˜é‡ä¸å­˜åœ¨ï¼\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # ç»“æ„ä½“ Whole_tracks\n",
    "\n",
    "        # ç¡®ä¿å®ƒæœ‰ `count` å’Œ `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"âŒ é”™è¯¯: 'Whole_tracks' ç»“æ„ä¸å®Œæ•´ï¼åŒ…å«: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # è¯»å– countï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ç¼–ç æ ¼å¼ï¼Œéœ€è¦è§£æï¼‰\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"ğŸ” Whole_tracks['count'] æ•°æ®:\", count)\n",
    "        print(\"ğŸ” æ•°æ®ç±»å‹:\", type(count))\n",
    "\n",
    "        # ç›´æ¥è½¬æ¢æˆæ•´æ•°\n",
    "        total_count = int(count.item())\n",
    "        # è¯»å– Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # ç»„ç»‡è¾“å‡º\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "filename = \"../Testing_Set/J0037_class_label.mat\"\n",
    "tracks_data = loadmat(filename)\n",
    "print(\"âœ… æˆåŠŸè¯»å– Whole_tracks æ•°æ®ï¼\")\n",
    "print(f\"è½¨è¿¹æ•°: {tracks_data['tracks']['count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "filename = \"../Testing_Set/J0037_class_label.mat\"\n",
    "\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    print(\"MAT æ–‡ä»¶å˜é‡:\", list(f.keys()))  # åˆ—å‡ºé¡¶å±‚å˜é‡\n",
    "    \n",
    "    for key in f.keys():\n",
    "        print(f\"\\nğŸ” å˜é‡ '{key}' ç»“æ„:\")\n",
    "        try:\n",
    "            print(\"    å­å˜é‡:\", list(f[key].keys()))  # å¦‚æœæ˜¯ groupï¼Œæ‰“å°å†…éƒ¨ç»“æ„\n",
    "        except AttributeError:\n",
    "            print(\"    ä¸æ˜¯ç»“æ„ä½“ï¼Œå¯èƒ½æ˜¯æ•°ç»„æˆ–æ ‡é‡\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_label_mat(filename):\n",
    "    \"\"\"\n",
    "    è¯»å– MATLAB v7.3 (.mat) æ–‡ä»¶ä¸­çš„ `class_label`\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        if 'class_label' not in data:\n",
    "            raise KeyError(\"âŒ é”™è¯¯: 'class_label' å˜é‡ä¸å­˜åœ¨ï¼\")\n",
    "\n",
    "        # è¯»å– class_label\n",
    "        class_label = data['class_label'][()]\n",
    "\n",
    "        # è§£ææ•°æ®\n",
    "        if isinstance(class_label, np.ndarray):\n",
    "            if class_label.size == 1:  # åªæœ‰ä¸€ä¸ªå€¼\n",
    "                class_label = class_label.item()\n",
    "            else:  # å¤šä¸ªå€¼ï¼Œè½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "                class_label = np.array(class_label)\n",
    "        else:\n",
    "            class_label = int(class_label)  # å¯èƒ½æ˜¯å•ä¸ªæ•°å€¼\n",
    "\n",
    "        print(f\"âœ… æˆåŠŸè§£æ class_label: {class_label}\")\n",
    "        return class_label\n",
    "\n",
    "# æµ‹è¯•\n",
    "filename = \"../Testing_Set/J0037_class_label.mat\"\n",
    "labels = load_label_mat(filename)\n",
    "print(\"ğŸ“Œ è§£æå‡ºçš„ labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    é€šç”¨æµ‹è¯•å‡½æ•°ï¼ˆæ— æŸå¤±å‡½æ•°è®¡ç®—ï¼‰\n",
    "    - é€‚ç”¨äºåˆ†ç±»ä»»åŠ¡\n",
    "    - è®¡ç®—é¢„æµ‹ç»“æœã€æ··æ·†çŸ©é˜µã€Precisionã€Recallã€F1\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "    - model: è®­ç»ƒå¥½çš„ PyTorch æ¨¡å‹\n",
    "    - test_loader: PyTorch DataLoader (æµ‹è¯•é›†)\n",
    "    - device: 'cuda' or 'cpu'\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - conf_matrix: æ··æ·†çŸ©é˜µ\n",
    "    - precision, recall, f1: åˆ†ç±»æŒ‡æ ‡\n",
    "    \"\"\"\n",
    "    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒåŠ é€Ÿæ¨ç†\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # è·å–æ¨¡å‹è¾“å‡º\n",
    "            output = model(data)\n",
    "\n",
    "            # åˆ†ç±»ä»»åŠ¡ï¼šè·å–é¢„æµ‹ç±»åˆ«\n",
    "            if output.dim() > 1:  # ç¡®ä¿ output æ˜¯ logits å½¢å¼\n",
    "                pred = output.argmax(dim=1)  # å–æœ€å¤§æ¦‚ç‡çš„ç±»åˆ«\n",
    "                preds.extend(pred.cpu().numpy())\n",
    "                labels.extend(target.cpu().numpy())\n",
    "\n",
    "    # è®¡ç®—åˆ†ç±»æŒ‡æ ‡\n",
    "    if preds:\n",
    "        conf_matrix = confusion_matrix(labels, preds)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    else:\n",
    "        conf_matrix, precision, recall, f1 = None, None, None, None\n",
    "\n",
    "    # è¾“å‡ºç»“æœ\n",
    "    print(f'ğŸ“Š Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "    print(f'ğŸ”¢ æ··æ·†çŸ©é˜µ:\\n{conf_matrix}')\n",
    "\n",
    "    return conf_matrix, precision, recall, f1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deterministic-a-bridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
