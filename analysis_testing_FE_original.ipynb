{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# del os.environ['MKL_NUM_THREADS'] # error corrected by MH 10/12/2022 (add these three lines)\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import scipy.io as spio\n",
    "import h5py\n",
    "import RESNET152_ATT_naive\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.utils.data as utils\n",
    "import os\n",
    "import sys\n",
    "# del os.environ['MKL_NUM_THREADS'] # error corrected by MH 10/12/2022 (add these three lines)\n",
    "from Embedding_layer import ROIFeatureExtractor\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import scipy.io as spio\n",
    "import RESNET152_ATT_naive\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.nn as nn\n",
    "from Util import focalLoss, preprocess_fiber_input\n",
    "from clustering_layer_v2 import ClusterlingLayer\n",
    "from klDiv import KLDivLoss\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    '''\n",
    "    读取 MATLAB v7.3 `.mat` 文件（Whole_tracks 作为 tracks）\n",
    "    '''\n",
    "    output = dict()\n",
    "    \n",
    "    # 打开 HDF5 MAT 文件\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        # 读取 Whole_tracks 变量\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "\n",
    "        whole_tracks = data['Whole_tracks']  # 结构体 Whole_tracks\n",
    "\n",
    "        # 确保它有 `count` 和 `data`\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count（可能是字符编码格式，需要解析）\n",
    "        count = whole_tracks['count'][()]  \n",
    "        print(\"🔍 Whole_tracks['count'] 数据:\", count)\n",
    "        print(\"🔍 数据类型:\", type(count))\n",
    "\n",
    "        # 直接转换成整数\n",
    "        total_count = int(count.item())\n",
    "        print(f'total_count: {total_count}')\n",
    "        # 读取 Whole_tracks['data']\n",
    "        track = []\n",
    "        for i in range(total_count):\n",
    "            data_ref = whole_tracks['data'][i].item()\n",
    "            track.append(np.transpose(data[data_ref][:]).astype(np.float32))\n",
    "\n",
    "        # 组织输出\n",
    "        output['tracks'] = {\n",
    "            'count': total_count,\n",
    "            'data': track\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "#%%\n",
    "def mySoftmax(z):\n",
    "    assert len(z.shape) == 2\n",
    "    s = np.max(z, axis=1)\n",
    "    s = s[:, np.newaxis] # necessary step to do broadcasting\n",
    "    e_x = np.exp(z - s)\n",
    "    div = np.sum(e_x, axis=1)\n",
    "    div = div[:, np.newaxis] # dito\n",
    "    return e_x / div\n",
    "\"\"\"normalize\"\"\"#110\n",
    "def rescale(X_list,count):\n",
    "    output=list()\n",
    "    if count==1:\n",
    "        output.append(X_list/110)\n",
    "        return output\n",
    "    for i in range(len(X_list)):\n",
    "        output.append(X_list[i]/110)\n",
    "    return output\n",
    "\n",
    "def udflip(X_nparray, y_nparray, shuffle=True):\n",
    "\n",
    "    if X_nparray.shape[2] == 4:\n",
    "        if np.std(X_nparray[:, 0, :]) > np.std(X_nparray[:, -1, :]):\n",
    "            print(\"Detected special info in first column, swapping...\")\n",
    "            X_nparray = np.concatenate((X_nparray[:, 1:, :], X_nparray[:, 0:1, :]), axis=1)\n",
    "    \n",
    "    X_flipped = np.flip(X_nparray, axis=2)  \n",
    "\n",
    "    X_aug = np.vstack((X_nparray, X_flipped))\n",
    "    y_aug = np.hstack((y_nparray, y_nparray))  \n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_idx = np.random.permutation(X_aug.shape[0])\n",
    "        return X_aug[shuffle_idx], y_aug[shuffle_idx]\n",
    "    else:\n",
    "        return X_aug, y_aug\n",
    "def datato3d(arrays):#list of np arrays, NULL*3*100\n",
    "    output=list()\n",
    "    for i in arrays:\n",
    "        i=np.squeeze(i,axis=1)\n",
    "        i=np.transpose(i,(0,2,1))\n",
    "        output.append(i)\n",
    "    return output\n",
    "def udflip(X_nparray, y_nparray, shuffle=True):\n",
    "\n",
    "    if X_nparray.shape[2] == 4:\n",
    "        if np.std(X_nparray[:, 0, :]) > np.std(X_nparray[:, -1, :]):\n",
    "            print(\"Detected special info in first column, swapping...\")\n",
    "            X_nparray = np.concatenate((X_nparray[:, 1:, :], X_nparray[:, 0:1, :]), axis=1)\n",
    "    \n",
    "    X_flipped = np.flip(X_nparray, axis=2)  \n",
    "    y_nparray = y_nparray.flatten()\n",
    "    X_aug = np.vstack((X_nparray, X_flipped))\n",
    "    y_aug = np.hstack((y_nparray, y_nparray))  \n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_idx = np.random.permutation(X_aug.shape[0])\n",
    "        return X_aug[shuffle_idx], y_aug[shuffle_idx]\n",
    "    else:\n",
    "        return X_aug, y_aug\n",
    "    \n",
    "def aug_at_test(probs,mode='max'):\n",
    "    assert(len(probs)>0)\n",
    "    if(mode=='max'):\n",
    "        all_probs=np.vstack(probs)\n",
    "        print(all_probs.shape)\n",
    "        max_probs=np.amax(all_probs,axis=1).reshape((2,-1))#row 0: prob for first half, row 1: prob for flipped half\n",
    "        max_idx=np.argmax(max_probs,axis=0)#should be 0/1\n",
    "        test_sample_count=all_probs.shape[0]/2\n",
    "        \n",
    "        class_pred=np.argmax(all_probs,axis=1)\n",
    "        final_pred=list()\n",
    "        for i in range(max_idx.shape[0]):\n",
    "            final_pred.append(class_pred[int(i+test_sample_count*max_idx[i])])#if 0, first half\n",
    "        return final_pred\n",
    "    if(mode=='mean'):\n",
    "        all_probs=np.exp(np.vstack(probs))\n",
    "        test_sample_count=int(all_probs.shape[0]/2)\n",
    "        final_probs=all_probs[0:test_sample_count]+all_probs[test_sample_count:]\n",
    "        final_pred=np.argmax(final_probs,axis=1)\n",
    "        return final_pred.tolist()    \n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\" 读取 MATLAB v7.3 .mat 文件 \"\"\"\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "        \n",
    "        whole_tracks = data['Whole_tracks']\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count\n",
    "        count = int(whole_tracks['count'][()].item())\n",
    "        track = [np.transpose(data[whole_tracks['data'][i].item()][:]).astype(np.float32) for i in range(count)]\n",
    "    \n",
    "    return {'tracks': {'count': count, 'data': track}}\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\" 读取标签 .mat 文件 \"\"\"\n",
    "    with h5py.File(label_path, 'r') as data:\n",
    "        if 'class_label' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'class_label' 变量不存在！\")\n",
    "        \n",
    "        class_label = data['class_label'][()]\n",
    "        \n",
    "        if isinstance(class_label, np.ndarray):\n",
    "            if class_label.size == 1:  \n",
    "                class_label = class_label.item()\n",
    "            else:  \n",
    "                class_label = np.array(class_label)\n",
    "        else:\n",
    "            class_label = int(class_label)\n",
    "\n",
    "        print(f\"✅ 成功解析 class_label, 形状: {class_label.shape}\")\n",
    "        return class_label\n",
    "    \n",
    "def process_file(matpath, label_path, model, roi_extractor, clustering_layer, device, NCLASS, args_test_batch_size):\n",
    "    \"\"\" 处理单个测试文件，并返回其指标 \"\"\"\n",
    "    print(f\"📌 处理数据: {matpath}\")\n",
    "    \n",
    "    mat = loadmat(matpath)\n",
    "    X_test = mat['tracks']['data']\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    X_test_original = np.transpose(X_test, (0, 2, 1))\n",
    "\n",
    "    # 读取标签\n",
    "    y_test = load_labels(label_path)\n",
    "    y_test_list = y_test\n",
    "\n",
    "    # 数据增强\n",
    "    X_test, y_test = udflip(X_test_original, y_test, shuffle=False)\n",
    "\n",
    "    # 转换为 PyTorch Tensor 并移动到相同设备\n",
    "    y_test = torch.from_numpy(y_test.astype(np.int64)).to(device)  # 确保标签也在正确设备上\n",
    "    X_test = torch.from_numpy(X_test).to(device)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    tst_set = utils.TensorDataset(X_test, y_test)\n",
    "    tst_loader = utils.DataLoader(tst_set, batch_size=args_test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # **确保模型和 layers 都在同一个设备**\n",
    "    model.to(device)\n",
    "    roi_extractor.to(device)\n",
    "    clustering_layer.to(device)\n",
    "    model.eval()\n",
    "    roi_extractor.eval()\n",
    "    clustering_layer.eval()\n",
    "\n",
    "    probs, labels = [], []\n",
    "\n",
    "    loss_nll = torch.nn.NLLLoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in tst_loader:\n",
    "            labels += target.cpu().numpy().tolist()\n",
    "\n",
    "            # 确保 data 和 target 都在同一设备\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # 预处理数据\n",
    "            data_processed = preprocess_fiber_input(data, roi_extractor=roi_extractor, device=device, net_type='FE')\n",
    "\n",
    "            # 送入模型\n",
    "            output, embed, *_ = model(data_processed)  # **确保 model 已被移动到 `device`**\n",
    "\n",
    "            probs.append(output.data.cpu().numpy())  # 确保 probs 存储在 CPU\n",
    "\n",
    "    # 计算最终预测\n",
    "    preds = aug_at_test(probs, mode='max')\n",
    "\n",
    "    # 计算指标\n",
    "    conf_mat = confusion_matrix(y_test_list, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test_list, preds, average='macro')\n",
    "\n",
    "    try:\n",
    "        probs = np.concatenate(probs, axis=0)\n",
    "        probs = F.softmax(torch.tensor(probs), dim=1).numpy()\n",
    "        labels = np.array(labels)\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "\n",
    "        auroc = roc_auc_score(labels, probs, multi_class='ovr')\n",
    "        auprc = average_precision_score(labels, probs, average='macro')\n",
    "    except ValueError as e:\n",
    "        print(f\"AUROC / AUPRC 计算错误: {e}\")\n",
    "        auroc, auprc = None, None\n",
    "\n",
    "    return precision, recall, f1, auroc, auprc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import gc\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.utils.data as utils\n",
    "\n",
    "# 参数\n",
    "matpath = '../Testing_Set/J0037_tracks.mat'\n",
    "label_path = '../Testing_Set/J0037_class_label.mat'  # 你的标签文件\n",
    "classnum = 15  # 类别数\n",
    "ROI_EMBEDDING_DIM = 32\n",
    "\n",
    "def loadmat(filename):\n",
    "    \"\"\" 读取 MATLAB v7.3 .mat 文件 \"\"\"\n",
    "    with h5py.File(filename, 'r') as data:\n",
    "        if 'Whole_tracks' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'Whole_tracks' 变量不存在！\")\n",
    "        \n",
    "        whole_tracks = data['Whole_tracks']\n",
    "        if 'count' not in whole_tracks or 'data' not in whole_tracks:\n",
    "            raise KeyError(f\"❌ 错误: 'Whole_tracks' 结构不完整！包含: {list(whole_tracks.keys())}\")\n",
    "\n",
    "        # 读取 count\n",
    "        count = int(whole_tracks['count'][()].item())\n",
    "        track = [np.transpose(data[whole_tracks['data'][i].item()][:]).astype(np.float32) for i in range(count)]\n",
    "    \n",
    "    return {'tracks': {'count': count, 'data': track}}\n",
    "\n",
    "def load_labels(label_path):\n",
    "    \"\"\" 读取标签 .mat 文件 \"\"\"\n",
    "    with h5py.File(label_path, 'r') as data:\n",
    "        if 'class_label' not in data:\n",
    "            raise KeyError(\"❌ 错误: 'class_label' 变量不存在！\")\n",
    "        \n",
    "        class_label = data['class_label'][()]\n",
    "        \n",
    "        if isinstance(class_label, np.ndarray):\n",
    "            if class_label.size == 1:  \n",
    "                class_label = class_label.item()\n",
    "            else:  \n",
    "                class_label = np.array(class_label)\n",
    "        else:\n",
    "            class_label = int(class_label)\n",
    "\n",
    "        print(f\"✅ 成功解析 class_label, 形状: {class_label.shape}\")\n",
    "        return class_label\n",
    "\n",
    "\n",
    "\"\"\" 测试模型 \"\"\"\n",
    "args_test_batch_size = 10000\n",
    "NCLASS = int(classnum)\n",
    "\n",
    "print(f\"📌 处理数据: {matpath}\")\n",
    "mat = loadmat(matpath)\n",
    "X_test = mat['tracks']['data']\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "X_test_original = np.transpose(X_test, (0, 2, 1))  # 维度转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def udflip(X_nparray, y_nparray, shuffle=True):\n",
    "\n",
    "    if X_nparray.shape[2] == 4:\n",
    "        if np.std(X_nparray[:, 0, :]) > np.std(X_nparray[:, -1, :]):\n",
    "            print(\"Detected special info in first column, swapping...\")\n",
    "            X_nparray = np.concatenate((X_nparray[:, 1:, :], X_nparray[:, 0:1, :]), axis=1)\n",
    "    \n",
    "    X_flipped = np.flip(X_nparray, axis=2)  \n",
    "    y_nparray = y_nparray.flatten()\n",
    "    X_aug = np.vstack((X_nparray, X_flipped))\n",
    "    y_aug = np.hstack((y_nparray, y_nparray))  \n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_idx = np.random.permutation(X_aug.shape[0])\n",
    "        return X_aug[shuffle_idx], y_aug[shuffle_idx]\n",
    "    else:\n",
    "        return X_aug, y_aug\n",
    "# 读取标签\n",
    "y_test = load_labels(label_path)\n",
    "y_test_list = y_test\n",
    "print(X_test_original.shape)\n",
    "print(y_test.shape)\n",
    "X_test, y_test = udflip(X_test_original,y_test,shuffle=False)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_test_np = X_test.copy()\n",
    "y_test = torch.from_numpy(y_test.astype(np.int64))  # 确保是整数类型\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "tst_set = utils.TensorDataset(X_test, y_test)\n",
    "tst_loader = utils.DataLoader(tst_set, batch_size=args_test_batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_at_test(probs,mode='max'):\n",
    "    assert(len(probs)>0)\n",
    "    if(mode=='max'):\n",
    "        all_probs=np.vstack(probs)\n",
    "        print(all_probs.shape)\n",
    "        max_probs=np.amax(all_probs,axis=1).reshape((2,-1))#row 0: prob for first half, row 1: prob for flipped half\n",
    "        max_idx=np.argmax(max_probs,axis=0)#should be 0/1\n",
    "        test_sample_count=all_probs.shape[0]/2\n",
    "        \n",
    "        class_pred=np.argmax(all_probs,axis=1)\n",
    "        final_pred=list()\n",
    "        for i in range(max_idx.shape[0]):\n",
    "            final_pred.append(class_pred[int(i+test_sample_count*max_idx[i])])#if 0, first half\n",
    "        return final_pred\n",
    "    if(mode=='mean'):\n",
    "        all_probs=np.exp(np.vstack(probs))\n",
    "        test_sample_count=int(all_probs.shape[0]/2)\n",
    "        final_probs=all_probs[0:test_sample_count]+all_probs[test_sample_count:]\n",
    "        final_pred=np.argmax(final_probs,axis=1)\n",
    "        return final_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, roi_extractor, tst_loader, device):\n",
    "    model.eval()\n",
    "    logit=list()\n",
    "    attVec=list()\n",
    "    for data,lbl in tst_loader:\n",
    "        with torch.no_grad():  # error corrected by MH 10/12/2022 (add with torch.no_grad():) \n",
    "            print(data)\n",
    "            print(data.shape)\n",
    "            print(type(data))\n",
    "            print(lbl)\n",
    "            data = Variable(data.cuda())\n",
    "            data_processed = preprocess_fiber_input(data, roi_extractor=roi_extractor, device=device, net_type='FE')\n",
    "            output,_,att,_, _, _, _, _, _, _, _ = model(data_processed)\n",
    "            logit.append(output.data.cpu().numpy())\n",
    "            attVec.append(att.data.cpu().numpy())\n",
    "    return logit,attVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:1\n",
      "using ROI with emb: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bohan/.conda/envs/deterministic-a-bridge/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-65.0002, -64.5361, -63.8976,  ..., -23.3039, -22.6899, -22.0731],\n",
      "         [ -8.2381,  -8.5802,  -8.8432,  ..., -18.2414, -18.1142, -17.9424],\n",
      "         [ 16.6752,  16.7939,  16.9457,  ...,   7.3856,   7.2366,   7.1150],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 726.0000, 726.0000, 726.0000]],\n",
      "\n",
      "        [[-64.1748, -63.7138, -63.2697,  ..., -28.5695, -28.6302, -28.5872],\n",
      "         [ -6.5569,  -6.7064,  -6.8594,  ...,  -9.6836,  -9.3544,  -8.9881],\n",
      "         [ 15.6466,  15.9384,  16.2253,  ...,   6.6380,   6.2094,   5.8055],\n",
      "         [146.0000, 145.0000, 145.0000,  ..., 693.0000, 693.0000, 693.0000]],\n",
      "\n",
      "        [[-21.7430, -22.0572, -22.5775,  ..., -63.9967, -64.3987, -64.5976],\n",
      "         [-18.2250, -18.2515, -18.2804,  ...,  -9.0208,  -9.6456, -10.3054],\n",
      "         [  1.9719,   2.6054,   3.2812,  ...,  16.4307,  16.1229,  15.8635],\n",
      "         [726.0000, 726.0000, 726.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-54.6185, -54.5089, -54.3271,  ..., -59.4571, -59.6040, -59.7255],\n",
      "         [-20.3521, -20.2784, -20.2040,  ..., -14.7383, -14.9322, -15.0921],\n",
      "         [ 31.4172,  31.2788,  31.1498,  ...,  24.4581,  24.4561,  24.4264],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 144.0000, 144.0000, 144.0000]],\n",
      "\n",
      "        [[-54.0341, -53.6494, -53.1068,  ..., -51.1623, -51.9492, -52.6466],\n",
      "         [-11.0007, -11.1763, -11.4185,  ..., -47.1521, -47.4780, -47.8689],\n",
      "         [ 26.2715,  26.9408,  27.5899,  ...,  -1.8642,  -2.0365,  -2.1217],\n",
      "         [143.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-52.5122, -52.3556, -52.1438,  ..., -54.9941, -55.1283, -55.2462],\n",
      "         [-23.9314, -24.0288, -24.1640,  ..., -39.8342, -39.9090, -39.9553],\n",
      "         [-18.9680, -18.9610, -18.9042,  ..., -12.4565, -12.2725, -12.1285],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,  36.0000,  36.0000,  36.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([0, 0, 0,  ..., 3, 3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bohan/projects/DCNN_Dice/RESNET152_ATT_naive.py:212: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x), embed, x_att, x, out1, out2, out3, final_feat, out1_feat, out2_feat, out3_feat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-53.8851, -53.7117, -53.5216,  ..., -55.7292, -55.8622, -55.9853],\n",
      "         [-20.4950, -20.5639, -20.6372,  ..., -35.2616, -35.3594, -35.4523],\n",
      "         [-24.5206, -24.3707, -24.2011,  ...,  -8.9174,  -8.7083,  -8.5122],\n",
      "         [ 41.0000,  41.0000,  41.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-57.3580, -57.1659, -56.9334,  ..., -54.5320, -54.7780, -55.0075],\n",
      "         [-34.6982, -34.6043, -34.5174,  ..., -23.0167, -23.0574, -23.0933],\n",
      "         [-23.2077, -23.0622, -22.8589,  ..., -22.9473, -23.1123, -23.2671],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,  34.0000,  34.0000,  34.0000]],\n",
      "\n",
      "        [[-55.3643, -55.3394, -55.3136,  ..., -54.6626, -54.6990, -54.7225],\n",
      "         [-35.1327, -35.1832, -35.2290,  ..., -22.3474, -22.1926, -22.0622],\n",
      "         [-25.6967, -25.4825, -25.2310,  ..., -23.4161, -23.6319, -23.7877],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,  34.0000,  34.0000,  34.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-28.7116, -28.9359, -29.2132,  ..., -56.6425, -56.9291, -57.1875],\n",
      "         [-60.8548, -60.8657, -60.8892,  ..., -37.1579, -36.8363, -36.5079],\n",
      "         [ -5.2487,  -4.7941,  -4.3528,  ...,  -9.1506,  -8.8516,  -8.5574],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-55.3288, -55.2248, -55.1137,  ..., -58.1381, -58.3516, -58.5472],\n",
      "         [-37.2297, -36.9837, -36.7201,  ..., -48.1217, -48.1027, -48.0682],\n",
      "         [-28.3955, -28.1490, -27.8853,  ...,  -0.9561,  -0.6567,  -0.3840],\n",
      "         [ 48.0000,  48.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-59.5021, -59.3615, -59.1479,  ..., -57.0117, -57.2239, -57.4223],\n",
      "         [-39.4086, -39.2395, -39.0566,  ..., -45.2701, -45.4350, -45.5890],\n",
      "         [-21.8859, -21.8934, -21.9135,  ...,  -7.0657,  -7.0795,  -7.0926],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([3, 3, 3,  ..., 4, 4, 4])\n",
      "tensor([[[-57.9447, -57.7776, -57.5954,  ..., -55.1422, -55.1858, -55.1957],\n",
      "         [-46.3212, -46.2880, -46.2564,  ..., -39.3651, -39.5777, -39.7433],\n",
      "         [ -4.6008,  -4.7670,  -4.9462,  ..., -23.3342, -23.4906, -23.5924],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,  49.0000,  49.0000,  49.0000]],\n",
      "\n",
      "        [[-56.9122, -56.7799, -56.6409,  ..., -57.9765, -58.1562, -58.3439],\n",
      "         [-47.6203, -47.4408, -47.2467,  ..., -39.7763, -39.9172, -40.0544],\n",
      "         [ -8.9992,  -8.8421,  -8.6685,  ..., -25.6551, -25.7320, -25.7879],\n",
      "         [ 37.0000,  37.0000,  37.0000,  ...,  49.0000,  43.0000,  49.0000]],\n",
      "\n",
      "        [[-57.9939, -57.8546, -57.6955,  ..., -55.2432, -55.3808, -55.4991],\n",
      "         [-43.9982, -44.0121, -44.0093,  ..., -34.4314, -34.4488, -34.4562],\n",
      "         [-12.1141, -12.0153, -11.9006,  ..., -24.8791, -25.0974, -25.2258],\n",
      "         [ 37.0000,  44.0000,  37.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-56.8631, -56.6522, -56.4267,  ..., -45.2129, -45.1278, -45.0552],\n",
      "         [-48.4358, -48.2854, -48.1243,  ..., -59.6190, -59.8676, -60.0649],\n",
      "         [ -7.0968,  -7.1840,  -7.2772,  ...,   1.3422,   1.2788,   1.2161],\n",
      "         [ 37.0000,  37.0000,  37.0000,  ...,   0.0000,   0.0000,  39.0000]],\n",
      "\n",
      "        [[-37.3605, -37.2114, -37.0270,  ..., -51.7100, -52.0736, -52.4259],\n",
      "         [-16.1446, -16.5967, -17.0067,  ..., -47.6997, -47.8730, -47.9620],\n",
      "         [ 36.3356,  36.3497,  36.4257,  ...,  39.0793,  39.3672,  39.6541],\n",
      "         [157.0000, 157.0000, 157.0000,  ...,   0.0000, 100.0000, 100.0000]],\n",
      "\n",
      "        [[-57.7456, -57.4935, -57.1924,  ..., -45.8498, -45.8011, -45.7644],\n",
      "         [-53.7867, -53.8700, -53.9379,  ..., -58.0229, -58.3447, -58.6380],\n",
      "         [ -7.6996,  -7.8354,  -7.9796,  ...,   0.7920,   0.8249,   0.8514],\n",
      "         [ 37.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([4, 4, 4,  ..., 5, 5, 5])\n",
      "tensor([[[-50.4660, -50.1867, -49.9220,  ..., -58.5143, -58.9012, -59.2556],\n",
      "         [-50.6803, -50.4125, -50.1230,  ..., -43.4148, -43.1567, -43.0163],\n",
      "         [ 17.4442,  17.7166,  18.0253,  ...,  -2.6418,  -2.4284,  -2.1992],\n",
      "         [ 25.0000,  25.0000,  25.0000,  ...,  30.0000,  30.0000,  30.0000]],\n",
      "\n",
      "        [[-53.1974, -53.0055, -52.7498,  ..., -53.6355, -53.8200, -53.9939],\n",
      "         [-56.8691, -56.6751, -56.4644,  ..., -48.0723, -48.2344, -48.3548],\n",
      "         [ 28.3757,  28.2497,  28.1328,  ...,  10.0571,   9.7825,   9.5402],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,  31.0000]],\n",
      "\n",
      "        [[-51.3080, -51.1863, -51.0550,  ..., -54.6779, -54.8179, -54.9655],\n",
      "         [-55.5464, -55.2781, -54.9936,  ..., -50.1270, -50.4140, -50.6884],\n",
      "         [ 19.0549,  19.2597,  19.4763,  ...,  12.7472,  12.8977,  13.0209],\n",
      "         [109.0000, 109.0000, 109.0000,  ...,  31.0000,  31.0000,  31.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 31.7984,  31.6889,  31.4834,  ...,   5.1505,   4.6707,   4.2763],\n",
      "         [-10.9916, -11.6142, -12.3375,  ..., -15.1842, -14.6090, -14.1022],\n",
      "         [  6.1125,   6.0815,   6.1713,  ...,  55.5143,  55.5721,  55.5885],\n",
      "         [694.0000, 694.0000, 694.0000,  ..., 531.0000, 531.0000, 531.0000]],\n",
      "\n",
      "        [[ 29.1655,  29.3759,  29.5221,  ...,   4.0020,   3.7528,   3.4681],\n",
      "         [-14.7293, -14.9400, -15.2125,  ..., -18.5548, -18.8528, -19.0523],\n",
      "         [  7.5525,   8.0561,   8.6817,  ...,  56.3889,  56.8855,  57.4216],\n",
      "         [725.0000, 725.0000, 725.0000,  ..., 537.0000, 537.0000, 537.0000]],\n",
      "\n",
      "        [[ 32.9667,  32.8007,  32.6265,  ...,   4.5818,   3.9862,   3.4804],\n",
      "         [-11.6903, -11.8346, -12.0200,  ..., -16.1910, -16.1940, -15.9398],\n",
      "         [  7.5032,   8.1110,   8.6907,  ...,  54.5279,  54.8137,  55.0583],\n",
      "         [694.0000,   0.0000,   0.0000,  ..., 537.0000,   0.0000, 537.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([ 5,  5,  5,  ..., 10, 10, 10])\n",
      "tensor([[[ 34.8336,  34.2343,  33.7778,  ...,   4.8991,   4.2299,   3.6572],\n",
      "         [-11.3042, -11.5437, -11.7695,  ..., -16.0082, -16.3269, -16.6864],\n",
      "         [  2.4751,   2.8394,   3.3150,  ...,  53.6012,  53.4814,  53.3270],\n",
      "         [694.0000,   0.0000, 694.0000,  ..., 536.0000, 536.0000, 536.0000]],\n",
      "\n",
      "        [[ 23.6527,  23.8006,  23.9496,  ...,   7.7435,   7.3207,   6.8345],\n",
      "         [-20.2164, -19.8310, -19.4652,  ..., -15.5763, -15.6566, -15.6686],\n",
      "         [ 12.3343,  12.7169,  13.1269,  ...,  53.6067,  53.2998,  53.0294],\n",
      "         [725.0000, 725.0000, 725.0000,  ..., 531.0000, 531.0000, 531.0000]],\n",
      "\n",
      "        [[ 20.6608,  20.7556,  20.8625,  ...,   7.0253,   6.4692,   5.9695],\n",
      "         [-19.0438, -18.9449, -18.8194,  ..., -16.7049, -16.3458, -16.0949],\n",
      "         [  9.2365,   9.8387,  10.4320,  ...,  52.9421,  52.9689,  52.9023],\n",
      "         [698.0000, 698.0000, 698.0000,  ..., 536.0000, 536.0000, 536.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 48.0954,  47.4776,  46.8634,  ...,  54.8180,  55.2412,  55.7382],\n",
      "         [-48.9266, -48.4863, -48.0011,  ..., -33.2269, -32.7461, -32.4817],\n",
      "         [ 20.1558,  20.1413,  20.3331,  ..., -17.3497, -17.7923, -18.3291],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ -9.7488, -10.2980, -11.0280,  ...,  12.7367,  13.4006,  13.8123],\n",
      "         [-52.3883, -51.8049, -51.3486,  ..., -29.5012, -30.0039, -30.6244],\n",
      "         [ 61.1920,  60.9648,  60.7724,  ...,  19.4899,  19.2144,  18.9067],\n",
      "         [112.0000, 112.0000, 112.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-26.2564, -25.6982, -25.2160,  ..., -35.0517, -34.8030, -34.5621],\n",
      "         [  2.6578,   2.9378,   3.3032,  ...,  53.7976,  54.2479,  54.6732],\n",
      "         [-11.9927, -11.7567, -11.6133,  ..., -11.5457, -11.9401, -12.3675],\n",
      "         [693.0000, 693.0000, 693.0000,  ...,   0.0000,   0.0000,   0.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([10, 10, 10,  ..., 14, 14, 14])\n",
      "tensor([[[-38.6893, -38.5153, -37.6705,  ..., -29.5582, -30.7188, -32.1277],\n",
      "         [-76.0954, -74.2829, -72.7855,  ..., -46.1474, -47.1871, -47.8350],\n",
      "         [ -7.8852,  -7.8488,  -7.1056,  ...,  47.9531,  48.8769,  49.8295],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000, 120.0000]],\n",
      "\n",
      "        [[ -6.1346,  -6.4591,  -6.6848,  ..., -19.9931, -19.7088, -19.4286],\n",
      "         [ 14.7067,  14.9960,  15.3362,  ...,  -3.6886,  -4.0020,  -4.3835],\n",
      "         [ -6.8612,  -6.5659,  -6.2446,  ...,  27.5204,  27.8241,  28.0515],\n",
      "         [691.0000, 691.0000, 691.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ -7.5654,  -7.5773,  -7.6764,  ..., -26.2349, -25.9714, -25.7088],\n",
      "         [ 22.9417,  22.7947,  22.6761,  ...,  39.1507,  39.6623,  40.0748],\n",
      "         [ 54.2259,  53.7111,  53.1547,  ...,  20.9163,  20.7580,  20.5907],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 198.0000,   0.0000, 198.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 31.5857,  31.6897,  31.8052,  ...,  24.2725,  24.5273,  24.7340],\n",
      "         [ 35.9746,  35.6856,  35.3422,  ...,  47.5625,  47.8052,  48.0192],\n",
      "         [ 34.6483,  34.5869,  34.5294,  ...,  27.4792,  27.6172,  27.7133],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 543.0000, 543.0000, 543.0000]],\n",
      "\n",
      "        [[-45.4234, -45.2054, -45.0085,  ..., -44.0420, -44.1439, -44.2411],\n",
      "         [-26.3704, -26.5047, -26.6683,  ..., -49.0785, -49.2687, -49.4476],\n",
      "         [ 34.5938,  34.4894,  34.3379,  ...,  39.0688,  39.3071,  39.5259],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,  99.0000,  99.0000,  99.0000]],\n",
      "\n",
      "        [[ 36.3411,  36.1523,  35.9701,  ...,  17.5797,  17.3176,  17.0715],\n",
      "         [-43.4498, -43.6104, -43.7053,  ..., -60.5485, -60.7325, -60.9036],\n",
      "         [ 55.4342,  55.2226,  55.0046,  ...,  43.1200,  42.9715,  42.8332],\n",
      "         [461.0000, 461.0000, 461.0000,  ...,   0.0000,   0.0000,   0.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-3.4254e+01, -3.4291e+01, -3.4464e+01,  ..., -3.2102e+01,\n",
      "          -3.2025e+01, -3.1807e+01],\n",
      "         [ 7.6128e+00,  6.6729e+00,  5.7107e+00,  ..., -1.0172e+01,\n",
      "          -9.6728e+00, -9.0990e+00],\n",
      "         [ 2.1561e+00,  2.2731e+00,  2.2642e+00,  ...,  6.3906e+01,\n",
      "           6.4753e+01,  6.5440e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.5500e+02,\n",
      "           1.5500e+02,  1.5500e+02]],\n",
      "\n",
      "        [[ 2.1733e+01,  2.1780e+01,  2.1827e+01,  ...,  3.4502e+01,\n",
      "           3.4715e+01,  3.4872e+01],\n",
      "         [-3.3454e+01, -3.3671e+01, -3.3903e+01,  ..., -5.0168e+01,\n",
      "          -5.0272e+01, -5.0355e+01],\n",
      "         [-2.8657e+01, -2.8804e+01, -2.8961e+01,  ..., -4.0119e+01,\n",
      "          -3.9989e+01, -3.9870e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.2015e+01, -2.1813e+01, -2.1255e+01,  ..., -3.6454e+01,\n",
      "          -3.7489e+01, -3.8501e+01],\n",
      "         [ 5.5845e+01,  5.4833e+01,  5.3958e+01,  ..., -1.1678e+01,\n",
      "          -1.1595e+01, -1.1566e+01],\n",
      "         [ 1.8608e+01,  1.8743e+01,  1.8589e+01,  ...,  4.7242e+01,\n",
      "           4.7447e+01,  4.7766e+01],\n",
      "         [ 1.9500e+02,  1.9500e+02,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  1.5600e+02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.3846e+01,  4.3778e+01,  4.3649e+01,  ...,  4.4569e+01,\n",
      "           4.4725e+01,  4.4830e+01],\n",
      "         [ 2.6706e+01,  2.6727e+01,  2.6741e+01,  ...,  3.0992e+01,\n",
      "           3.0909e+01,  3.0811e+01],\n",
      "         [-1.7286e+01, -1.7090e+01, -1.6880e+01,  ...,  2.2898e+00,\n",
      "           2.4886e+00,  2.6229e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-9.0031e+00, -9.0937e+00, -9.2035e+00,  ..., -1.6649e+01,\n",
      "          -1.6160e+01, -1.5797e+01],\n",
      "         [ 1.1824e+00,  2.0948e+00,  2.9698e+00,  ...,  9.1155e-01,\n",
      "           1.5832e-01, -4.8718e-01],\n",
      "         [ 3.9496e+01,  3.9318e+01,  3.8990e+01,  ...,  1.1784e+01,\n",
      "           1.2197e+01,  1.2651e+01],\n",
      "         [ 3.1500e+02,  3.1500e+02,  3.1500e+02,  ...,  0.0000e+00,\n",
      "           6.9100e+02,  6.9100e+02]],\n",
      "\n",
      "        [[-4.2943e+01, -4.3105e+01, -4.3315e+01,  ..., -5.5000e+01,\n",
      "          -5.5196e+01, -5.5380e+01],\n",
      "         [-1.4701e+01, -1.4804e+01, -1.4921e+01,  ..., -1.9225e+01,\n",
      "          -1.9354e+01, -1.9476e+01],\n",
      "         [-3.8175e+01, -3.8096e+01, -3.7992e+01,  ..., -2.4422e+01,\n",
      "          -2.4479e+01, -2.4532e+01],\n",
      "         [ 2.8700e+02,  0.0000e+00,  2.8700e+02,  ...,  4.1000e+01,\n",
      "           4.1000e+01,  4.1000e+01]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[ 54.8778,  55.3145,  55.8814,  ...,  64.5005,  65.2966,  66.1551],\n",
      "         [-21.2370, -21.7561, -22.2766,  ..., -25.5780, -25.6458, -25.7480],\n",
      "         [ 38.7795,  38.0344,  37.2840,  ..., -22.3883, -23.0970, -23.6383],\n",
      "         [488.0000, 488.0000,   0.0000,  ..., 380.0000, 380.0000, 380.0000]],\n",
      "\n",
      "        [[ 25.8670,  26.0920,  25.8529,  ...,  51.6468,  52.7153,  53.5155],\n",
      "         [-21.7369, -20.6417, -19.5572,  ...,  27.5394,  27.5732,  27.6412],\n",
      "         [ 66.3441,  65.8641,  65.3816,  ...,  11.6047,  11.0039,  10.1195],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 572.0000, 572.0000, 572.0000]],\n",
      "\n",
      "        [[ 35.9067,  35.7934,  35.6324,  ...,  42.7097,  42.7856,  42.7819],\n",
      "         [ 34.4837,  33.9939,  33.5232,  ...,  50.5758,  51.0704,  51.5734],\n",
      "         [ 30.6543,  30.7643,  30.8297,  ...,   3.5384,   3.5616,   3.5869],\n",
      "         [548.0000,   0.0000,   0.0000,  ..., 595.0000, 595.0000, 595.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-60.6746, -60.0751, -59.3760,  ..., -29.1479, -28.8107, -28.3433],\n",
      "         [-56.5177, -56.8744, -56.6906,  ..., -64.7162, -65.6394, -66.6635],\n",
      "         [ 12.8988,  13.8854,  14.9376,  ...,  -2.1294,  -2.9205,  -3.4631],\n",
      "         [ 32.0000,  32.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-31.1270, -30.3605, -29.9694,  ...,  32.0496,  33.3032,  34.4223],\n",
      "         [ 38.5140,  37.6447,  36.8739,  ...,  12.3872,  12.1309,  12.3074],\n",
      "         [ 37.2963,  36.3922,  35.1992,  ...,  14.8398,  14.1235,  13.1989],\n",
      "         [203.0000,   0.0000, 206.0000,  ...,   0.0000,   0.0000, 567.0000]],\n",
      "\n",
      "        [[ 47.7975,  47.5892,  47.3649,  ...,  34.5123,  34.4400,  34.3727],\n",
      "         [ 23.4889,  23.5418,  23.6058,  ...,  29.8724,  29.8102,  29.7523],\n",
      "         [-12.0832, -12.1230, -12.1640,  ...,  -2.8605,  -2.6596,  -2.4722],\n",
      "         [576.0000, 576.0000, 576.0000,  ..., 618.0000, 618.0000, 618.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-4.7545e+01, -4.7531e+01, -4.7524e+01,  ..., -6.1912e+01,\n",
      "          -6.2151e+01, -6.2367e+01],\n",
      "         [-3.9688e+01, -3.9741e+01, -3.9816e+01,  ..., -4.7786e+01,\n",
      "          -4.7666e+01, -4.7511e+01],\n",
      "         [-5.4410e-01, -8.0956e-01, -1.1539e+00,  ..., -1.9948e-01,\n",
      "          -6.2897e-02,  3.5534e-02],\n",
      "         [ 3.0000e+01,  3.0000e+01,  3.0000e+01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  3.0000e+01]],\n",
      "\n",
      "        [[ 5.6085e+01,  5.5902e+01,  5.5651e+01,  ...,  4.6837e+01,\n",
      "           4.7042e+01,  4.7236e+01],\n",
      "         [-7.5968e-01, -8.0849e-01, -8.4589e-01,  ..., -1.9546e+01,\n",
      "          -1.9480e+01, -1.9413e+01],\n",
      "         [-3.0822e+01, -3.0565e+01, -3.0313e+01,  ..., -1.1159e+01,\n",
      "          -1.0876e+01, -1.0616e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.7300e+02,\n",
      "           3.7300e+02,  3.7300e+02]],\n",
      "\n",
      "        [[-2.1305e+01, -2.1220e+01, -2.1143e+01,  ..., -9.3661e+00,\n",
      "          -9.2375e+00, -9.1171e+00],\n",
      "         [-7.1364e+01, -7.1119e+01, -7.0936e+01,  ..., -5.2742e+01,\n",
      "          -5.2586e+01, -5.2440e+01],\n",
      "         [-3.7969e+01, -3.7925e+01, -3.7935e+01,  ..., -4.5582e+01,\n",
      "          -4.5750e+01, -4.5907e+01],\n",
      "         [ 6.9900e+02,  6.9900e+02,  6.9900e+02,  ...,  7.1300e+02,\n",
      "           7.1300e+02,  7.1300e+02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.7342e+00,  7.5346e+00,  7.3201e+00,  ...,  2.1042e+01,\n",
      "           2.1067e+01,  2.1091e+01],\n",
      "         [-6.9499e+00, -7.0889e+00, -7.2376e+00,  ...,  2.3526e+01,\n",
      "           2.3925e+01,  2.4297e+01],\n",
      "         [ 1.2579e+01,  1.2177e+01,  1.1746e+01,  ...,  9.8979e+00,\n",
      "           1.0205e+01,  1.0492e+01],\n",
      "         [ 6.9800e+02,  6.9800e+02,  6.9800e+02,  ...,  6.9200e+02,\n",
      "           6.9200e+02,  6.9200e+02]],\n",
      "\n",
      "        [[ 3.7688e+01,  3.7562e+01,  3.7353e+01,  ...,  4.3625e+01,\n",
      "           4.4491e+01,  4.5319e+01],\n",
      "         [-7.2627e+01, -7.2588e+01, -7.2311e+01,  ..., -9.4474e+00,\n",
      "          -9.3570e+00, -9.2568e+00],\n",
      "         [ 3.3069e+01,  3.2256e+01,  3.1433e+01,  ...,  4.2243e+01,\n",
      "           4.2179e+01,  4.1919e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-4.0662e+01, -4.0702e+01, -4.0747e+01,  ..., -4.2212e+01,\n",
      "          -4.2440e+01, -4.2636e+01],\n",
      "         [ 2.4581e+01,  2.4663e+01,  2.4754e+01,  ...,  4.4214e+01,\n",
      "           4.4347e+01,  4.4422e+01],\n",
      "         [ 3.5907e+00,  3.8386e+00,  4.1095e+00,  ...,  2.5339e+00,\n",
      "           2.7115e+00,  2.8485e+00],\n",
      "         [ 2.2600e+02,  2.2600e+02,  2.2600e+02,  ...,  2.2300e+02,\n",
      "           2.2300e+02,  2.2300e+02]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[ 1.5342e+01,  1.4640e+01,  1.4138e+01,  ..., -5.8384e+00,\n",
      "          -5.2077e+00, -4.5457e+00],\n",
      "         [-1.5536e+01, -1.5519e+01, -1.5431e+01,  ..., -2.8671e+01,\n",
      "          -2.8549e+01, -2.8516e+01],\n",
      "         [ 2.7974e+01,  2.7760e+01,  2.7279e+01,  ...,  5.3191e+01,\n",
      "           5.3569e+01,  5.3834e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.3400e+02,\n",
      "           1.3400e+02,  1.3400e+02]],\n",
      "\n",
      "        [[ 1.4094e+00,  1.6898e+00,  1.9892e+00,  ...,  1.3205e+01,\n",
      "           1.3023e+01,  1.2831e+01],\n",
      "         [-1.6786e+01, -1.6731e+01, -1.6673e+01,  ..., -2.2087e+01,\n",
      "          -2.2278e+01, -2.2451e+01],\n",
      "         [ 2.7829e+01,  2.7668e+01,  2.7495e+01,  ...,  4.6076e+01,\n",
      "           4.6293e+01,  4.6456e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  5.3600e+02]],\n",
      "\n",
      "        [[ 2.9262e+01,  2.9071e+01,  2.8880e+01,  ...,  1.0223e+01,\n",
      "           9.8619e+00,  9.5308e+00],\n",
      "         [-1.7512e+01, -1.7724e+01, -1.7966e+01,  ..., -3.3150e+01,\n",
      "          -3.3164e+01, -3.3182e+01],\n",
      "         [-1.0232e+01, -1.0080e+01, -9.8940e+00,  ...,  4.1137e+00,\n",
      "           4.0495e+00,  3.9917e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.9800e+02,\n",
      "           0.0000e+00,  6.9800e+02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.7898e+01,  2.8043e+01,  2.8171e+01,  ...,  3.9783e+01,\n",
      "           3.9836e+01,  3.9886e+01],\n",
      "         [-7.0266e+01, -7.0359e+01, -7.0466e+01,  ..., -8.2462e+01,\n",
      "          -8.2460e+01, -8.2456e+01],\n",
      "         [-7.4091e+00, -7.2951e+00, -7.2209e+00,  ..., -1.2058e+01,\n",
      "          -1.2230e+01, -1.2422e+01],\n",
      "         [ 6.3900e+02,  6.3900e+02,  6.3900e+02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.1701e-02,  4.2543e-01,  9.6836e-01,  ...,  1.3033e+01,\n",
      "           1.2817e+01,  1.2672e+01],\n",
      "         [-3.9375e+01, -3.9253e+01, -3.9180e+01,  ..., -5.4923e+01,\n",
      "          -5.5363e+01, -5.5744e+01],\n",
      "         [ 1.8631e+01,  1.8384e+01,  1.8172e+01,  ...,  4.9400e+01,\n",
      "           4.9772e+01,  5.0060e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-4.0136e+01, -4.0301e+01, -4.0366e+01,  ..., -2.5878e+01,\n",
      "          -2.5814e+01, -2.5817e+01],\n",
      "         [-1.6405e+00, -1.6249e+00, -1.6252e+00,  ...,  1.0292e+01,\n",
      "           1.0708e+01,  1.1123e+01],\n",
      "         [-3.8421e+01, -3.7906e+01, -3.7368e+01,  ..., -1.0006e+01,\n",
      "          -9.6042e+00, -9.3050e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           6.9300e+02,  6.9300e+02]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-1.3519e+01, -1.4000e+01, -1.4576e+01,  ..., -4.8452e+01,\n",
      "          -4.8445e+01, -4.8475e+01],\n",
      "         [ 2.3678e+00,  2.2896e+00,  2.2187e+00,  ..., -6.0196e+00,\n",
      "          -6.0257e+00, -5.9166e+00],\n",
      "         [ 6.3562e+01,  6.3045e+01,  6.2476e+01,  ...,  8.5609e+00,\n",
      "           7.8150e+00,  7.0559e+00],\n",
      "         [ 1.8400e+02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.4600e+02,  1.4600e+02]],\n",
      "\n",
      "        [[-3.3763e+00, -3.4386e+00, -3.4459e+00,  ..., -1.1683e+01,\n",
      "          -1.1876e+01, -1.2022e+01],\n",
      "         [-3.6516e+01, -3.6247e+01, -3.5988e+01,  ..., -1.0221e+01,\n",
      "          -9.9720e+00, -9.6690e+00],\n",
      "         [-1.8163e+01, -1.7992e+01, -1.7810e+01,  ..., -2.3771e+00,\n",
      "          -2.3686e+00, -2.3388e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  7.2600e+02]],\n",
      "\n",
      "        [[-2.1895e+01, -2.1846e+01, -2.1792e+01,  ..., -2.0654e+01,\n",
      "          -2.0579e+01, -2.0508e+01],\n",
      "         [-1.2296e+01, -1.2281e+01, -1.2264e+01,  ..., -1.4412e+01,\n",
      "          -1.4257e+01, -1.4116e+01],\n",
      "         [ 1.9711e-01,  4.8339e-01,  7.9169e-01,  ...,  2.6678e+01,\n",
      "           2.6931e+01,  2.7167e+01],\n",
      "         [ 7.2600e+02,  7.2600e+02,  7.2600e+02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2117e+01, -2.1915e+01, -2.1766e+01,  ..., -9.0241e+00,\n",
      "          -8.8713e+00, -8.7288e+00],\n",
      "         [ 1.4076e+01,  1.3782e+01,  1.3488e+01,  ..., -1.4226e+01,\n",
      "          -1.4528e+01, -1.4811e+01],\n",
      "         [ 6.1649e+00,  6.1136e+00,  6.1258e+00,  ..., -3.1349e+00,\n",
      "          -3.3349e+00, -3.5232e+00],\n",
      "         [ 6.9300e+02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.4865e+01,  3.4201e+01,  3.3418e+01,  ...,  1.5881e+01,\n",
      "           1.6237e+01,  1.6313e+01],\n",
      "         [-2.7661e+01, -2.8142e+01, -2.8537e+01,  ..., -9.3717e+00,\n",
      "          -9.3248e+00, -9.3173e+00],\n",
      "         [ 1.0632e+01,  1.1053e+01,  1.1571e+01,  ...,  6.9193e+01,\n",
      "           7.0118e+01,  7.1040e+01],\n",
      "         [ 3.6800e+02,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.5196e+01, -1.5302e+01, -1.5428e+01,  ..., -7.6926e+00,\n",
      "          -7.6921e+00, -7.7168e+00],\n",
      "         [-1.9325e+01, -1.9304e+01, -1.9291e+01,  ..., -1.1043e+01,\n",
      "          -1.1028e+01, -1.1009e+01],\n",
      "         [ 7.3854e+01,  7.3690e+01,  7.3516e+01,  ...,  6.9142e+01,\n",
      "           6.9411e+01,  6.9617e+01],\n",
      "         [ 1.5300e+02,  1.5300e+02,  1.5300e+02,  ...,  1.9300e+02,\n",
      "           1.9300e+02,  1.9300e+02]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[ 11.7313,  12.1660,  12.3944,  ..., -16.5290, -16.7562, -16.8995],\n",
      "         [-34.7722, -34.7963, -34.3083,  ..., -48.2979, -48.4657, -48.6501],\n",
      "         [ 37.7809,  36.9004,  36.0919,  ...,  70.4995,  71.4539,  72.3932],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-15.3455, -15.6464, -15.9611,  ...,  -5.3486,  -4.9509,  -4.5371],\n",
      "         [-69.1505, -68.8737, -68.5882,  ..., -45.2841, -45.3191, -45.3764],\n",
      "         [ 29.9698,  30.0112,  30.0562,  ...,  16.5715,  16.4745,  16.5350],\n",
      "         [130.0000, 130.0000, 130.0000,  ..., 321.0000, 321.0000, 321.0000]],\n",
      "\n",
      "        [[ 17.5932,  17.5504,  17.6666,  ...,  56.9782,  57.6141,  57.9855],\n",
      "         [ -4.1120,  -4.1320,  -4.2582,  ...,  13.7418,  14.0488,  14.2715],\n",
      "         [ 69.7179,  68.8300,  67.8595,  ...,  11.7754,  11.1403,  10.3393],\n",
      "         [534.0000, 534.0000, 534.0000,  ..., 566.0000,   0.0000, 566.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 48.0071,  48.2584,  48.6788,  ...,  10.1574,  10.6837,  11.0871],\n",
      "         [ -7.9094,  -8.5767,  -9.2703,  ..., -48.2156, -48.0782, -47.8586],\n",
      "         [-11.7849, -10.9461, -10.1106,  ...,  11.7272,  10.6922,   9.6807],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-37.7736, -36.9533, -36.0422,  ...,  18.2276,  17.5529,  16.7672],\n",
      "         [-14.3532, -14.9478, -15.7861,  ..., -40.2580, -40.8780, -41.6371],\n",
      "         [  2.8904,   3.6815,   4.0590,  ...,  49.9732,  50.8875,  51.5933],\n",
      "         [343.0000, 343.0000, 339.0000,  ...,   0.0000, 480.0000, 480.0000]],\n",
      "\n",
      "        [[ 43.8839,  44.3415,  44.7928,  ...,  17.3759,  16.6016,  15.9067],\n",
      "         [-17.5173, -17.0980, -16.6465,  ...,   6.1505,   5.6603,   5.3160],\n",
      "         [ 35.7449,  35.1901,  34.5772,  ...,  26.4308,  26.6292,  26.7630],\n",
      "         [487.0000, 488.0000, 488.0000,  ..., 692.0000,   0.0000, 692.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[ 39.2345,  38.8890,  38.4191,  ...,  16.2924,  16.2016,  16.0719],\n",
      "         [ 12.8795,  13.0150,  13.2056,  ...,  21.0452,  21.3498,  21.6232],\n",
      "         [ 28.7756,  28.6984,  28.5843,  ...,  54.3009,  54.6307,  54.9584],\n",
      "         [556.0000, 556.0000, 556.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ -3.3746,  -3.8861,  -4.5135,  ..., -15.5283, -15.2727, -15.0472],\n",
      "         [-24.7122, -24.8752, -25.0711,  ..., -45.2569, -44.8302, -44.4566],\n",
      "         [ 28.5917,  28.3235,  27.9870,  ...,  63.7718,  64.3236,  64.7249],\n",
      "         [317.0000, 317.0000, 317.0000,  ..., 114.0000, 114.0000, 114.0000]],\n",
      "\n",
      "        [[-35.2061, -35.4157, -35.6033,  ..., -37.5037, -37.9940, -38.4773],\n",
      "         [ 45.1815,  44.7604,  44.2925,  ...,  50.9471,  50.9660,  50.9095],\n",
      "         [-13.1590, -13.0569, -12.9861,  ..., -10.6443, -10.6970, -10.7804],\n",
      "         [269.0000,   0.0000,   0.0000,  ..., 265.0000, 265.0000, 265.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 47.2279,  47.2138,  47.2221,  ...,  41.0567,  41.0489,  41.0477],\n",
      "         [ 16.6807,  16.6479,  16.5876,  ...,  25.8611,  25.9657,  26.0832],\n",
      "         [ -2.5245,  -2.3184,  -2.0801,  ...,   9.6283,   9.4481,   9.2559],\n",
      "         [567.0000, 567.0000, 567.0000,  ..., 573.0000, 573.0000, 573.0000]],\n",
      "\n",
      "        [[ 39.3797,  39.1363,  38.8667,  ...,  25.5155,  25.9960,  26.5643],\n",
      "         [-41.0033, -41.0603, -41.2866,  ..., -90.2371, -91.0262, -91.6465],\n",
      "         [-24.9455, -24.1546, -23.2941,  ...,  -4.1902,  -4.2559,  -4.2824],\n",
      "         [627.0000, 627.0000, 627.0000,  ...,   0.0000,   0.0000, 413.0000]],\n",
      "\n",
      "        [[ 38.4751,  37.9496,  37.4160,  ...,  62.9477,  63.6756,  64.2988],\n",
      "         [-65.0549, -64.6812, -64.3278,  ..., -43.4735, -43.5459, -43.5527],\n",
      "         [ 42.7822,  42.6859,  42.3214,  ...,   8.6285,   8.5134,   8.3506],\n",
      "         [451.0000, 450.0000, 450.0000,  ..., 369.0000, 369.0000, 369.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-36.3600, -36.2214, -36.0018,  ..., -44.5975, -44.7050, -44.8244],\n",
      "         [ 10.4610,  10.5702,  10.4831,  ...,  10.8003,  10.7572,  10.6575],\n",
      "         [ 51.8796,  51.2785,  50.6122,  ...,   2.2216,   1.5072,   0.9239],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 222.0000,   0.0000, 222.0000]],\n",
      "\n",
      "        [[-13.8717, -14.8121, -15.4517,  ..., -56.5329, -58.0242, -59.3976],\n",
      "         [  2.1594,   2.7122,   2.8025,  ..., -53.4031, -53.9877, -54.8164],\n",
      "         [ 63.5765,  62.3623,  60.8834,  ...,  -6.0335,  -5.7839,  -5.8649],\n",
      "         [184.0000,   0.0000,   0.0000,  ...,   0.0000,  38.0000,  38.0000]],\n",
      "\n",
      "        [[-35.4347, -35.3858, -35.3143,  ..., -30.5174, -30.7663, -30.9302],\n",
      "         [-33.6083, -33.5025, -33.4239,  ..., -14.8296, -15.0699, -15.2661],\n",
      "         [ 13.7936,  13.4472,  13.0892,  ..., -14.0364, -14.3026, -14.5053],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 324.0000, 324.0000, 324.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-33.3946, -33.1684, -32.9273,  ..., -35.7720, -35.8624, -35.9469],\n",
      "         [ 12.8694,  12.9010,  12.9334,  ...,  15.1261,  15.2061,  15.2809],\n",
      "         [ 54.6608,  54.4710,  54.2673,  ...,  29.5878,  29.3027,  29.0360],\n",
      "         [216.0000, 216.0000, 216.0000,  ..., 210.0000, 210.0000, 210.0000]],\n",
      "\n",
      "        [[ -6.2484,  -6.1696,  -6.2286,  ..., -17.8380, -18.0944, -18.3652],\n",
      "         [-37.9814, -37.4004, -36.8152,  ..., -21.6057, -21.1118, -20.6349],\n",
      "         [-20.3299, -20.1914, -20.0818,  ...,  14.0479,  13.7721,  13.4538],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 697.0000, 697.0000, 697.0000]],\n",
      "\n",
      "        [[-34.2262, -34.0546, -33.8956,  ..., -17.5295, -17.3285, -17.1079],\n",
      "         [ 30.8480,  30.6598,  30.4620,  ...,  25.4002,  25.6056,  25.8290],\n",
      "         [ 38.7368,  38.3165,  37.8787,  ...,  51.9932,  52.3819,  52.7443],\n",
      "         [207.0000, 207.0000, 207.0000,  ...,   0.0000, 177.0000, 177.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-4.2609e+01, -4.2547e+01, -4.2523e+01,  ..., -4.0337e+01,\n",
      "          -4.0668e+01, -4.0896e+01],\n",
      "         [-2.1872e+01, -2.1801e+01, -2.1893e+01,  ..., -4.7684e+01,\n",
      "          -4.7091e+01, -4.6545e+01],\n",
      "         [ 6.3590e+01,  6.2532e+01,  6.1401e+01,  ...,  4.1602e+01,\n",
      "           4.2530e+01,  4.3418e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0200e+02,\n",
      "           0.0000e+00,  1.0200e+02]],\n",
      "\n",
      "        [[-1.6583e-01,  1.5986e-02,  2.7102e-01,  ...,  2.5852e+01,\n",
      "           2.6105e+01,  2.6338e+01],\n",
      "         [ 6.1319e-01,  6.1089e-01,  6.0649e-01,  ..., -5.5972e+00,\n",
      "          -5.7480e+00, -5.8899e+00],\n",
      "         [-6.8315e+00, -6.7676e+00, -6.6810e+00,  ..., -8.1563e+00,\n",
      "          -8.1952e+00, -8.2295e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.9578e+00,  1.2690e+00,  6.0306e-01,  ..., -2.7923e+01,\n",
      "          -2.7540e+01, -2.7265e+01],\n",
      "         [-3.2413e+01, -3.2312e+01, -3.2147e+01,  ..., -6.2605e+01,\n",
      "          -6.2900e+01, -6.3307e+01],\n",
      "         [ 6.3728e+00,  6.6860e+00,  7.0017e+00,  ...,  3.3733e+01,\n",
      "           3.4382e+01,  3.4924e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0500e+02,\n",
      "           1.0500e+02,  1.0500e+02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.4777e+01, -3.4918e+01, -3.5068e+01,  ..., -3.1089e+01,\n",
      "          -3.0936e+01, -3.0793e+01],\n",
      "         [ 1.0740e+00,  1.0432e+00,  1.0087e+00,  ...,  6.3587e+00,\n",
      "           6.4434e+00,  6.5230e+00],\n",
      "         [-1.6861e+01, -1.6663e+01, -1.6445e+01,  ...,  5.1542e+00,\n",
      "           5.3599e+00,  5.5510e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.9300e+02,\n",
      "           6.9300e+02,  6.9300e+02]],\n",
      "\n",
      "        [[ 5.1939e+01,  5.2060e+01,  5.2190e+01,  ...,  5.4745e+01,\n",
      "           5.4828e+01,  5.4904e+01],\n",
      "         [-5.0329e+00, -4.9044e+00, -4.7668e+00,  ...,  9.6514e+00,\n",
      "           9.6622e+00,  9.6763e+00],\n",
      "         [ 4.6833e+00,  4.7736e+00,  4.8702e+00,  ...,  1.4156e+00,\n",
      "           1.2107e+00,  1.0199e+00],\n",
      "         [ 4.9100e+02,  4.9100e+02,  4.9100e+02,  ...,  4.9500e+02,\n",
      "           4.9500e+02,  4.9500e+02]],\n",
      "\n",
      "        [[-1.6508e+01, -1.6451e+01, -1.6391e+01,  ..., -2.2101e+01,\n",
      "          -2.2190e+01, -2.2268e+01],\n",
      "         [ 2.4288e+01,  2.4341e+01,  2.4398e+01,  ...,  7.9932e+00,\n",
      "           7.7540e+00,  7.5735e+00],\n",
      "         [-5.0725e+00, -5.2978e+00, -5.5361e+00,  ..., -1.3759e+01,\n",
      "          -1.3817e+01, -1.3885e+01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-56.7285, -56.5640, -56.3577,  ..., -49.2084, -49.3025, -49.3946],\n",
      "         [-40.2542, -40.3006, -40.3558,  ..., -33.6798, -33.6138, -33.5415],\n",
      "         [  8.5225,   8.4904,   8.4500,  ...,  -1.4929,  -1.6170,  -1.7981],\n",
      "         [ 24.0000,  24.0000,  24.0000,  ...,  29.0000,  29.0000,  29.0000]],\n",
      "\n",
      "        [[-43.1653, -43.3697, -43.3293,  ...,  14.7156,  14.2021,  14.0027],\n",
      "         [ 13.0945,  12.0903,  11.0459,  ...,  32.2184,  32.6506,  32.8156],\n",
      "         [ 22.3409,  22.3937,  22.0933,  ...,  46.5822,  47.4221,  48.4543],\n",
      "         [220.0000,   0.0000, 220.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[ 19.4304,  19.2736,  19.0477,  ...,   1.9730,   1.7006,   1.2113],\n",
      "         [-11.8902, -11.8464, -11.9599,  ..., -49.5930, -50.2097, -50.6137],\n",
      "         [  2.6303,   1.7654,   0.8370,  ..., -60.3772, -61.0314, -61.6962],\n",
      "         [725.0000, 725.0000, 725.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-27.6062, -28.4140, -29.4365,  ..., -37.6072, -38.7430, -39.5280],\n",
      "         [-46.2610, -46.0329, -45.7677,  ...,  31.6575,  31.3036,  30.9885],\n",
      "         [ 15.8979,  14.9213,  13.9997,  ...,   4.6519,   3.9901,   2.9657],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-54.3768, -54.2097, -54.0050,  ..., -54.1099, -54.4171, -54.7016],\n",
      "         [ -5.9470,  -6.1366,  -6.3665,  ...,  -2.6375,  -2.5489,  -2.4849],\n",
      "         [ 19.1044,  18.9338,  18.8251,  ...,  37.1662,  37.2897,  37.4158],\n",
      "         [159.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  6.3848,   6.8549,   7.3581,  ...,  17.6710,  17.9158,  18.0245],\n",
      "         [ 40.5886,  39.9888,  39.3257,  ..., -23.3109, -24.0474, -24.7528],\n",
      "         [ 48.1605,  48.2532,  48.1998,  ...,  40.7245,  40.3944,  40.0953],\n",
      "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000, 536.0000, 536.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
      "tensor([[[-26.0336, -26.1319, -26.2382,  ..., -40.1220, -40.2657, -40.3799],\n",
      "         [ 36.2600,  36.3736,  36.4980,  ...,  37.2878,  37.2456,  37.2148],\n",
      "         [-10.5268, -10.3825, -10.2311,  ..., -13.6749, -13.8528, -14.0047],\n",
      "         [273.0000, 273.0000, 273.0000,  ...,   0.0000,   0.0000, 230.0000]],\n",
      "\n",
      "        [[ -4.2405,  -4.9004,  -5.6411,  ...,  11.1061,  11.2976,  11.4573],\n",
      "         [-21.1929, -21.3133, -21.4223,  ..., -24.0331, -24.6656, -25.2472],\n",
      "         [ 51.1694,  51.3673,  51.4896,  ...,  37.0973,  37.3726,  37.7870],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 662.0000, 662.0000, 662.0000]],\n",
      "\n",
      "        [[ 21.1432,  20.9092,  20.6699,  ...,  38.6158,  38.8909,  39.1657],\n",
      "         [ 29.0934,  29.1974,  29.2975,  ...,  29.0595,  29.3297,  29.5678],\n",
      "         [ 40.3279,  40.0213,  39.6928,  ...,  28.9970,  29.1428,  29.2880],\n",
      "         [518.0000, 518.0000, 518.0000,  ..., 552.0000, 552.0000, 552.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-29.2533, -30.0833, -30.4109,  ...,  -9.1337,  -7.9832,  -6.8463],\n",
      "         [-37.5809, -36.9166, -36.0513,  ..., -48.3341, -48.6145, -48.8133],\n",
      "         [ 62.2177,  61.6102,  60.8256,  ...,  47.2926,  47.5597,  47.9570],\n",
      "         [139.0000, 139.0000, 139.0000,  ..., 111.0000, 111.0000, 111.0000]],\n",
      "\n",
      "        [[ 47.6058,  47.4423,  47.2324,  ...,  18.5705,  18.6413,  18.9028],\n",
      "         [-47.7175, -48.2269, -48.6798,  ..., -84.8404, -85.5626, -86.2997],\n",
      "         [ -9.2509,  -8.6803,  -7.9136,  ...,  35.7034,  36.0929,  36.4462],\n",
      "         [  0.0000,   0.0000,   0.0000,  ..., 399.0000, 399.0000, 399.0000]],\n",
      "\n",
      "        [[ -4.6193,  -5.6061,  -6.7103,  ...,  29.8672,  29.5237,  29.5738],\n",
      "         [-61.5425, -62.0850, -62.3579,  ..., -46.9466, -47.8308, -48.6512],\n",
      "         [ 40.6497,  40.0180,  39.3701,  ...,  53.5478,  54.4786,  55.4454],\n",
      "         [121.0000,   0.0000, 130.0000,  ...,   0.0000,   0.0000,   0.0000]]])\n",
      "torch.Size([10000, 4, 100])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([14, 14, 14,  ..., 14, 14, 14])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m loss_nll \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss(size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# log-softmax applied in the network\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 64\u001b[0m     logit, attVec \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroi_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtst_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     attVec\u001b[38;5;241m=\u001b[39mmySoftmax(np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39mvstack(attVec)))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize of attVec\u001b[39m\u001b[38;5;124m'\u001b[39m,attVec\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, roi_extractor, tst_loader, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         data_processed \u001b[38;5;241m=\u001b[39m preprocess_fiber_input(data, roi_extractor\u001b[38;5;241m=\u001b[39mroi_extractor, device\u001b[38;5;241m=\u001b[39mdevice, net_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m         output,_,att,_, _, _, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m model(data_processed)\n\u001b[0;32m---> 14\u001b[0m         logit\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     15\u001b[0m         attVec\u001b[38;5;241m.\u001b[39mappend(att\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logit,attVec\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 数据加载\n",
    "import os\n",
    "import sys\n",
    "# del os.environ['MKL_NUM_THREADS'] # error corrected by MH 10/12/2022 (add these three lines)\n",
    "from Embedding_layer import ROIFeatureExtractor\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "import scipy.io as spio\n",
    "import RESNET152_ATT_naive\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import torch.nn as nn\n",
    "from Util import focalLoss, preprocess_fiber_input\n",
    "from clustering_layer_v2 import ClusterlingLayer\n",
    "from klDiv import KLDivLoss\n",
    "\n",
    "modelpath = 'save_small/focal_loss_and_cluster_loss_c_10.0_FE_dim_32.model'\n",
    "fe_path = 'save_small/FE_layer_focal_loss_and_cluster_loss_c_10.0_FE_dim_32.model'\n",
    "cls_path = 'save_small/CLS_layer_focal_loss_and_cluster_loss_c_10.0_FE_dim_32.model'\n",
    "# 加载模型\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "ROI_EMBEDDING_DIM = 32\n",
    "NUM_ROI_CLASSES = 726 + 1\n",
    "HIDDEN_DIM = 64\n",
    "model=RESNET152_ATT_naive.resnet18(num_classes=NCLASS, input_ch=3+ROI_EMBEDDING_DIM)\n",
    "# init ROI Embedding layer\n",
    "roi_embedding_layer = nn.Embedding(NUM_ROI_CLASSES, ROI_EMBEDDING_DIM).to(device)\n",
    "# init FE\n",
    "roi_extractor = ROIFeatureExtractor(roi_embedding_layer, ROI_EMBEDDING_DIM, hidden_dim=HIDDEN_DIM).to(device)\n",
    "roi_extractor.to(device)\n",
    "model.to(device)\n",
    "clustering_layer = ClusterlingLayer(embedding_dimension=512, num_clusters=NCLASS, alpha=1.0)\n",
    "kl_loss = KLDivLoss(NCLASS, loss_weight=2.0, temperature=2)\n",
    "kl_loss.to(device)\n",
    "clustering_layer.to(device)\n",
    "# 2️⃣ 加载权重\n",
    "state_dict = torch.load(modelpath, map_location=device)\n",
    "state_dict_FE = torch.load(fe_path, map_location=device)\n",
    "state_dict_cls = torch.load(cls_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "roi_extractor.load_state_dict(state_dict_FE)\n",
    "clustering_layer.load_state_dict(state_dict_cls)\n",
    "# 0.9115309895465665 0.919601178493508 0.913951033276079  \n",
    "# 0.9038265169218341 0.9223096121975994 0.9100564454400993\n",
    "model.eval()\n",
    "roi_extractor.eval()\n",
    "clustering_layer.eval()\n",
    "\n",
    "log_testing_total_loss = 0.0\n",
    "log_focal_loss = 0.0\n",
    "log_centering_loss= 0.\n",
    "log_clustering_loss = 0.0\n",
    "probs = []\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "global global_cluster_rois  # Ensure global access to cluster anatomical profiles\n",
    "loss_nll = nn.NLLLoss(size_average=True) # log-softmax applied in the network\n",
    "with torch.no_grad():\n",
    "    logit, attVec = test(model, roi_extractor, tst_loader, device)\n",
    "    attVec=mySoftmax(np.squeeze(np.vstack(attVec))).astype(np.float32)\n",
    "    print('size of attVec',attVec.shape)\n",
    "    #build output\n",
    "    prob=np.exp(np.vstack(logit)).astype(np.float32)\n",
    "    membership=np.argmax(prob,axis=1).reshape((-1,1)).astype(np.float32)\n",
    "    maxprob=np.amax(prob,axis=1).reshape((-1,1)).astype(np.float32)\n",
    "    \n",
    "    output_max=np.zeros((X_test_np.shape[0],7),dtype=np.float32)\n",
    "    output_max[:,0]=np.arange(1,X_test_np.shape[0]+1)\n",
    "    for i in range(X_test_np.shape[0]):\n",
    "        output_max[i, 0] = i + 1  # Fiber ID（从 1 开始）\n",
    "        output_max[i, 1:4] = X_test_np[i, 0:3, 0]  # 取前三个通道的坐标\n",
    "        output_max[i, 4] = X_test_np[i, 3, 0]  # 存储 ROI 信息\n",
    "    #merge\n",
    "    output_max=np.hstack((output_max,prob,membership,maxprob))\n",
    "    np.savetxt(matpath.replace('.mat','.txt'),output_max,fmt='%.4e')\n",
    "        # Compute clustering loss if enabled\n",
    "    for i in range(NCLASS):\n",
    "        #print(i)\n",
    "        submat=output_max[np.where(output_max[:,-2]==i)]\n",
    "        #fiber index\n",
    "        fiberIndex=submat[:,0].reshape((-1,1))\n",
    "        np.savetxt(matpath.replace('.mat','_'+'{0:02}'.format(i)+'_fiberindex.txt'),fiberIndex,fmt='%d')\n",
    "        #fiber prob\n",
    "        fiberProb=submat[:,-1].reshape((-1,1))\n",
    "        np.savetxt(matpath.replace('.mat','_'+'{0:02}'.format(i)+'_fiberprob.txt'),fiberProb,fmt='%.4e')\n",
    "        #fiber attention map\n",
    "        fiberAtm=attVec[np.where(output_max[:,-2]==i)]\n",
    "        #print('fiberAtm.shape',fiberAtm.shape)\n",
    "        np.savetxt(matpath.replace('.mat','_'+'{0:02}'.format(i)+'_fiberatm.txt'),fiberAtm,fmt='%.4e')        \n",
    "    print('results saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test_np shape:\", X_test_np.shape)\n",
    "print(\"Sample data:\", X_test_np[0])  # 打印第一个样本\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deterministic-a-bridge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
